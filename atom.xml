<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>编程沉思录</title>
  
  <subtitle>一些思考和总结</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.cyhone.com/"/>
  <updated>2020-02-11T05:45:18.915Z</updated>
  <id>http://www.cyhone.com/</id>
  
  <author>
    <name>cyhone</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Golang channel源码深度剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-golang-channel/"/>
    <id>http://www.cyhone.com/articles/analysis-of-golang-channel/</id>
    <published>2020-02-11T04:45:00.000Z</published>
    <updated>2020-02-11T05:45:18.915Z</updated>
    
    <content type="html"><![CDATA[<p>channel是Golang中一个非常重要的特性，也是Golang CSP并发模型的一个重要体现。简单来说就是，goroutine之间可以通过channel进行通信。</p><p>channel在Golang如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于<a href="https://github.com/golang/go/tree/dev.boringcrypto.go1.13" target="_blank" rel="noopener">go 1.13的源码</a>，分析channel的内部实现原理。</p><a id="more"></a><h1 id="channel的基本使用"><a class="markdownIt-Anchor" href="#channel的基本使用"></a> channel的基本使用</h1><p>在正式分析channel的实现之前，我们先看下channel的最基本用法，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        c &lt;- <span class="number">1</span> <span class="comment">// send to channel</span></span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    x := &lt;-c <span class="comment">// recv from channel</span></span><br><span class="line"></span><br><span class="line">    fmt.Println(x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在以上代码中，我们通过<code>make(chan int)</code>来创建了一个类型为int的channel。<br>在一个goroutine中使用<code>c &lt;- 1</code>将数据发送到channel中。在主goroutine中通过<code>x := &lt;- c</code>从channel中读取数据并赋值给x。</p><p>以上代码对应了channel的两种基本操作：send操作 <code>c &lt;- 1</code>和 recv操作 <code>x := &lt;- c</code>, 分别表示发送数据到channel和从channel中接收数据。</p><p>此外，channel还分为有缓存channel和无缓存channel。上述代码中，我们使用的是无缓冲的channel。对于无缓冲的channel，如果当前没有其他goroutine正在接收channel数据，则发送方会阻塞在发送语句处。</p><p>我们可以在channel初始化时指定缓冲区大小，例如，<code>make(chan int, 2)</code>则指定缓冲区大小为2。在缓冲区未满之前，发送方无阻塞地可以往channel发送数据，无需等待接收方准备好。而如果缓冲区已满，则发送方依然会阻塞。</p><h1 id="channel对应的底层实现函数"><a class="markdownIt-Anchor" href="#channel对应的底层实现函数"></a> channel对应的底层实现函数</h1><p>在探究channel源码之前，我们至少需要先找到channel在Golang的具体实现在哪。因为我们在使用channel时，用的是<code>&lt;-</code>符号，并不能直接在go源码中找到其实现。但是Golang的编译器必然会将<code>&lt;-</code>符号翻译成底层对应的实现。</p><p>我们可以使用Go自带的命令: <code>go tool compile -N -l -S hello.go</code>, 将代码翻译成对应的汇编指令。</p><p>或者，直接可以使用<code>Compiler Explorer</code>这个在线工具。对于上述示例代码可以直接在这个链接看其汇编结果: <a href="https://go.godbolt.org/z/3xw5Cj" target="_blank" rel="noopener">go.godbolt.org/z/3xw5Cj</a></p><p><img src="/img/channel/channel-godbolt.png" alt="channel汇编指令"></p><p>通过仔细查看以上示例代码对应的汇编指令，可以发现以下的对应关系：</p><ol><li>channel的构造语句 <code>make(chan int)</code>, 对应的是 <code>runtime.makechan</code>函数</li><li>发送语句 <code>c &lt;- 1</code>, 对应的是<code>runtime.chansend1</code>函数</li><li>接收语句 <code>x := &lt;- c</code>, 对应的是<code>runtime.chanrecv1</code>函数</li></ol><p>以上几个函数的实现都位于go源码中的<code>runtime/chan.go</code>代码文件中。我们接下来针对这几个函数，探究下channel的实现。</p><h1 id="channel的构造"><a class="markdownIt-Anchor" href="#channel的构造"></a> channel的构造</h1><p>channel的构造语句 <code>make(chan int)</code>，将会被golang编译器翻译为<code>runtime.makechan</code>函数, 其函数签名如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makechan</span><span class="params">(t *chantype, size <span class="keyword">int</span>)</span> *<span class="title">hchan</span></span></span><br></pre></td></tr></table></figure><p>其中，<code>t *chantype</code>即构造channel时传入的元素类型。<code>size int</code>即用户指定的channel缓冲区大小，不指定则为0。该函数的返回值是<code>*hchan</code>。hchan则是channel在golang中的内部实现。其定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hchan <span class="keyword">struct</span> &#123;</span><br><span class="line">qcount   <span class="keyword">uint</span>           <span class="comment">// buffer中已放入的元素个数</span></span><br><span class="line">dataqsiz <span class="keyword">uint</span>           <span class="comment">// 用户构造channel时指定的buf大小</span></span><br><span class="line">buf      unsafe.Pointer <span class="comment">// buffer</span></span><br><span class="line">elemsize <span class="keyword">uint16</span>         <span class="comment">// buffer中每个元素的大小</span></span><br><span class="line">closed   <span class="keyword">uint32</span>         <span class="comment">// channel是否关闭，== 0代表未closed</span></span><br><span class="line">elemtype *_type         <span class="comment">// channel元素的类型信息</span></span><br><span class="line">sendx    <span class="keyword">uint</span>           <span class="comment">// buffer中已发送的索引位置 send index</span></span><br><span class="line">recvx    <span class="keyword">uint</span>           <span class="comment">// buffer中已接收的索引位置 receive index</span></span><br><span class="line">recvq    waitq          <span class="comment">// 等待接收的goroutine  list of recv waiters</span></span><br><span class="line">sendq    waitq          <span class="comment">// 等待发送的goroutine list of send waiters</span></span><br><span class="line"></span><br><span class="line">lock mutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>hchan中的所有属性大致可以分为三类：</p><ol><li>buffer相关的属性。例如buf、dataqsiz、qcount等。 当channel的缓冲区大小不为0时，buffer中存放了待接收的数据。使用ring buffer实现。</li><li>waitq相关的属性，可以理解为是一个FIFO的标准队列。其中recvq中是正在等待接收数据的goroutine，sendq中是等待发送数据的goroutine。waitq使用双向链表实现。</li><li>其他属性，例如lock、elemtype、closed等。</li></ol><p><code>makechan</code>的整个过程基本都是一些合法性检测和对<code>buffer</code>、<code>hchan</code>等属性的内存分配，此处不再进行深入讨论了，有兴趣的可以直接看此处的源码。</p><p>通过简单分析hchan的属性，我们可以知道其中有两个重要的组件，<code>buffer</code>和<code>waitq</code>。<code>hchan</code>所有行为和实现都是围绕这两个组件进行的。</p><h1 id="向channel中发送数据"><a class="markdownIt-Anchor" href="#向channel中发送数据"></a> 向channel中发送数据</h1><p>channel的发送和接收流程很相似，我们先分析下channel的发送过程(如<code>c &lt;- 1</code>), 对应于<code>runtime.chansend</code>函数的实现。</p><p>在尝试向channel中发送数据时，如果<code>recvq</code>队列不为空，则首先会从<code>recvq</code>中头部取出一个等待接收数据的goroutine出来。并将数据直接发送给该goroutine。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> sg := c.recvq.dequeue(); sg != <span class="literal">nil</span> &#123;</span><br><span class="line">send(c, sg, ep, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; unlock(&amp;c.lock) &#125;, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>recvq中是正在等待接收数据的goroutine。当某个goroutine使用recv操作(例如，<code>x := &lt;- c</code>)，如果此时channel的缓存中没有数据，且没有其他goroutine正在等待发送数据(即<code>sendq</code>为空)，会将该goroutine以及要接收的数据地址打包成<code>sudog</code>对象，并放入到recvq中。</p><p>继续接着讲上面的代码，如果此时<code>recvq</code>不为空，则调用send函数将数据拷贝到对应的goroutine的堆栈上。</p><p>send函数的实现主要包含两点：</p><ol><li><code>memmove(dst, src, t.size)</code>进行数据的转移，本质上就是一个内存拷贝。</li><li><code>goready(gp, skip+1)</code> goready的作用是唤醒对应的goroutine。</li></ol><p>而如果<code>recvq</code>队列为空，则说明此时没有等待接收数据的goroutine，那么此时channel会尝试把数据放到缓存中。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> c.qcount &lt; c.dataqsiz &#123;</span><br><span class="line"><span class="comment">// 相当于 c.buf[c.sendx]</span></span><br><span class="line">qp := chanbuf(c, c.sendx)</span><br><span class="line"><span class="comment">// 将数据拷贝到buffer中</span></span><br><span class="line">typedmemmove(c.elemtype, qp, ep)</span><br><span class="line">c.sendx++</span><br><span class="line"><span class="keyword">if</span> c.sendx == c.dataqsiz &#123;</span><br><span class="line">c.sendx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">c.qcount++</span><br><span class="line">unlock(&amp;c.lock)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码的作用其实非常简单，就是把数据放到buffer中而已。此过程涉及了ring buffer的操作，其中<code>dataqsiz</code>代表用户指定的channel的buffer大小，如果不指定则默认为0。其他具体的详细操作后续过程会在ring buffer一节详细讲到。</p><p>如果用户使用的是无缓冲channel或者此时buffer已满，则<code>c.qcount &lt; c.dataqsiz</code>条件不会满足, 以上流程也并不会执行到。此时会将当前的goroutine以及要发送的数据放入到<code>sendq</code>队列中，同时会切出该goroutine。整个流程对应代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">gp := getg()</span><br><span class="line">mysg := acquireSudog()</span><br><span class="line">mysg.releasetime = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> t0 != <span class="number">0</span> &#123;</span><br><span class="line">mysg.releasetime = <span class="number">-1</span></span><br><span class="line">&#125;</span><br><span class="line">mysg.elem = ep</span><br><span class="line">mysg.waitlink = <span class="literal">nil</span></span><br><span class="line">mysg.g = gp</span><br><span class="line">mysg.isSelect = <span class="literal">false</span></span><br><span class="line">mysg.c = c</span><br><span class="line">gp.waiting = mysg</span><br><span class="line">gp.param = <span class="literal">nil</span></span><br><span class="line">c.sendq.enqueue(mysg)</span><br><span class="line"><span class="comment">// 将goroutine转入waiting状态，并解锁</span></span><br><span class="line">goparkunlock(&amp;c.lock, waitReasonChanSend, traceEvGoBlockSend, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>以上代码中，goparkunlock就是解锁传入的mutex，并切出该goroutine，将该goroutine置为waiting状态。<code>gopark</code>和上面的<code>goready</code>对应，互为逆操作。<code>gopark</code>和<code>goready</code>在runtime的源码中会经常遇到，涉及了goroutine的调度过程，这里就不再深入讨论，以后会单独写一篇文章讲解。</p><p>调用<code>gopark</code>后，对于用户侧来看，该向channel发送数据的代码语句会进行阻塞。</p><p>以上过程就是channel的发送语句(如，<code>c &lt;- 1</code>)的内部工作流程，同时整个发送过程都使用<code>c.lock</code>进行加锁，保证并发安全。</p><p>简单来说，整个流程如下：</p><ol><li>检查recvq是否为空，如果不为空，则从recvq头部取一个goroutine，将数据发送过去，并唤醒对应的goroutine即可。</li><li>如果recvq为空，则将数据放入到buffer中。</li><li>如果buffer已满，则将要发送的数据和当前goroutine打包成<code>sudog</code>对象放入到<code>sendq</code>中。并将当前goroutine置为waiting状态。</li></ol><p>从channel中接收数据的过程基本与发送过程类似，此处不再赘述了。具体接收过程涉及到的buffer的相关操作，会在后面进行详细的讲解。</p><p>这里需要注意的是，channel的整个发送过程和接收过程都使用<code>runtime.mutex</code>进行加锁。<code>runtime.mutex</code>是runtime相关源码中常用到的一个轻量级锁。整个过程并不是最高效的lockfree的做法。golang在这里有个issue:<a href="https://github.com/golang/go/issues/8899" target="_blank" rel="noopener">go/issues#8899</a>，给出了lockfree的channel的方案。</p><h1 id="channel的ring-buffer实现"><a class="markdownIt-Anchor" href="#channel的ring-buffer实现"></a> channel的ring buffer实现</h1><p>channel中使用了ring buffer(环形缓冲区)来缓存写入的数据。ring buffer有很多好处，而且非常适合用来实现FIFO式的固定长度队列。</p><p>在channel中，ring buffer的实现如下：</p><p><img src="/img/channel/ring-buffer.png" alt="channel中ring buffer的实现"></p><p><code>hchan</code>中有两个与buffer相关的变量: <code>recvx</code>和<code>sendx</code>。其中<code>sendx</code>表示buffer中可写的index, <code>recvx</code>表示buffer中可读的index。 从<code>recvx</code>到<code>sendx</code>之间的元素，表示已正常存放入buffer中的数据。</p><p>我们可以直接使用<code>buf[recvx]</code>来读取到队列的第一个元素，使用<code>buf[sendx] = x</code>来将元素放到队尾。</p><h2 id="buffer的写入"><a class="markdownIt-Anchor" href="#buffer的写入"></a> buffer的写入</h2><p>当buffer未满时，将数据放入到buffer中的操作如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qp := chanbuf(c, c.sendx)</span><br><span class="line"><span class="comment">// 将数据拷贝到buffer中</span></span><br><span class="line">typedmemmove(c.elemtype, qp, ep)</span><br><span class="line">c.sendx++</span><br><span class="line"><span class="keyword">if</span> c.sendx == c.dataqsiz &#123;</span><br><span class="line">c.sendx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">c.qcount++</span><br></pre></td></tr></table></figure><p>其中<code>chanbuf(c, c.sendx)</code>相当于<code>c.buf[c.sendx]</code>。以上过程非常简单，就是将数据拷贝到buffer的<code>sendx</code>的位置上。</p><p>接着，将<code>sendx</code>移到下一个位置上。如果<code>sendx</code>已到达最后一位，则将其置为0，这是一个典型的头尾相连的做法。</p><h2 id="buffer的读取"><a class="markdownIt-Anchor" href="#buffer的读取"></a> buffer的读取</h2><p>当buffer未满时，此时<code>sendq</code>里面也一定是空的(因为如果buffer未满，用于发送数据的goroutine肯定不会排队，而是直接放数据到buffer中，具体逻辑参考上文向channel发送数据一节)，这时候对于channel的读取过程<code>chanrecv</code>就比较简单了，直接从buffer中读取即可，也是一个移动<code>recvx</code>的过程。与上文buffer的写入基本一致。</p><p>而<code>sendq</code>里面有已等待的goroutine的时候，此时buffer一定是满的。这个时候channel的读取逻辑如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 相当于c.buf[c.recvx]</span></span><br><span class="line">qp := chanbuf(c, c.recvx)</span><br><span class="line"><span class="comment">// copy data from queue to receiver</span></span><br><span class="line"><span class="keyword">if</span> ep != <span class="literal">nil</span> &#123;</span><br><span class="line">typedmemmove(c.elemtype, ep, qp)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// copy data from sender to queue</span></span><br><span class="line">typedmemmove(c.elemtype, qp, sg.elem)</span><br><span class="line">c.recvx++</span><br><span class="line"><span class="keyword">if</span> c.recvx == c.dataqsiz &#123;</span><br><span class="line">c.recvx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">c.sendx = c.recvx <span class="comment">// c.sendx = (c.sendx+1) % c.dataqsiz</span></span><br></pre></td></tr></table></figure><p>以上代码中，<code>ep</code>接收数据的变量对应的地址。例如，在<code>x := &lt;- c</code>中，表示变量<code>x</code>的地址。<br>而<code>sg</code>代表从sendq中取出的第一个<code>sudog</code>。并且：</p><ol><li><code>typedmemmove(c.elemtype, ep, qp)</code>表示buffer中的当前可读元素拷贝到接收变量的地址处。</li><li><code>typedmemmove(c.elemtype, qp, sg.elem)</code>表示将sendq中goroutine等待发送的数据拷贝到buffer中。因为此后进行了<code>recv++</code>, 因此相当于把sendq中的数据放到了队尾。</li></ol><p>简单来说，这里channel将buffer中队首的数据拷贝给了对应的接收变量，同时将sendq中的元素拷贝到了队尾，这样可以才可以做到数据的FIFO(先入先出)。</p><p>接下来可能有点绕，<code>c.sendx = c.recvx</code>, 这句话实际的作用相当于<code>c.sendx = (c.sendx+1) % c.dataqsiz</code>，因为此时buffer依然是满的，所以<code>sendx == recvx</code>是成立的。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>channel作为golang中最常用设施，了解其源码可以帮助我们更好的理解和使用。同时也不会过于迷信和依赖channel的性能，channel就目前的设计来说也还有更多的优化空间。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://github.com/developer-learning/night-reading-go/issues/450" target="_blank" rel="noopener">Go夜读：channel &amp; select 源码分析</a></li><li><a href="http://legendtkl.com/2017/07/30/understanding-golang-channel/" target="_blank" rel="noopener">深入理解 Go Channel</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;channel是Golang中一个非常重要的特性，也是Golang CSP并发模型的一个重要体现。简单来说就是，goroutine之间可以通过channel进行通信。&lt;/p&gt;
&lt;p&gt;channel在Golang如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于&lt;a href=&quot;https://github.com/golang/go/tree/dev.boringcrypto.go1.13&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;go 1.13的源码&lt;/a&gt;，分析channel的内部实现原理。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>libco 的定时器实现——时间轮</title>
    <link href="http://www.cyhone.com/articles/time-wheel-in-libco/"/>
    <id>http://www.cyhone.com/articles/time-wheel-in-libco/</id>
    <published>2019-12-15T05:17:26.000Z</published>
    <updated>2019-12-15T11:09:07.528Z</updated>
    
    <content type="html"><![CDATA[<p>定时器是网络框架中非常重要的组成部分，往往可以利用定时器做一些超时事件的判断或者定时清理任务等。</p><p>定时器有许多经典高效的实现。例如，libevent 采用了小根堆实现定时器，redis 则结合自己场景直接使用了简单粗暴的双向链表。</p><p>时间轮也是一个非常经典的定时器实现，Linux 2.6 内核之前就采用了多级时间轮作为其低精度定时器的实现。而在微信的协程库 libco 中，也用了单级时间轮来处理其内部的超时事件。</p><p>在 libco 的时间轮中，对超时事件的添加删除查询操作均可以达到 <code>O(1)</code> 的时间复杂度，是一个非常高效的数据结构。</p><a id="more"></a><h1 id="时间轮的表示"><a class="markdownIt-Anchor" href="#时间轮的表示"></a> 时间轮的表示</h1><p>libco 的时间轮的数据结构定义如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeout_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">stTimeoutItemLink_t *pItems;</span><br><span class="line"><span class="keyword">int</span> iItemSize;</span><br><span class="line"></span><br><span class="line"><span class="keyword">long</span> <span class="keyword">long</span> llStartIdx;</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> ullStart;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>时间轮 <code>stTimeout_t</code> 负责 libco 中所有超时事件的管理, 其中各属性的意义如下:</p><ol><li><code>pItems</code> 是一个数组，数组长度为 iItemSize。而数组中的每个元素是 <code>stTimeoutItemLink_t</code> 类型，这是一个双向链表实现。而同一个链表中的每个元素，它们的超时时间都是相同的。</li><li><code>llStartIdx</code> 代表当前最近超时时间对应的 index。</li><li><code>ullStart</code> 代表当前最近超时时间的时间戳，单位是毫秒</li></ol><p>总体来说，libco 的时间轮是一个环形数组的实现，如下图所示：</p><p><img src="/img/libco/time-wheel.png" alt="time wheel"></p><p>在这个环形数组中，数组中每个元素代表 1ms。而 libco 将环形数组的总长度设为 <code>60*1000</code>, 即最多可以表达 1 分钟以内的超时事件，且超时精度是毫秒。</p><p>而且，有可能会有多个超时事件在同一时刻发生，因此数组中的元素是个链表，代表同在该时刻触发的超时事件。</p><p>在 libco 初始化时，<code>ullStart</code> 被初始化为当前时刻的时间戳 (单位为毫秒)，<code>llStartIdx</code> 初始化为 0。</p><h1 id="添加一个超时事件"><a class="markdownIt-Anchor" href="#添加一个超时事件"></a> 添加一个超时事件</h1><p>我们看下 libco 是怎么添加一个超时事件的：</p><ol><li>将相对时间转化为时间戳，代码如下：</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="keyword">long</span> now = GetTickMS();</span><br><span class="line">apItem.ullExpireTime = now + timeout;</span><br></pre></td></tr></table></figure><p>这点不难理解，只有统一成标准的时间表示，才可以和其他超时事件统一的放在一起。</p><ol start="2"><li>计算该超时事件的触发时间距离时间轮中最近的超时时间 <code>ullStart</code> 的时间差值</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> diff = apItem-&gt;ullExpireTime - apTimeout-&gt;ullStart;</span><br></pre></td></tr></table></figure><p>计算得到了这个时间差值，才可以进一步计算新的超时事件在时间轮中的位置。<br>当然，在把超时事件放入时间轮之前，需要先判断下该超时事件是否越界了。如果比 <code>ullStart</code> 大于 1 分钟, 则 libco 时间轮没有办法表示这个超时事件，将会报错。相关代码如下</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(diff&gt;= apTimeout-&gt;iItemSize )</span><br><span class="line">&#123;</span><br><span class="line">co_log_err(<span class="string">"CO_ERR: AddTimeout line %d diff %d"</span>,__LINE__,diff);</span><br><span class="line"><span class="keyword">return</span> __LINE__;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>计算得出该超时事件在时间轮中的位置，并将其插入到时间轮中。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AddTail(apTimeout-&gt;pItems + ( apTimeout-&gt;llStartIdx + diff ) % apTimeout-&gt;iItemSize , apItem );</span><br></pre></td></tr></table></figure><p>这里其实有两步:</p><ul><li>计算在时间轮中的位置。其实很简单，就是一个简单的取余过程，这个也是环形数组的普遍做法。得到的 <code>apTimeout-&gt;pItems + ${index}</code>，即是该超时事件所在的位置。</li><li>将该超时事件追加在该位置上的链表最后。前面讲过，有可能多个超时事件可能会在同一时刻触发。</li></ul><h1 id="超时事件的判断及取出"><a class="markdownIt-Anchor" href="#超时事件的判断及取出"></a> 超时事件的判断及取出</h1><p>libco 是如何判断事件是否超时以及取出所有已超时的事件呢？过程如下：</p><ul><li>如果当前的时间小于 <code>ullStart</code>，说明目前没有事件超时</li><li>如果大于等于 <code>ullStart</code>，用当前时间减去 <code>ullStart</code>，就可以得出一共过去了多少毫秒，一毫秒代表一个数组元素，从 <code>llStartIdx</code> 开始遍历即可。</li></ul><p>时间轮是典型的空间换时间的做法，需要预先把环形数组的内存空间都分配好，这也是 libco 的超时事件存取高效的原因。</p><p>讲到这里，其实 libco 的整个时间轮算法已经全部分析完成了。</p><p>但是对于 libco 的时间轮大家可能会有一些疑问：</p><ol><li>libco 的时间轮最多只能支持 1 分钟的超时时间。虽然这个时间对于后台服务的场景已经完全足够了，但是如果我们在其他场景需要更长的超时时间呢？</li><li>libco 中的一个数组元素代表 1ms。如果我们需要更长的时间那岂不是内存空间也随之线性增长了？</li></ol><p>那接下来我们就简单讲下对于时间轮的进一步优化:</p><ol><li>单级时间轮的优化。我们可以对 libco 的单级时间轮做一些简单的优化，例如给每个超时事件加一个 rotation 参数，代表该超时事件会在第几轮触发，这样就可以在一个单级时间轮中存放无限长的超时事件了。但这样代价是超时事件的判断和取出将不会是 <code>O(1)</code> 了。</li><li>多级时间轮。Linux 内核中就采用了多级时间轮的机制，模拟了现实生活中水表刻度。即第一级的时间轮与普通的单级时间轮相同，而第二级时间轮的每个元素的时长等于第一级时间轮的全部总时长，依次类推。Linux 内核中一共采用了五级时间轮。第一级的时间轮所有事件消耗完成后，会触发第二级时间轮的事件迁移。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;定时器是网络框架中非常重要的组成部分，往往可以利用定时器做一些超时事件的判断或者定时清理任务等。&lt;/p&gt;
&lt;p&gt;定时器有许多经典高效的实现。例如，libevent 采用了小根堆实现定时器，redis 则结合自己场景直接使用了简单粗暴的双向链表。&lt;/p&gt;
&lt;p&gt;时间轮也是一个非常经典的定时器实现，Linux 2.6 内核之前就采用了多级时间轮作为其低精度定时器的实现。而在微信的协程库 libco 中，也用了单级时间轮来处理其内部的超时事件。&lt;/p&gt;
&lt;p&gt;在 libco 的时间轮中，对超时事件的添加删除查询操作均可以达到 &lt;code&gt;O(1)&lt;/code&gt; 的时间复杂度，是一个非常高效的数据结构。&lt;/p&gt;
    
    </summary>
    
      <category term="网络编程" scheme="http://www.cyhone.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="定时器" scheme="http://www.cyhone.com/tags/%E5%AE%9A%E6%97%B6%E5%99%A8/"/>
    
      <category term="协程" scheme="http://www.cyhone.com/tags/%E5%8D%8F%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>FileBeat-Log 相关配置指南</title>
    <link href="http://www.cyhone.com/articles/usage-of-filebeat-log-config/"/>
    <id>http://www.cyhone.com/articles/usage-of-filebeat-log-config/</id>
    <published>2019-11-26T12:36:54.000Z</published>
    <updated>2020-01-14T11:40:26.563Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍 Filebeat 7.5 版本中 Log 相关的各个配置项的含义以及其应用场景。</p><p>一般情况下，我们使用 log input 的方式如下，只需要指定一系列 paths 即可。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/messages</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/*.log</span></span><br></pre></td></tr></table></figure><p>但其实除了基本的 paths 配置外，log input 还有大概十几个配置项需要我们关注。</p><p>这些配置项或多或少都会影响到 Filebeat 的使用方式以及性能。虽然其默认值基本足够日常使用，但是还是需要深刻理解每个配置项背后的含义，这样才能够对其完全把控。</p><p>同时，在 filebeat 的日常线上运维中，也会涉及到这些配置参数的调节。</p><a id="more"></a><h1 id="log-input-配置"><a class="markdownIt-Anchor" href="#log-input-配置"></a> log input 配置</h1><h2 id="paths"><a class="markdownIt-Anchor" href="#paths"></a> paths</h2><p>我们可以指定一系列的 paths 作为信息输入源，在指定 path 的时候，注意以下规则：</p><ol><li>指定的路径必须是文件，不能是目录。</li><li>支持 Glob 模式。</li><li>默认支持递归路径，如 <code>/**/</code> 形式，Filebeat 将会展开 8 层嵌套目录。</li></ol><h3 id="glob-模式"><a class="markdownIt-Anchor" href="#glob-模式"></a> Glob 模式</h3><p>Glob 模式支持通配符匹配，目前支持的语法有：</p><table><thead><tr><th>通配符</th><th>解释</th><th>示例</th><th>匹配</th></tr></thead><tbody><tr><td>*</td><td>匹配任意数目的任意字符</td><td><code>La*</code></td><td>Law, Lawyer</td></tr><tr><td>?</td><td>匹配任意的单字符</td><td><code>?at</code></td><td>Cat, cat, Bat or bat</td></tr><tr><td>[abc]</td><td>匹配一个在中括号的字符</td><td><code>[CB]at</code></td><td>Cat or Bat</td></tr><tr><td>[a-z]</td><td>匹配一个指定范围的字符</td><td><code>Letter[0-9]</code></td><td>Letter0, Letter1, Letter2 up to Letter9</td></tr></tbody></table><h3 id="递归的-glob-模式"><a class="markdownIt-Anchor" href="#递归的-glob-模式"></a> 递归的 Glob 模式</h3><p>此外，filebeat 对传统的 Glob 模式进行了扩展，支持用户指定 <code>/**/</code> 模式的路径，filebeat 可以将其展开为 8 层的 Glob 路径。</p><p>例如，假如指定了 <code>/home/data/**/my*.log</code>, filebeat 将会把 <code>/**/</code> 翻译成 8 层的子目录，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/home/data/my*.log</span><br><span class="line">/home/data/*/my*.log</span><br><span class="line">/home/data/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/*/*/my*.log</span><br></pre></td></tr></table></figure><p>加上不带子目录的 Glob 路径，一共会有 8 条 Glob 路径。这些路径都会作为 input 的输入源路径进行搜索。</p><p>但是在使用的时候需要注意：</p><ol><li>filebeat 展开为 8 层子目录的规则，是直接 hardcode 在代码中的，无法通过配置修改匹配层数</li><li>只支持单纯的 <code>/**/</code> 模式，对于 <code>/data**/</code> 模式不支持</li><li>递归模式默认开启，可通过 <code>recursive_glob.enabled</code> 配置项关闭</li></ol><h2 id="recursive_globenabled"><a class="markdownIt-Anchor" href="#recursive_globenabled"></a> recursive_glob.enabled:</h2><p>是否开启递归的 Glob 模式，默认为 true。</p><h2 id="encoding"><a class="markdownIt-Anchor" href="#encoding"></a> encoding</h2><p>指定日志编码，默认是 plain。即 ASCII 模式</p><h2 id="exclude_lines"><a class="markdownIt-Anchor" href="#exclude_lines"></a> exclude_lines</h2><p>可指定多个正则表达式，来去除某些不需要上报的行。例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  exclude_lines:</span> <span class="string">['^DBG']</span></span><br></pre></td></tr></table></figure><p>该配置将会去除以 <code>DBG</code> 开头的行。</p><h2 id="include_lines"><a class="markdownIt-Anchor" href="#include_lines"></a> include_lines</h2><p>可指定多项正则表达式，来仅上报匹配的行。例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  include_lines:</span> <span class="string">['^ERR',</span> <span class="string">'^WARN'</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>该配置将会仅上报以 <code>ERR</code> 和 <code>WARN</code> 开头的行。</p><p>问题来了，如果同时指定了 exclude_lines 和 include_lines 会怎么处理？</p><p>对于这种情况，Filebeat 将会先校验 include_lines，再校验 exclude_lines，其代码实现如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *Harvester)</span> <span class="title">shouldExportLine</span><span class="params">(line <span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(h.config.IncludeLines) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !harvester.MatchAny(h.config.IncludeLines, line) &#123;</span><br><span class="line"><span class="comment">// drop line</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(h.config.ExcludeLines) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">if</span> harvester.MatchAny(h.config.ExcludeLines, line) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="exclude_files"><a class="markdownIt-Anchor" href="#exclude_files"></a> exclude_files</h2><p>可指定多个正则表达式，匹配到的文件名将不会被处理。</p><p>例如:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">exclude_files:</span> <span class="string">['.gz$']</span></span><br></pre></td></tr></table></figure><div class="note danger">            <p>这里需要注意的是，不管是 exclude_files，还是 exclude_lines、include_lines, 声明正则的时候，最好使用单引号引用正则表达式，不要用双引号。否则 yaml 会报转义问题</p>          </div><h2 id="harvester_buffer_size"><a class="markdownIt-Anchor" href="#harvester_buffer_size"></a> harvester_buffer_size</h2><p>读文件时的 buffer 大小，最终会应用在 golang 的 <code>File.Read</code> 函数上面。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *File)</span> <span class="title">Read</span><span class="params">(b []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span></span><br></pre></td></tr></table></figure><p>默认是 16384。即 16k。</p><h2 id="max_bytes"><a class="markdownIt-Anchor" href="#max_bytes"></a> max_bytes</h2><p>表示一条 log 消息的最大 bytes 数目。超过这个大小，剩余就会被截断。<br>默认值为 10485760(即 10MB)。</p><h2 id="multiline"><a class="markdownIt-Anchor" href="#multiline"></a> multiline</h2><p>multiline 是为了解决需要多行聚合在一起发送的情况，例如 Java Stack Traces 信息等。<br>虽然 filebeat 默认不开启 multiline，但是官方的配置文件给了一个例子，可以支持 Java Stack Traces 或者是 C 语言式的换行连续符 <code>\</code>,  可在 <a href="https://www.elastic.co/guide/en/beats/filebeat/master/_examples_of_multiline_configuration.html" target="_blank" rel="noopener">Examples of multiline configuration</a> 中查看。</p><p>由于大部分场景不涉及 multiline，本文不再进行深入讨论。关于 multiline 配置的详细资料可查看官方文档：<br><a href="https://www.elastic.co/guide/en/beats/filebeat/7.5/multiline-examples.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/7.5/multiline-examples.html</a></p><h2 id="ignore_older"><a class="markdownIt-Anchor" href="#ignore_older"></a> ignore_older</h2><p>ignore_older 表示对于最近修改时间距离当前时间已经超过某个时长的文件，就暂时不进行处理。默认值为 0，表示禁用该功能。</p><p>注意：ignore_older 只是暂时不处理该文件，并不会在 Registrar 中改变该文件的状态。</p><p>其代码实现如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Input)</span> <span class="title">isIgnoreOlder</span><span class="params">(state file.State)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="comment">// ignore_older is disable</span></span><br><span class="line"><span class="keyword">if</span> p.config.IgnoreOlder == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">modTime := state.Fileinfo.ModTime()</span><br><span class="line"><span class="keyword">if</span> time.Since(modTime) &gt; p.config.IgnoreOlder &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="close_-系列"><a class="markdownIt-Anchor" href="#close_-系列"></a> close_* 系列</h2><p>log input 中有一系列以 close_开头配置，这些配置决定了 Harvester 何时结束对文件的读取。</p><ol><li>close_eof<br>如果读取到了 EOF(即文件末尾)，是否要结束读取。如果为 true，则读取到文件末尾就结束读取，否则 Harvester 将会继续工作。默认只为 false。</li><li>close_inactive<br>如果配置了 close_eof 为 false，则 Harvester 即使读取到了文件末尾也不会终止。close_inactive 决定了最长没有读到新消息的时长，默认为 5m(即五分钟)。如果超过了 close_inactive 规定的时间依然没有新消息，则 Harvester 退出。</li><li>close_timeout<br>决定了一个 Harvester 的最长工作时间，如果 Harvester 工作了一段时间后依然没有停止，则强行停止 Harvester。默认为 0，表示不强行停止 Harvester。</li><li>close_renamed<br>文件更名时是否退出，默认为 false。文件更名一般发生在日志轮替的场景下。</li><li>close_removed<br>表示当文件被删除时 Harvester 是否要继续。默认为 true，表示当文件被删除时，Harvester 即刻停止工作。</li></ol><p>不过即使 Harvester 关闭了也关系不大。因为根据 filebeat 会定时扫描文件，如果关闭后又有了新增内容，filebeat 依然是可以检查出来的。</p><h2 id="clean_-系列"><a class="markdownIt-Anchor" href="#clean_-系列"></a> clean_* 系列</h2><p>clean_开头的一系列配置用来清理 Registrar 中的文件状态，同时也可以起到减小 Registrar 文件大小、防止 inode 复用等作用。</p><ol><li><p>clean_inactive<br>表示一个时间段。用于移除已经一长段时间没有新产生内容的日志文件，默认为 0，表示禁用该功能。</p></li><li><p>clean_removed<br>在 Registrar 中移除那些已经不存在的文件。默认为 true，表示当文件不存在时，则从 Registrar 中移除。</p></li></ol><h2 id="scan_frequency"><a class="markdownIt-Anchor" href="#scan_frequency"></a> scan_frequency</h2><p>代表 input 的扫描频率，默认为 10s。<br>input 会按照此频率，启动定时器定时扫描路径，以发现新文件和文件的改动情况。</p><h2 id="scansort-和-scanorder"><a class="markdownIt-Anchor" href="#scansort-和-scanorder"></a> scan.sort 和 scan.order</h2><p>这两个配置项需要放在一起讲。<br><code>scan.sort</code> 可取的值为: modtime 和 filename。默认值为空，不进行排序。<br><code>scan.order</code> 可取的值为：asc 和 desc。默认值为 asc。<code>scan.order</code> 仅在 <code>scan.sort</code> 非空时生效。</p><p>需要注意的是：该功能目前为实验功能，可能会在以后版本移除。</p><h2 id="tail_files"><a class="markdownIt-Anchor" href="#tail_files"></a> tail_files</h2><p>默认情况下，Harvester 处理文件时，会文件头开始读取文件。开启此功能后，filebeat 将直接会把文件的 offset 置到末尾，从文件末尾监听消息。默认值是 false。</p><p>注意： 开启了 tail_files, 则所有文件中的当前内容将不会被上报，只有新产生消息时才会上报。</p><p>在真实的实现中，tail_files 被当做 <code>ignore_older=1ns</code> 处理。因此，在启动的时候，只要是新文件，里面的内容都会被忽略，直接把 offset 置为文件末尾。</p><p>所以使用该配置项时千万要谨慎！</p><h2 id="harvester_limit"><a class="markdownIt-Anchor" href="#harvester_limit"></a> harvester_limit</h2><p>harvester_limit 决定了一个 input 最多同时有多少个 harvester 启动。默认为 0，代表不对 harvester 个数进行限制。<br>在使用时要注意两点：</p><ol><li>如果一个文件对应的 harvester 在本轮扫描时没能启动，那会在下次扫描时，有其他文件的 harvester 完全退出时，该文件的 harvester 才能启动。</li><li>harvester_limit 仅对针对配置的 input 进行了限制，多个 input 之间的 harvester_limit 互不影响。</li></ol><h2 id="symlinks"><a class="markdownIt-Anchor" href="#symlinks"></a> symlinks</h2><p>代表是否要对符号链接进行处理，默认值为 false，代表不处理。</p><h2 id="backoff-相关配置"><a class="markdownIt-Anchor" href="#backoff-相关配置"></a> backoff 相关配置</h2><p>我们上文讲到 <code>close_eof</code> 选项，当读取到 eof 时，且 close_eof 为 false，则 Harvester 还会一直尝试读取文件。</p><p>在这种情况下，Harvester 继续读取之前，其实 filebeat 还会等待一段时间。等待的时长就是由 <code>backoff</code>、<code>backoff_factor</code> 和 <code>max_backoff</code> 三个配置项共同决定。</p><p>对应的代码实现为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *Log)</span> <span class="title">wait</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// Wait before trying to read file again. File reached EOF.</span></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-f.done:</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(f.backoff):</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Increment backoff up to maxBackoff</span></span><br><span class="line"><span class="keyword">if</span> f.backoff &lt; f.config.MaxBackoff &#123;</span><br><span class="line">f.backoff = f.backoff * time.Duration(f.config.BackoffFactor)</span><br><span class="line"><span class="keyword">if</span> f.backoff &gt; f.config.MaxBackoff &#123;</span><br><span class="line">f.backoff = f.config.MaxBackoff</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，<code>backoff</code> 默认值为 1s, <code>backoff_factor</code> 默认值为 2，<code>max_backoff</code> 默认值为 10s。</p><p>该配置项意味着，如果读到 EOF，则 filebeat 将会等待一段时间再去读文件。<br>等待时间开始为 1s，如果一直是 EOF，则会逐渐增大等待时间，每次的等待时间是前一次的两倍，且一次最长等待 10s。</p><p>再结合 <code>close_inactive</code> 选项，如果等待时间超过了默认值 5 分钟，则 Harvester 结束。</p><p>此外，如果等待的时候文件又追加了新的数据，则 backoff 将会重新置为初始值。</p><h1 id="全局配置"><a class="markdownIt-Anchor" href="#全局配置"></a> 全局配置</h1><p>除了 log input 相关的属性外，有一些全局属性也需要我们注意。</p><h2 id="queue-相关配置"><a class="markdownIt-Anchor" href="#queue-相关配置"></a> queue 相关配置</h2><p>filebeat 会将 event 暂时存放在 queue 里面。filebeat 的 queue 目前有 mem 和 spool 两种实现，默认是 mem。<br>本文只介绍下 mem 的相关配置项。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">queue:</span></span><br><span class="line"><span class="attr">  mem:</span></span><br><span class="line"><span class="attr">    events:</span> <span class="number">4096</span></span><br><span class="line">    <span class="string">flush.min_events:</span> <span class="number">2048</span></span><br><span class="line">    <span class="string">flush.timeout:</span> <span class="number">1</span><span class="string">s</span></span><br></pre></td></tr></table></figure><p>events 代表 queue 最多能够承载的 event 的个数。如果个数达到最大值，则 input 将不能再向 queue 中插入数据，直至 output 将数据消费。</p><p><code>flush.min_events</code> 代表只有 queue 里面的数据到达了指定个数，才将数据发送给 output。设为 0 代表直接发送给 output，不进行等待。默认值是2048。</p><p><code>flush.timeout</code> 代表定时刷新 event 到 output 中，即使其个数没有达到 <code>flush.min_events</code>。该配置项只会在 <code>flush.min_events</code> 大于 0 时生效。</p><h2 id="registry-相关配置"><a class="markdownIt-Anchor" href="#registry-相关配置"></a> registry 相关配置</h2><ol><li>filebeat.registry.path<br>定制 registry 文件的目录，默认值是 <code>registry</code>。</li></ol><p>注意，这里指定的只是 registry 的目录，最终的 registry 文件的路径会是这样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;filebeat.registry.path&#125;/filebeat/data.json</span><br></pre></td></tr></table></figure><ol start="2"><li><p>filebeat.registry.flush<br>将 registry 文件内容定时刷新到磁盘中。默认为 0s，代表每次更新时直接写文件。<br>配置了该选项可以提高些 filebeat 的性能，避免频繁写磁盘，但是也增加了一定数据丢失的风险。</p></li><li><p>filebeat.registry.file_permissions<br>默认为 0600，即只有拥有者可以读写该用户, 其他用户不可以修改。</p></li></ol><h2 id="日志相关配置"><a class="markdownIt-Anchor" href="#日志相关配置"></a> 日志相关配置</h2><p>filebeat 可以对输出日志的进行相关配置，filebeat 提供了如下日志相关的配置:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">logging.level:</span> <span class="string">info</span> <span class="comment"># 日志输出的最小级别</span></span><br><span class="line"><span class="string">logging.selectors:</span> <span class="string">[]</span> <span class="comment"># 过滤器，用户可在 logp.NewLogger 时指定</span></span><br><span class="line"><span class="string">logging.to_stderr:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到 stderr</span></span><br><span class="line"><span class="string">logging.to_syslog:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到 syslog (主要用于 unix)</span></span><br><span class="line"><span class="string">logging.to_eventlog:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到 windows 的 event log</span></span><br><span class="line"><span class="string">logging.to_files:</span> <span class="literal">true</span> <span class="comment"># 将日志输出到文件中</span></span><br><span class="line"><span class="string">logging.files:</span></span><br><span class="line"><span class="attr">path:</span> <span class="string">$&#123;filebeat_bin_path&#125;/logs/</span> <span class="comment"># 日志目录</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">filebeat</span>  <span class="comment"># 文件名 filebeat filebeat.1 filebeat.2</span></span><br><span class="line"><span class="attr">rotateonstartup:</span> <span class="literal">true</span> <span class="comment"># 在 filebeat 启动时进行日志轮替</span></span><br><span class="line"><span class="attr">rotateeverybytes:</span> <span class="number">10485760</span> <span class="comment"># = 10MB 日志轮替的默认值</span></span><br><span class="line"><span class="attr">keepfiles:</span> <span class="number">7</span> <span class="comment"># 日志保留个数</span></span><br><span class="line"><span class="attr">permissions:</span> <span class="number">0600</span> <span class="comment"># 日志权限</span></span><br><span class="line"><span class="attr">interval:</span> <span class="number">0</span> <span class="comment"># 日志轮替</span></span><br><span class="line"><span class="string">logging.metrics.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">logging.metrics.period:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="string">logging.json:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>filebeat 可以选择将日志输出到许多地方，在线上运营时我们常常会将日志输出到文件, 所以接下来讲下文件相关的配置。</p><p>我们可以配置日志文件的所在目录以及文件名，分别对应 <code>logging.files.path</code> 和 <code>logging.files.name</code>。<br>默认情况下，日志的输出目录是在 filebeat 的 bin 文件所在目录下的 logs 文件。</p><p>filebeat 会进行日志轮替，一般情况下，常见的日志轮替规则有按大小和按时间，filebeat 两种规则均支持。<br>其中:</p><ol><li><code>rotateeverybytes</code> 决定了日志文件的最大值，如果日志文件超过了该值，将发生日志轮替，默认值为 10MB。</li><li><code>rotateonstartup</code> 是说明是否在每次启动时都进行一次日志轮替，这样的话，每次启动的日志都会从一个新文件开始。默认为 true</li></ol><p>按文件大小进行轮替后，日志文件名将会变成 filebeat、filebeat.1、filebeat.2 这种格式，后缀越大文件越旧。</p><p>filebeat 也支持按时间进行轮替，可以配置 <code>logging.files</code> 下的 interval 属性，支持按照秒、分钟、小时、周、月、年进行轮替，对应值为 <code>1s</code>,<code>1m</code>, <code>1h</code>, <code>24h</code>, <code>7*24h</code>, <code>30*24h</code>, 和 <code>365*24h</code>。当然，最小值是 1s。</p><p>按照时间进行轮替时，时间将会以连字符进行分割, 例如：按照 1 小时进行轮替的话，文件格式为：<code>filebeat-2019-11-28-15</code>。filebeat 目前还不支持日期格式的自定义。</p><p>同时，我们也可以指定日志的保留策略，目前只能通过设置 <code>keepfiles</code> 来决定保留日志的个数。</p><p>在日志里面还有 <code>logging.metrics</code> 相关配置，filebeat 会定时输出一些当前的运行指标，例如输出下当前 ack 成功的数目、当前的内存占用情况等：</p><ul><li><code>logging.metrics.enabled</code> 决定是否开启指标搜集</li><li><code>logging.metrics.period</code> 决定指标输出的间隔</li></ul><h2 id="使用环境变量"><a class="markdownIt-Anchor" href="#使用环境变量"></a> 使用环境变量</h2><p>我们可以在使用配置文件中直接使用环境变量，使用方式如下:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">fields:</span></span><br><span class="line"><span class="attr">env:</span> <span class="string">$&#123;ENV_NAME&#125;</span></span><br></pre></td></tr></table></figure><p>我们可以直接用 <code>${ENV_NAME}</code> 来引用系统的环境变量。<br>除了直接引用外，filebeat 还提供了两个表达式配合使用:</p><ol><li><code>${VAR:default_value}</code>。如果没有环境变量 <code>VAR</code>, 则使用默认值 default_value</li><li><code>${VAR:?error_text}</code>。如果没有环境变量 <code>VAR</code>，则显示错误提示 <code>error_text</code></li></ol><p>filebeat 也支持在启动时指定命令行参数来提供环境变量: <code>-E name=${NAME}</code></p><h1 id="相关阅读"><a class="markdownIt-Anchor" href="#相关阅读"></a> 相关阅读</h1><ul><li><a href="https://www.cyhone.com/articles/analysis-of-filebeat/">Elastic-Filebeat 实现剖析</a></li></ul><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-input-log.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-input-log.html</a></li><li><a href="https://github.com/elastic/beats/blob/7.5/filebeat/filebeat.reference.yml" target="_blank" rel="noopener">https://github.com/elastic/beats/blob/7.5/filebeat/filebeat.reference.yml</a></li><li><a href="https://en.wikipedia.org/wiki/Glob_(programming)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Glob_(programming)</a></li><li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/using-environ-vars.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/using-environ-vars.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍 Filebeat 7.5 版本中 Log 相关的各个配置项的含义以及其应用场景。&lt;/p&gt;
&lt;p&gt;一般情况下，我们使用 log input 的方式如下，只需要指定一系列 paths 即可。&lt;/p&gt;
&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;filebeat.inputs:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;- type:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;log&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;  paths:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;    -&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/var/log/messages&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;    -&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/var/log/*.log&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;但其实除了基本的 paths 配置外，log input 还有大概十几个配置项需要我们关注。&lt;/p&gt;
&lt;p&gt;这些配置项或多或少都会影响到 Filebeat 的使用方式以及性能。虽然其默认值基本足够日常使用，但是还是需要深刻理解每个配置项背后的含义，这样才能够对其完全把控。&lt;/p&gt;
&lt;p&gt;同时，在 filebeat 的日常线上运维中，也会涉及到这些配置参数的调节。&lt;/p&gt;
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://www.cyhone.com/categories/Elasticsearch/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="Filebeat" scheme="http://www.cyhone.com/tags/Filebeat/"/>
    
      <category term="Elasticsearch" scheme="http://www.cyhone.com/tags/Elasticsearch/"/>
    
      <category term="大数据" scheme="http://www.cyhone.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Redis 事件循环器 (AE) 实现剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-redis-ae/"/>
    <id>http://www.cyhone.com/articles/analysis-of-redis-ae/</id>
    <published>2019-11-20T03:16:54.000Z</published>
    <updated>2019-12-17T10:57:36.458Z</updated>
    
    <content type="html"><![CDATA[<p>Redis 作为一个单线程高性能的内存缓存 Server 而被人熟知。作为一个典型的 Reactor 式网络应用，Redis 能够达到如此高的性能，必然要依靠足够可靠的事件循环库。<br>Redis 内置了一个高性能事件循环器，叫做 AE。其定义和实现可以在 <code>ae*.h/cpp</code> 这些文件中找到。</p><p>AE 本身就是 Redis 的一部分，所以整体设计原则就是够用就行。也正因为这个背景，AE 的代码才可以简短干净，非常适合阅读和学习。</p><p>本文将基于 Redis 5.0.6 的源码分析下其事件循环器 (AE) 的实现原理。</p><p>同时本人也提供了一个 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/redis-5.0" target="_blank" rel="noopener">Redis 注释版</a>，用以辅助理解 Redis 的源码。</p><a id="more"></a><h1 id="eventloop-的创建"><a class="markdownIt-Anchor" href="#eventloop-的创建"></a> eventloop 的创建</h1><p>Redis 通过以下接口进行 eventloop 的创建和释放。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">aeEventLoop *<span class="title">aeCreateEventLoop</span><span class="params">(<span class="keyword">int</span> setsize)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeDeleteEventLoop</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br></pre></td></tr></table></figure><p>Redis 通过将对应事件注册到 eventloop 中，然后不断循环检测有无事件触发。目前 eventloop 支持超时事件和网络 IO 读写事件的注册。</p><p>我们可以通过 aeCreateEventLoop 来创建一个 eventloop。可以看到在创建 EventLoop 的时候，必须指定一个 setsize 的参数。</p><p>setsize 参数表示了 eventloop 可以监听的网络事件 fd 的个数（不包含超时事件），如果当前监听的 fd 个数超过了 setsize，eventloop 将不能继续注册。</p><p>我们知道，Linux 内核会给每个进程维护一个文件描述符表。而 POSIX 标准对于文件描述符进行了以下约束：</p><ol><li>fd 为 0、1、2 分别表示标准输入、标准输出和错误输出</li><li>每次新打开的 fd，必须使用当前进程中最小可用的文件描述符。</li></ol><p>Redis 充分利用了文件描述符的这些特点，来存储每个 fd 对应的事件。</p><p>在 Redis 的 eventloop 中，直接用了一个连续数组来存储事件信息:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eventLoop-&gt;events = zmalloc(<span class="keyword">sizeof</span>(aeFileEvent)*setsize);</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; setsize; i++)</span><br><span class="line">    eventLoop-&gt;events[i].mask = AE_NONE;</span><br></pre></td></tr></table></figure><p>可以看到数组长度就是 setsize，同时创建之后将每一个 event 的 mask 属性置为 AE_NONE(即是 0)，mask 代表该 fd 注册了哪些事件。</p><p>对于 <code>eventLoop-&gt;events</code> 数组来说，fd 就是这个数组的下标。<br>例如，当程序刚刚启动时候，创建监听套接字，按照标准规定，该 fd 的值为 3。此时就直接在 <code>eventLoop-&gt;events</code> 下标为 3 的元素中存放相应 event 数据。</p><p>不过也基于文件描述符的这些特点，意味着 events 数组的前三位一定不会有相应的 fd 赋值。</p><p>那么，Redis 是如何指定 eventloop 的 setsize 的呢？以下是 Redis 创建 eventloop 的相关代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);</span><br></pre></td></tr></table></figure><p>其中：</p><ol><li>maxclients 代表用户配置的最大连接数，可在启动时由 <code>--maxclients</code> 指定，默认为 10000。</li><li>CONFIG_FDSET_INCR 大小为 128。给 Redis 预留一些安全空间。</li></ol><p>也正是因为 Redis 利用了 fd 的这个特点，Redis 只能在完全符合 POSIX 标准的系统中工作。其他的例如 Windows 系统，生成的 fd 或者说 HANDLE 更像是个指针，并不符合 POSIX 标准。</p><h1 id="网络-io-事件"><a class="markdownIt-Anchor" href="#网络-io-事件"></a> 网络 IO 事件</h1><p>Redis 通过以下接口进行网络 IO 事件的注册和删除。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeCreateFileEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeFileProc *proc, <span class="keyword">void</span> *clientData)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeDeleteFileEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask)</span></span>;</span><br></pre></td></tr></table></figure><p>aeCreateFileEvent 表示将某个 fd 的某些事件注册到 eventloop 中。</p><p>目前可注册的事件有三种:</p><ol><li>AE_READABLE  可读事件</li><li>AE_WRITABLE  可写事件</li><li>AE_BARRIER   该事件稍后在 “<strong>事件的等待和处理</strong>” 一节详细讲到。</li></ol><p>而 mask 就是这几个事件经过或运算后的掩码。</p><p>aeCreateFileEvent 在 epoll 的实现中调用了 epoll_ctl 函数。Redis 会根据该事件对应之前的 mask 是否为 AE_NONE，来决定使用 EPOLL_CTL_ADD 还是 EPOLL_CTL_MOD。</p><p>同样的，aeDeleteFileEvent 也使用了 epoll_ctl，Redis 判断用户是否是要完全删除该 fd 上所有事件，来决定使用 EPOLL_CTL_DEL 还是 EPOLL_CTL_MOD。</p><h1 id="定时器"><a class="markdownIt-Anchor" href="#定时器"></a> 定时器</h1><p>AE 中最不值得分析的大概就是定时器了。。因为实现的实在是太简单了，甚至可以说是简陋。</p><p>Redis 通过以下两个接口进行定时器的注册和取消。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">aeCreateTimeEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">long</span> <span class="keyword">long</span> milliseconds,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeTimeProc *proc, <span class="keyword">void</span> *clientData,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeEventFinalizerProc *finalizerProc)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeDeleteTimeEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">long</span> <span class="keyword">long</span> id)</span></span>;</span><br></pre></td></tr></table></figure><p>在调用 aeCreateTimeEvent 注册超时事件的时候，调用方需要提供两个 callback: aeTimeProc 和 aeEventFinalizerProc。</p><ul><li>aeTimeProc 很简单，就是当超时事件触发时调用的 callback。有点特殊的是，aeTimeProc 需要返回一个 int 值，代表下次该超时事件触发的时间间隔。如果返回 - 1，则说明超时时间不需要再触发了，标记为删除即可。</li><li>finalizerProc  当 timer 被删除的时候，会调用这个 callback</li></ul><p>Redis 的定时器其实做的非常简陋，只是一个普通的双向链表，链表也并不是有序的。每次最新的超时事件，直接插入链表的最头部。<br>当 AE 要遍历当前时刻的超时事件时，也是直接暴力的从头到尾遍历链表，看看有没有超时的事件。</p><p>当时我看到这里源码的时候，还是很震惊的。因为一般来说，定时器都会采用最小堆或者时间轮等有序数据结构进行存储，<br>为什么 Redis 的定时器做的这么简陋？</p><p>《Redis 的设计与实现》一书中说，在 Redis 3.0 版本中，只使用到了 serverCon 这一个超时事件。<br>所以这种情况下，也无所谓性能了，虽然是个链表，但其实用起来就只有一个元素，相当于当做一个指针在用。</p><p>虽然还不清楚 5.0.6 版本里面超时事件有没有增多，不过可以肯定的是，目前依然达不到花点时间去优化的程度。<br>Redis 在注释里面也说明了这事，并且给出了以后的优化方案：<br>用 skiplist 代替现有普通链表，查询的时间复杂度将优化为 O(1), 插入的时间复杂度将变成 O(log(N))</p><h2 id="异常处理"><a class="markdownIt-Anchor" href="#异常处理"></a> 异常处理</h2><p>虽然定时器做的这么简陋，但是对于一些时间上的异常情况，Redis 还是做了下基本的处理。具体可见如下代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (now &lt; eventLoop-&gt;lastTime) &#123;</span><br><span class="line">        te = eventLoop-&gt;timeEventHead;</span><br><span class="line">        <span class="keyword">while</span>(te) &#123;</span><br><span class="line">                te-&gt;when_sec = <span class="number">0</span>;</span><br><span class="line">                te = te-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码的意思是，如果当前时刻小于 lastTime, 那意味着时间有可能被调整了。</p><p>对于这种情况，Redis 是怎么处理的呢：<br>直接把所有的事件的超时时间都置为 0, <code>te-&gt;when_sec = 0</code>。这样的话，接下来检查有哪些超时时间到期的时候，所有的超时事件都会被判定为到期。相当于本次遍历把所有超时事件一次性全部激活。</p><p>因为 Redis 认为，在这种异常情况下，与其冒着超时事件可能永远无法触发的风险，还不如把事情提前做了。</p><p>还是基于 Redis 够用就行的原则，这个解决方案在 Redis 中显然是被接受的。</p><p>但是其实还有更好的做法，比如 libevent 就是通过相对时间的方式进行处理这个问题。为了解决这个几乎不会出现的异常 case，libevent 也花了大量代码进行处理。</p><h1 id="事件的等待和处理"><a class="markdownIt-Anchor" href="#事件的等待和处理"></a> 事件的等待和处理</h1><p>Redis 中关于处理等待事件的函数有以下两个：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeProcessEvents</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> flags)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeMain</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br></pre></td></tr></table></figure><p>aeMain 的实现很简单, 就是我们所说的事件循环了，真的就是个循环：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeMain</span><span class="params">(aeEventLoop *eventLoop)</span> </span>&#123;</span><br><span class="line">    eventLoop-&gt;stop = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (!eventLoop-&gt;stop) &#123;</span><br><span class="line">        <span class="keyword">if</span> (eventLoop-&gt;beforesleep != <span class="literal">NULL</span>)</span><br><span class="line">            eventLoop-&gt;beforesleep(eventLoop);</span><br><span class="line">        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而 aeProcessEvents 代表处理一次事件循环，那么 aeProcessEvents 都做了那些事情呢？</p><ol><li>取出最近的一次超时事件。</li><li>计算该超时事件还有多久才可以触发。</li><li>等待网络事件触发或者超时。</li><li>处理触发的各个事件，包括网络事件和超时事件</li></ol><p>为什么要取出最近的一次超时事件？这是因为对于 epoll_wait 来说，必须要指定一个超时时间。以下是 epoll_wait 的定义：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, struct epoll_event *events, <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout)</span></span>;</span><br></pre></td></tr></table></figure><p>timeout 参数单位是毫秒，如果指定了大于 0 的超时时间，则在这段时间内即使如果没有网络 IO 事件触发，epoll_wait 到了指定时间也会返回。<br>如果超时时间指定为 - 1，则 epoll_wait 将会一直阻塞等待，直到网络事件触发。</p><p>epoll_wait 的超时时间一定要指定为最近超时事件的时间间隔，这样可以防止万一这段时间没有网络事件触发，超时事件也可以正常的响应。</p><p>同时，eventloop 还有两个 callback: beforesleep 和 aftersleep，分别会在 epoll_wait 之前和之后调用。</p><p>接着，我们看下 Redis 是怎么处理已触发的网络事件的：<br>一般情况下，Redis 会先处理读事件 (AE_READABLE)，再处理写事件 (AE_WRITABLE)。<br>这个顺序安排其实也算是一点小优化，<strong>先读后写</strong> 可以让一个请求的处理和回包都是在同一次循环里面，使得请求可以尽快地回包，</p><p>前面讲到，网络 IO 事件注册的时候，除了正常的读写事件外，还可以注册一个 AE_BARRIER 事件，这个事件就是会影响到先读后写的处理顺序。<br>如果某个 fd 的 mask 包含了 AE_BARRIER，那它的处理顺序会是 <strong>先写后读</strong>。</p><p>针对这个场景，redis 举的例子是，如果在 beforesleep 回调中进行了 fsync 动作，然后需要把结果快速回复给 client。这个情况下就需要用到 AE_BARRIER 事件，用来翻转处理事件顺序了。</p><h1 id="操作系统的适配"><a class="markdownIt-Anchor" href="#操作系统的适配"></a> 操作系统的适配</h1><p>Redis 不仅支持 Linux 下的 epoll，还支持其他的 IO 复用方式，目前支持如下四种：</p><ol><li>epoll：支持 Linux 系统</li><li>kqueue：支持 FreeBSD 系统 (如 macOS)</li><li>select</li><li>evport: 支持 Solaris</li></ol><p>几个 IO 复用方式使用的判断顺序如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EVPORT</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_evport.c"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EPOLL</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_epoll.c"</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_KQUEUE</span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_kqueue.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_select.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>这个顺序其实也代表了四种 IO 复用方式的性能高低。</p><p>对于每种 IO 复用方式，只要实现以下 8 个接口就可以正常对接 Redis 了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiCreate</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiDelEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> delmask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiResize</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> setsize)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiFree</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiAddEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiDelEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> delmask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiPoll</span><span class="params">(aeEventLoop *eventLoop, struct timeval *tvp)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">aeApiName</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure><p>在这个 8 个接口下面，其实底层并没有做太多的优化，只是简单的对原有 API 封装而已。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>与其他通用型的事件循环库 (如 libevent) 不一样的是，Redis 的事件循环库不用考虑太多的用户侧因素：</p><ol><li>不用考虑 ABI 兼容。因为 AE 本身就和 Redis 一起编译，所以无需像 libevent 一样考虑库的升级问题。</li><li>不支持 Windows 系统，只支持 unix like 的系统</li><li>指定了监听 fd 的个数的上限，默认支持 10000 个客户端连接。</li></ol><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li>《Redis 的设计与实现》</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis 作为一个单线程高性能的内存缓存 Server 而被人熟知。作为一个典型的 Reactor 式网络应用，Redis 能够达到如此高的性能，必然要依靠足够可靠的事件循环库。&lt;br&gt;
Redis 内置了一个高性能事件循环器，叫做 AE。其定义和实现可以在 &lt;code&gt;ae*.h/cpp&lt;/code&gt; 这些文件中找到。&lt;/p&gt;
&lt;p&gt;AE 本身就是 Redis 的一部分，所以整体设计原则就是够用就行。也正因为这个背景，AE 的代码才可以简短干净，非常适合阅读和学习。&lt;/p&gt;
&lt;p&gt;本文将基于 Redis 5.0.6 的源码分析下其事件循环器 (AE) 的实现原理。&lt;/p&gt;
&lt;p&gt;同时本人也提供了一个 &lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/redis-5.0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis 注释版&lt;/a&gt;，用以辅助理解 Redis 的源码。&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.cyhone.com/categories/Redis/"/>
    
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="Redis" scheme="http://www.cyhone.com/tags/Redis/"/>
    
      <category term="网络编程" scheme="http://www.cyhone.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Reactor" scheme="http://www.cyhone.com/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>Elastic-Filebeat 实现原理剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-filebeat/"/>
    <id>http://www.cyhone.com/articles/analysis-of-filebeat/</id>
    <published>2019-11-15T02:55:00.000Z</published>
    <updated>2020-01-06T05:14:37.349Z</updated>
    
    <content type="html"><![CDATA[<p>Filebeat 是使用 Golang 实现的轻量型日志采集器，也是 Elasticsearch stack 里面的一员。本质上是一个 agent，可以安装在各个节点上，根据配置读取对应位置的日志，并上报到相应的地方去。</p><p>Filebeat 的可靠性很强，可以保证日志 At least once 的上报，同时也考虑了日志搜集中的各类问题，例如日志断点续读、文件名更改、日志 Truncated 等。</p><p>Filebeat 并不依赖于 Elasticsearch，可以单独存在。我们可以单独使用 Filebeat 进行日志的上报和搜集。filebeat 内置了常用的 Output 组件, 例如 kafka、Elasticsearch、redis 等。出于调试考虑，也可以输出到 console 和 file。我们可以利用现有的 Output 组件，将日志进行上报。</p><p>当然，我们也可以自定义 Output 组件，让 Filebeat 将日志转发到我们想要的地方。</p><p>filebeat 其实是 <a href="https://github.com/elastic/beats" target="_blank" rel="noopener">elastic/beats</a> 的一员，除了 filebeat 外，还有 HeartBeat、PacketBeat。这些 beat 的实现都是基于 libbeat 框架。</p><a id="more"></a><h1 id="整体架构"><a class="markdownIt-Anchor" href="#整体架构"></a> 整体架构</h1><p>下图是 Filebeat 官方提供的架构图：</p><p><img src="/img/filebeat/filebeat.png" alt="filebeat"></p><p>除了图中提到的各个组件，整个 filebeat 主要包含以下重要组件：</p><ol><li>Crawler：负责管理和启动各个 Input</li><li>Input：负责管理和解析输入源的信息，以及为每个文件启动 Harvester。可由配置文件指定输入源信息。</li><li>Harvester: Harvester 负责读取一个文件的信息。</li><li>Pipeline: 负责管理缓存、Harvester 的信息写入以及 Output 的消费等，是 Filebeat 最核心的组件。</li><li>Output: 输出源，可由配置文件指定输出源信息。</li><li>Registrar：管理记录每个文件处理状态，包括偏移量、文件名等信息。当 Filebeat 启动时，会从 Registrar 恢复文件处理状态。</li></ol><p>filebeat 的整个生命周期，几个组件共同协作，完成了日志从采集到上报的整个过程。</p><h1 id="日志采集流程"><a class="markdownIt-Anchor" href="#日志采集流程"></a> 日志采集流程</h1><p>Filebeat 不仅支持普通文本日志的作为输入源，还内置支持了 redis 的慢查询日志、stdin、tcp 和 udp 等作为输入源。</p><p>本文只分析下普通文本日志的处理方式，对于普通文本日志，可以按照以下配置方式，指定 log 的输入源信息。</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/*.log</span></span><br></pre></td></tr></table></figure><p>其中 Input 也可以指定多个, 每个 Input 下的 Log 也可以指定多个。</p><p>filebeat 启动时会开启 Crawler，对于配置中的每条 Input，Crawler 都会启动一个 Input 进行处理，代码如下所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Crawler)</span> <span class="title">Start</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> _, inputConfig := <span class="keyword">range</span> c.inputConfigs &#123;</span><br><span class="line">        err := c.startInput(pipeline, inputConfig, r.GetStates())</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于指定的 paths 可以配置多个，而且可以是 Glob 类型，因此 Filebeat 将会匹配到多个配置文件。</p><p>Input 对于每个匹配到的文件，都会开启一个 Harvester 进行逐行读取，每个 Harvester 都工作在自己的的 goroutine 中。</p><p>Harvester 的工作流程非常简单，就是逐行读取文件，并更新该文件暂时在 Input 中的文件偏移量（注意，并不是 Registrar 中的偏移量），读取完成则结束流程。</p><p>同时，我们需要考虑到，日志型的数据其实是在不断增长和变化的：</p><ol><li>会有新的日志在不断产生</li><li>可能一个日志文件对应的 Harvester 退出后，又再次有了内容更新。</li></ol><p>为了解决这两个情况，filebeat 采用了 Input 定时扫描的方式。代码如下，可以看出，Input 扫描的频率是由用户指定的 <code>scan_frequency</code> 配置来决定的 (默认 10s 扫描一次)。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Runner)</span> <span class="title">Run</span><span class="params">()</span></span> &#123;</span><br><span class="line">p.input.Run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.Once &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-p.done:</span><br><span class="line">logp.Info(<span class="string">"input ticker stopped"</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(p.config.ScanFrequency): <span class="comment">// 定时扫描</span></span><br><span class="line">logp.Debug(<span class="string">"input"</span>, <span class="string">"Run input"</span>)</span><br><span class="line">p.input.Run()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外，如果用户启动时指定了 <code>--once</code> 选项，则扫描只会进行一次，就退出了。</p><h1 id="日志定时扫描及异常处理"><a class="markdownIt-Anchor" href="#日志定时扫描及异常处理"></a> 日志定时扫描及异常处理</h1><p>我们之前讲到 Registrar 会记录每个文件的状态，当 Filebeat 启动时，会从 Registrar 恢复文件处理状态。</p><p>其实在 filebeat 运行过程中，Input 组件也记录了文件状态。不一样的是，Registrar 是持久化存储，而 Input 中的文件状态仅表示当前文件的读取偏移量，且修改时不会同步到磁盘中。</p><p>每次，Filebeat 刚启动时，Input 都会载入 Registrar 中记录的文件状态，作为初始状态。Input 中的状态有两个非常重要：</p><ol><li>offset: 代表文件当前读取的 offset，从 Registrar 中初始化。Harvest 读取文件后，会同时修改 offset。</li><li>finished: 代表该文件对应的 Harvester 是否已经结束，Harvester 开始时置为 false，结束时置为 False。</li></ol><p>对于每次定时扫描到的文件，概括来说，会有三种大的情况：</p><ol><li>Input 找不到该文件状态的记录, 说明是新增文件，则开启一个 Harvester，从头开始解析该文件</li><li>如果可以找到文件状态，且 finished 等于 false。这个说明已经有了一个 Harvester 在处理了，这种情况直接忽略就好了。</li><li>如果可以找到文件状态，且 finished 等于 true。说明之前有 Harvester 处理过，但已经处理结束了。</li></ol><p>对于这种第三种情况，我们需要考虑到一些异常情况，Filebeat 是这么处理的：</p><ol><li>如果 offset 大于当前文件大小：说明文件被 Truncate 过，此时按做一个新文件处理，直接从头开始解析该文件</li><li>如果 offset 小于当前文件大小，说明文件内容有新增，则从上次 offset 处继续读即可。</li></ol><p>对于第二种情况，Filebeat 似乎有一个逻辑上的问题: 如果文件被 Truncate 过，后来又新增了数据，且文件大小也比之前 offset 大，那么 Filebeat 是检查不出来这个问题的。</p><p>除此之外，一个比较有意思的点是，Filebeat 甚至可以处理文件名修改的问题。即使一个日志的文件名被修改过，Filebeat 重启后，也能找到该文件，从上次读过的地方继续读。</p><p>这是因为 Filebeat 除了在 Registrar 存储了文件名，还存储了文件的唯一标识。对于 Linux 来说，这个文件的唯一标识就是该文件的 inode ID + device ID。</p><p>至此，我们可以清楚的知道，Filebeat 是如何采集日志文件，同时做到监听日志文件的更新和修改。而日志采集过程，Harvest 会将数据写到 Pipeline 中。我们接下来看下数据是如何写入到 Pipeline 中的。</p><h1 id="pipeline-的写入"><a class="markdownIt-Anchor" href="#pipeline-的写入"></a> Pipeline 的写入</h1><p>Haveseter 会将数据写入缓存中，而另一方面 Output 会从缓存将数据读走。整个生产消费的过程都是由 Pipeline 进行调度的，而整个调度过程也非常复杂。</p><p>此外，Filebeat 的缓存目前分为 memqueue 和 spool。memqueue 顾名思义就是内存缓存，spool 则是将数据缓存到磁盘中。本文将基于 memqueue 讲解整个调度过程。</p><p>我们首先看下 Haveseter 是如何将数据写入缓存中的，如下图所示：</p><p><img src="/img/filebeat/produce-to-pipeline.png" alt=""></p><p>Harvester 通过 pipeline 提供的 pipelineClient 将数据写入到 pipeline 中，Haveseter 会将读到的数据会包装成一个 Event 结构体，再递交给 pipeline。</p><p>在 Filebeat 的实现中，pipelineClient 并不直接操作缓存，而是将 event 先写入一个 events channel 中。</p><p>同时，有一个 eventloop 组件，会监听 events channel 的事件到来，等 event 到达时，eventloop 会将其放入缓存中。</p><p>当缓存满的时候，eventloop 直接移除对该 channel 的监听。<br>每次 event ACK 或者取消后，缓存不再满了，则 eventloop 会重新监听 events channel。</p><p>以上是 Pipeline 的写入过程，此时 event 已被写入到了缓存中。<br>但是 Output 是如何从缓存中拿到 event 数据的？</p><h1 id="pipeline-的消费过程"><a class="markdownIt-Anchor" href="#pipeline-的消费过程"></a> Pipeline 的消费过程</h1><p>整个消费的过程非常复杂，数据会在多个 channel 之间传递流转，如下图所示：<br><img src="/img/filebeat/consume-from-pipeline.png" alt=""></p><p>首先再介绍两个角色：</p><ol><li>consumer： pipeline 在创建的时候，会同时创建一个 consumer。consumer 负责从缓存中取数据</li><li>client worker：负责接收 consumer 传来的数据，并调用 Output 的 Publish 函数进行上报。</li></ol><p>与 producer 类似，consumer 也不直接操作缓存，而是会向 get channel 中写入消费请求。<br>consumer 本身是个后台 loop 的过程，这个消费请求会不断进行。</p><p>eventloop 监听 get channel, 拿到之后会从缓存中取数据。并将数据写入到 resp channel 中。<br>consumer 从 resp channel 中拿到 event 数据后，又会将其写入到 workQueue。</p><p>workQueue 也是个 channel。client worker 会监听该 channel 上的数据到来，将数据交给 Output client 进行 Publish 上报。</p><p>而且，Output 收到的是 Batch Events，即会一次收到一批 Events。BatchSize 由各个 Output 自行决定。</p><p>至此，消息已经递交给了 Output 组件。</p><h1 id="ack-机制"><a class="markdownIt-Anchor" href="#ack-机制"></a> Ack 机制</h1><p>filebeat 之所以可以保证日志可以 at least once 的上报，就是基于其 Ack 机制。</p><p>简单来说，Ack 机制就是，当 Output Publish 成功之后会调用 ACK，最终 Registrar 会收到 ACK，并修改偏移量。</p><p>而且, Registrar 只会在 Output 调用 batch 的相关信号时，才改变文件偏移量。其中 Batch 对外提供了这些信号：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Batch <span class="keyword">interface</span> &#123;</span><br><span class="line">Events() []Event</span><br><span class="line"></span><br><span class="line"><span class="comment">// signals</span></span><br><span class="line">ACK()</span><br><span class="line">Drop()</span><br><span class="line">Retry()</span><br><span class="line">RetryEvents(events []Event)</span><br><span class="line">Cancelled()</span><br><span class="line">CancelledEvents(events []Event)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Output 在 Publish 之后，无论失败，必须调用这些函数中的其中一个。</p><p>以下是 Output Publish 成功后调用 Ack 的流程：<br><img src="/img/filebeat/ack.png" alt="ack"></p><p>可以看到其中起核心作用的组件是 Ackloop。AckLoop 中有一个 ackChanList，其中每一个 ackChan，对应于转发给 Output 的一个 Batch。<br>每次新建一个 Batch，同时会建立一个 ackChan，该 ackChan 会被 append 到 ackChanList 中。</p><p>而 AckLoop 每次只监听处于 ackChanList 最头部的 ackChan。</p><p>当 Batch 被 Output 调用 Ack 后，AckLoop 会收到对应 ackChan 上的事件，并将其最终转发给 Registrar。同时，ackChanList 将会 pop 头部的 ackChan，继续监听接下来的 Ack 事件。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>了解了 Filebeat 的实现原理，我们才有会明白 Filebeat 配置中各个参数对程序的最终影响。同时，由于 FileBeat 是 At least once 的上报，但并不保证 Exactly once, 因此一条数据可能会被上报多次，所以接收端需要自行进行去重过滤。</p><h1 id="相关阅读"><a class="markdownIt-Anchor" href="#相关阅读"></a> 相关阅读</h1><ul><li><a href="https://www.cyhone.com/articles/usage-of-filebeat-log-config/">FileBeat-Log 相关配置介绍</a></li></ul><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html" target="_blank" rel="noopener">How FileBeat Works</a></li><li><a href="https://cloud.tencent.com/developer/article/1367784" target="_blank" rel="noopener">filebeat 源码解析</a></li><li><a href="https://niyanchun.com/filebeat-truncate-bug.html" target="_blank" rel="noopener">filebeat 数据重复和截断及丢失问题分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/72912085" target="_blank" rel="noopener">容器日志采集利器：filebeat 深度剖析与实践</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Filebeat 是使用 Golang 实现的轻量型日志采集器，也是 Elasticsearch stack 里面的一员。本质上是一个 agent，可以安装在各个节点上，根据配置读取对应位置的日志，并上报到相应的地方去。&lt;/p&gt;
&lt;p&gt;Filebeat 的可靠性很强，可以保证日志 At least once 的上报，同时也考虑了日志搜集中的各类问题，例如日志断点续读、文件名更改、日志 Truncated 等。&lt;/p&gt;
&lt;p&gt;Filebeat 并不依赖于 Elasticsearch，可以单独存在。我们可以单独使用 Filebeat 进行日志的上报和搜集。filebeat 内置了常用的 Output 组件, 例如 kafka、Elasticsearch、redis 等。出于调试考虑，也可以输出到 console 和 file。我们可以利用现有的 Output 组件，将日志进行上报。&lt;/p&gt;
&lt;p&gt;当然，我们也可以自定义 Output 组件，让 Filebeat 将日志转发到我们想要的地方。&lt;/p&gt;
&lt;p&gt;filebeat 其实是 &lt;a href=&quot;https://github.com/elastic/beats&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;elastic/beats&lt;/a&gt; 的一员，除了 filebeat 外，还有 HeartBeat、PacketBeat。这些 beat 的实现都是基于 libbeat 框架。&lt;/p&gt;
    
    </summary>
    
      <category term="Elasticsearch" scheme="http://www.cyhone.com/categories/Elasticsearch/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Filebeat" scheme="http://www.cyhone.com/tags/Filebeat/"/>
    
      <category term="Elasticsearch" scheme="http://www.cyhone.com/tags/Elasticsearch/"/>
    
      <category term="大数据" scheme="http://www.cyhone.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>uber-go 漏桶限流器使用与原理分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/"/>
    <id>http://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/</id>
    <published>2019-11-10T07:40:19.000Z</published>
    <updated>2019-12-10T05:07:50.063Z</updated>
    
    <content type="html"><![CDATA[<p>uber 在 Github 上开源了一套用于服务限流的 go 语言库 <a href="https://github.com/uber-go/ratelimit/" target="_blank" rel="noopener">ratelimit</a>, 该组件基于 Leaky Bucket(漏桶) 实现。</p><p>我在之前写过 <a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">《Golang 限流器 time/rate 实现剖析》</a>，讲了 Golang 标准库中提供的基于 Token Bucket 实现限流组件的 <code>time/rate</code> 原理，同时也讲了限流的一些背景。</p><p>相比于 TokenBucket，只要桶内还有剩余令牌，调用方就可以一直消费。而 Leaky Bucket 相对来说比较严格，调用方只能严格按照这个间隔顺序进行消费调用。(实际上，uber-go 对这个限制也做了一些优化，具体可以看下文详解)</p><p>还是老规矩，在正式讲其实现之前，我们先看下 ratelimit 的使用方法。</p><a id="more"></a><h1 id="ratelimit-的使用"><a class="markdownIt-Anchor" href="#ratelimit-的使用"></a> ratelimit 的使用</h1><p>我们直接看下 uber-go 官方库给的例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rl := ratelimit.New(<span class="number">100</span>) <span class="comment">// per second</span></span><br><span class="line"></span><br><span class="line">prev := time.Now()</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">  now := rl.Take()</span><br><span class="line">  fmt.Println(i, now.Sub(prev))</span><br><span class="line">  prev = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们给定限流器每秒可以通过 100 个请求，也就是平均每个请求间隔 10ms。<br>因此，最终会每 10ms 打印一行数据。输出结果如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Output:</span></span><br><span class="line"><span class="comment">// 0 0</span></span><br><span class="line"><span class="comment">// 1 10ms</span></span><br><span class="line"><span class="comment">// 2 10ms</span></span><br><span class="line"><span class="comment">// 3 10ms</span></span><br><span class="line"><span class="comment">// 4 10ms</span></span><br><span class="line"><span class="comment">// 5 10ms</span></span><br><span class="line"><span class="comment">// 6 10ms</span></span><br><span class="line"><span class="comment">// 7 10ms</span></span><br><span class="line"><span class="comment">// 8 10ms</span></span><br><span class="line"><span class="comment">// 9 10ms</span></span><br></pre></td></tr></table></figure><h1 id="基本实现"><a class="markdownIt-Anchor" href="#基本实现"></a> 基本实现</h1><p>要实现以上每秒固定速率的目的，其实还是比较简单的。</p><p>在 ratelimit 的 New 函数中，传入的参数是每秒允许请求量 (RPS)。<br>我们可以很轻易的换算出每个请求之间的间隔：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limiter.perRequest = time.Second / time.Duration(rate)</span><br></pre></td></tr></table></figure><p>以上 <code>limiter.perRequest</code> 指的就是每个请求之间的间隔时间。</p><p>如下图，当请求 1 处理结束后, 我们记录下请求 1 的处理完成的时刻, 记为 <code>limiter.last</code>。<br>稍后请求 2 到来, 如果此刻的时间与 <code>limiter.last</code> 相比并没有达到 <code>perRequest</code> 的间隔大小，那么 sleep 一段时间即可。</p><p><img src="/img/token-bucket/wait-interval.png" alt="漏桶示例图"></p><p>对应 ratelimit 的实现代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sleepFor = t.perRequest - now.Sub(t.last)</span><br><span class="line"><span class="keyword">if</span> sleepFor &gt; <span class="number">0</span> &#123;</span><br><span class="line">t.clock.Sleep(sleepFor)</span><br><span class="line">t.last = now.Add(sleepFor)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.last = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="最大松弛量"><a class="markdownIt-Anchor" href="#最大松弛量"></a> 最大松弛量</h1><p>我们讲到，传统的 Leaky Bucket，每个请求的间隔是固定的，然而，在实际上的互联网应用中，流量经常是突发性的。对于这种情况，uber-go 对 Leaky Bucket 做了一些改良，引入了最大松弛量 (maxSlack) 的概念。</p><p>我们先理解下整体背景: 假如我们要求每秒限定 100 个请求，平均每个请求间隔 10ms。但是实际情况下，有些请求间隔比较长，有些请求间隔比较短。如下图所示：</p><p><img src="/img/token-bucket/3-requests.png" alt=""></p><p>请求 1 完成后，15ms 后，请求 2 才到来，可以对请求 2 立即处理。请求 2 完成后，5ms 后，请求 3 到来，这个时候距离上次请求还不足 10ms，因此还需要等待 5ms。</p><p>但是，对于这种情况，实际上三个请求一共消耗了 25ms 才完成，并不是预期的 20ms。在 uber-go 实现的 ratelimit 中，可以把之前间隔比较长的请求的时间，匀给后面的使用，保证每秒请求数 (RPS) 即可。</p><p>对于以上 case，因为请求 2 相当于多等了 5ms，我们可以把这 5ms 移给请求 3 使用。加上请求 3 本身就是 5ms 之后过来的，一共刚好 10ms，所以请求 3 无需等待，直接可以处理。此时三个请求也恰好一共是 20ms。<br>如下图所示：</p><p><img src="/img/token-bucket/maxslack.png" alt=""></p><p>在 ratelimit 的对应实现中很简单，是把每个请求多余出来的等待时间累加起来，以给后面的抵消使用。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t.sleepFor += t.perRequest - now.Sub(t.last)</span><br><span class="line"><span class="keyword">if</span> t.sleepFor &gt; <span class="number">0</span> &#123;</span><br><span class="line">  t.clock.Sleep(t.sleepFor)</span><br><span class="line">  t.last = now.Add(t.sleepFor)</span><br><span class="line">  t.sleepFor = <span class="number">0</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  t.last = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里跟上述代码不同的是，这里是 <code>+=</code>。而同时 <code>t.perRequest - now.Sub(t.last)</code> 是可能为负值的，负值代表请求间隔时间比预期的长。</p><p>当 <code>t.sleepFor &gt; 0</code>，代表此前的请求多余出来的时间，无法完全抵消此次的所需量，因此需要 sleep 相应时间, 同时将 <code>t.sleepFor</code> 置为 0。</p><p>当 <code>t.sleepFor &lt; 0</code>，说明此次请求间隔大于预期间隔，将多出来的时间累加到 <code>t.sleepFor</code> 即可。</p><p>但是，对于某种情况，请求 1 完成后，请求 2 过了很久到达 (好几个小时都有可能)，那么此时对于请求 2 的请求间隔 <code>now.Sub(t.last)</code>，会非常大。以至于即使后面大量请求瞬时到达，也无法抵消完这个时间。那这样就失去了限流的意义。</p><p>为了防止这种情况，ratelimit 就引入了最大松弛量 (maxSlack) 的概念, 该值为负值，表示允许抵消的最长时间，防止以上情况的出现。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> t.sleepFor &lt; t.maxSlack &#123;</span><br><span class="line">  t.sleepFor = t.maxSlack</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ratelimit 中 maxSlack 的值为 <code>-10 * time.Second / time.Duration(rate)</code>, 是十个请求的间隔大小。我们也可以理解为 ratelimit 允许的最大瞬时请求为 10。</p><h1 id="高级用法"><a class="markdownIt-Anchor" href="#高级用法"></a> 高级用法</h1><p>ratelimit 的 New 函数，除了可以配置每秒请求数 (QPS)， 其实还提供了一套可选配置项 Option。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(rate <span class="keyword">int</span>, opts ...Option)</span> <span class="title">Limiter</span></span></span><br></pre></td></tr></table></figure><p>Option 的类型为 <code>type Option func(l *limiter)</code>, 也就是说我们可以提供一些这样类型的函数，作为 Option，传给 ratelimit, 定制相关需求。</p><p>但实际上，自定义 Option 的用处比较小，因为 <code>limiter</code> 结构体本身就是个私有类型，我们并不能拿它做任何事情。</p><p>我们只需要了解 ratelimit 目前提供的两个配置项即可：</p><h2 id="withoutslack"><a class="markdownIt-Anchor" href="#withoutslack"></a> <code>WithoutSlack</code></h2><p>我们上文讲到 ratelimit 中引入了最大松弛量的概念，而且默认的最大松弛量为 10 个请求的间隔时间。</p><p>但是确实会有这样需求场景，需要严格的限制请求的固定间隔。那么我们就可以利用 WithoutSlack 来取消松弛量的影响。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limiter := ratelimit.New(<span class="number">100</span>, ratelimit.WithoutSlack)</span><br></pre></td></tr></table></figure><h2 id="withclockclock-clock"><a class="markdownIt-Anchor" href="#withclockclock-clock"></a> <code>WithClock(clock Clock)</code></h2><p>我们上文讲到，ratelimit 的实现时，会计算当前时间与上次请求时间的差值，并 sleep 相应时间。<br>在 ratelimit 基于 go 标准库的 time 实现时间相关计算。如果有精度更高或者特殊需求的计时场景，可以用 WithClock 来替换默认时钟。</p><p>通过该方法，只要实现了 Clock 的 interface，就可以自定义时钟了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Clock <span class="keyword">interface</span> &#123;</span><br><span class="line">Now() time.Time</span><br><span class="line">Sleep(time.Duration)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clock &amp;= MyClock&#123;&#125;</span><br><span class="line">limiter := ratelimit.New(<span class="number">100</span>, ratelimit.WithClock(clock))</span><br></pre></td></tr></table></figure><h1 id="相关文章"><a class="markdownIt-Anchor" href="#相关文章"></a> 相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">Golang 限流器 time/rate 实现剖析</a></li><li><a href="https://www.cyhone.com/articles/usage-of-golang-rate/">Golang 限流器 time/rate 使用介绍</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;uber 在 Github 上开源了一套用于服务限流的 go 语言库 &lt;a href=&quot;https://github.com/uber-go/ratelimit/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ratelimit&lt;/a&gt;, 该组件基于 Leaky Bucket(漏桶) 实现。&lt;/p&gt;
&lt;p&gt;我在之前写过 &lt;a href=&quot;https://www.cyhone.com/articles/analisys-of-golang-rate/&quot;&gt;《Golang 限流器 time/rate 实现剖析》&lt;/a&gt;，讲了 Golang 标准库中提供的基于 Token Bucket 实现限流组件的 &lt;code&gt;time/rate&lt;/code&gt; 原理，同时也讲了限流的一些背景。&lt;/p&gt;
&lt;p&gt;相比于 TokenBucket，只要桶内还有剩余令牌，调用方就可以一直消费。而 Leaky Bucket 相对来说比较严格，调用方只能严格按照这个间隔顺序进行消费调用。(实际上，uber-go 对这个限制也做了一些优化，具体可以看下文详解)&lt;/p&gt;
&lt;p&gt;还是老规矩，在正式讲其实现之前，我们先看下 ratelimit 的使用方法。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Golang 限流器 time/rate 实现剖析</title>
    <link href="http://www.cyhone.com/articles/analisys-of-golang-rate/"/>
    <id>http://www.cyhone.com/articles/analisys-of-golang-rate/</id>
    <published>2019-11-05T05:35:19.000Z</published>
    <updated>2019-12-10T05:07:50.063Z</updated>
    
    <content type="html"><![CDATA[<p>限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章 <a href="https://www.cyhone.com/articles/usage-of-golang-rate/">《Golang 限流器 time/rate 使用介绍》</a> 简单介绍了 time/rate 的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。</p><p>上一篇文章讲到，time/rate 是基于 Token Bucket(令牌桶) 算法实现的限流。本文将会基于源码，深入剖析下 Golang 是如何实现 Token Bucket 的。其代码也非常简洁，去除注释后，也就 200 行左右的代码量。</p><p>同时，我也提供了 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/go/x/time" target="_blank" rel="noopener">time/rate 注释版</a>，辅助大家理解该组件的实现。</p><a id="more"></a><h1 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h1><p>简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。<br>而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。</p><p>一般介绍 Token Bucket 的时候，都会有一张这样的原理图：<br><img src="/img/token-bucket/token-bucket.jpg" alt="Token Bucket 原理图"></p><p>从这个图中看起来，似乎令牌桶实现应该是这样的：</p><blockquote><p>有一个 Timer 和一个 BlockingQueue。Timer 固定的往 BlockingQueue 中放 token。用户则从 BlockingQueue 中取数据。</p></blockquote><p>这固然是 Token Bucket 的一种实现方式，这么做也非常直观，但是效率太低了：我们需要不仅多维护一个 Timer 和 BlockingQueue，而且还耗费了一些不必要的内存。</p><p>在 Golang 的 <code>timer/rate</code> 中的实现, 并没有单独维护一个 Timer，而是采用了 lazyload 的方式，直到每次消费之前才根据时间差更新 Token 数目，而且也不是用 BlockingQueue 来存放 Token，而是仅仅通过计数的方式。</p><h1 id="token-的生成和消费"><a class="markdownIt-Anchor" href="#token-的生成和消费"></a> Token 的生成和消费</h1><p>我们在 <a href="https://www.cyhone.com/articles/usage-of-golang-rate/">上一篇文章</a> 中讲到，Token 的消费方式有三种。但其实在内部实现，最终三种消费方式都调用了 reserveN 函数来生成和消费 Token。</p><p>我们看下 reserveN 函数的具体实现，整个过程非常简单。在正式讲之前，我们先了解一个简单的概念：</p><p>在 <code>time/rate</code> 中，<code>NewLimiter</code> 的第一个参数是速率 limit，代表了一秒钟可以产生多少 Token。<br>那么简单换算一下，我们就可以知道一个 Token 的生成间隔是多少。</p><p>有了这个生成间隔，我们就可以轻易地得到两个数据：<br><strong>1. 生成 N 个新的 Token 一共需要多久。</strong><code>time/rate</code> 中对应的实现函数为 <code>durationFromTokens</code>。<br><strong>2. 给定一段时长，这段时间一共可以生成多少个 Token。</strong><code>time/rate</code> 中对应的实现函数为 <code>tokensFromDuration</code>。</p><p>那么，有了这些转换函数，整个过程就很清晰了，如下：</p><ol><li><p>计算从上次取 Token 的时间到当前时刻，期间一共新产生了多少 Token：<br>我们只在取 Token 之前生成新的 Token，也就意味着每次取 Token 的间隔，实际上也是生成 Token 的间隔。我们可以利用 <code>tokensFromDuration</code>, 轻易的算出这段时间一共产生 Token 的数目。<br>那么，当前 Token 数目 = 新产生的 Token 数目 + 之前剩余的 Token 数目 - 要消费的 Token 数目。</p></li><li><p>如果消费后剩余 Token 数目大于零，说明此时 Token 桶内仍不为空，此时 Token 充足，无需调用侧等待。<br>如果 Token 数目小于零，则需等待一段时间。<br>那么这个时候，我们可以利用 <code>durationFromTokens</code> 将当前负值的 Token 数转化为需要等待的时间。</p></li><li><p>将需要等待的时间等相关结果返回给调用方。</p></li></ol><p>从上面可以看出，其实整个过程就是利用了 **Token 数可以和时间相互转化 ** 的原理。而如果 Token 数为负，则需要等待相应时间即可。</p><p>** 注意：** 如果当消费时，Token 桶中的 Token 数目已经为负值了，依然可以按照上述流程进行消费。随着负值越来越小，等待的时间将会越来越长。<br>从结果来看，这个行为跟用 Timer+BlockQueue 实现是一样的。</p><p>此外，整个过程为了保证线程安全，更新令牌桶相关数据时都用了 mutex 加锁。</p><p>我们模拟下请求与 Token 数变化的关系：</p><ol><li>当某一时间，桶内 Token 数为 3, 此时 A 线程请求 5 个 Token。那么此时桶内 Token 不足，因此 A 线程需要等待 2 个 Token 的时间。<br>且此时桶内 Token 数变为 - 2。</li><li>同时，B 线程请求 4 个 Token，此时桶内 Token 数为 - 2，因此 B 线程需要等待 2+4=6 个 Token 的时间，且此时桶内 Token 数变为 - 6。</li></ol><p>对于 Allow 函数实现时，只要判断需要等待的时间是否为 0 即可，如果大于 0 说明需要等待，则返回 False，反之返回 True。</p><p>对于 Wait 函数，直接 <code>t := time.NewTimer(delay)</code>，等待对应的时间即可。</p><h1 id="float-精度问题"><a class="markdownIt-Anchor" href="#float-精度问题"></a> float 精度问题</h1><p>从上面原理讲述可以看出，在 Token 和时间的相互转化函数 <code>durationFromTokens</code> 和 <code>tokensFromDuration</code> 中，涉及到 float64 的乘除运算。<br>一谈到 float 的乘除，我们就需要小心精度问题了。</p><p>而 Golang 在这里也踩了坑，以下是 <code>tokensFromDuration</code> 最初的实现版本</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(limit Limit)</span> <span class="title">tokensFromDuration</span><span class="params">(d time.Duration)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> d.Seconds() * <span class="keyword">float64</span>(limit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个操作看起来一点问题都没：每秒生成的 Token 数乘于秒数。<br>然而，这里的问题在于，<code>d.Seconds()</code> 已经是小数了。两个小数相乘，会带来精度的损失。</p><p>所以就有了这个 issue:<a href="https://github.com/golang/go/issues/34861" target="_blank" rel="noopener">golang.org/issues/34861</a>。</p><p>修改后新的版本如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(limit Limit)</span> <span class="title">tokensFromDuration</span><span class="params">(d time.Duration)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line">sec := <span class="keyword">float64</span>(d/time.Second) * <span class="keyword">float64</span>(limit)</span><br><span class="line">nsec := <span class="keyword">float64</span>(d%time.Second) * <span class="keyword">float64</span>(limit)</span><br><span class="line"><span class="keyword">return</span> sec + nsec/<span class="number">1e9</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>time.Duration</code> 是 <code>int64</code> 的别名，代表纳秒。分别求出秒的整数部分和小数部分，进行相乘后再相加，这样可以得到最精确的精度。</p><h1 id="数值溢出问题"><a class="markdownIt-Anchor" href="#数值溢出问题"></a> 数值溢出问题</h1><p>我们讲 reserveN 函数的具体实现时，第一步就是计算从当前时间到上次取 Token 的时刻，期间一共新产生了多少 Token，同时也可得出当前的 Token 是多少。</p><p>我最开始的理解是，直接可以这么做：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// elapsed 表示过去的时间差</span></span><br><span class="line">elapsed := now.Sub(lim.last)</span><br><span class="line"><span class="comment">// delta 表示这段时间一共新产生了多少 Token</span></span><br><span class="line">delta = tokensFromDuration(now.Sub(lim.last))</span><br><span class="line"></span><br><span class="line">tokens := lim.tokens + delta</span><br><span class="line"><span class="keyword">if</span>(token&gt; lim.burst)&#123;</span><br><span class="line">token = lim.burst</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，<code>lim.tokens</code> 是当前剩余的 Token，<code>lim.last</code> 是上次取 token 的时刻。<code>lim.burst</code> 是 Token 桶的大小。<br>使用 tokensFromDuration 计算出新生成了多少 Token，累加起来后，不能超过桶的容量即可。</p><p>这么做看起来也没什么问题，然而并不是这样。</p><p>在 <code>time/rate</code> 里面是这么做的，如下代码所示：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">maxElapsed := lim.limit.durationFromTokens(<span class="keyword">float64</span>(lim.burst) - lim.tokens)</span><br><span class="line">elapsed := now.Sub(last)</span><br><span class="line"><span class="keyword">if</span> elapsed &gt; maxElapsed &#123;</span><br><span class="line">elapsed = maxElapsed</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">delta := lim.limit.tokensFromDuration(elapsed)</span><br><span class="line"></span><br><span class="line">tokens := lim.tokens + delta</span><br><span class="line"><span class="keyword">if</span> burst := <span class="keyword">float64</span>(lim.burst); tokens &gt; burst &#123;</span><br><span class="line">tokens = burst</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与我们最开始的代码不一样的是，它没有直接用 <code>now.Sub(lim.last)</code> 来转化为对应的 Token 数，而是<br>先用 <code>lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)</code>，计算把桶填满的时间 maxElapsed。<br>取 elapsed 和 maxElapsed 的最小值。</p><p>这么做算出的结果肯定是正确的，但是这么做相比于我们的做法，好处在哪里？</p><p>对于我们的代码，当 last 非常小的时候（或者当其为初始值 0 的时候），此时 <code>now.Sub(lim.last)</code> 的值就会非常大，如果 <code>lim.limit</code> 即每秒生成的 Token 数目也非常大时，直接将二者进行乘法运算，** 结果有可能会溢出。**</p><p>因此，<code>time/rate</code> 先计算了把桶填满的时间，将其作为时间差值的上限，这样就规避了溢出的问题。</p><h1 id="token-的归还"><a class="markdownIt-Anchor" href="#token-的归还"></a> Token 的归还</h1><p>而对于 Reserve 函数，返回的结果中，我们可以通过 <code>Reservation.Delay()</code> 函数，得到需要等待时间。<br>同时调用方可以根据返回条件和现有情况，可以调用 <code>Reservation.Cancel()</code> 函数，取消此次消费。<br>当调用 <code>Cancel()</code> 函数时，消费的 Token 数将会尽可能归还给 Token 桶。</p><p>此外，我们在 <a href="https://www.cyhone.com/articles/usage-of-golang-rate/">上一篇文章</a> 中讲到，Wait 函数可以通过 Context 进行取消或者超时等，<br>当通过 Context 进行取消或超时时，此时消费的 Token 数也会归还给 Token 桶。</p><p>然而，归还 Token 的时候，并不是简单的将 Token 数直接累加到现有 Token 桶的数目上，这里还有一些注意点：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">restoreTokens := <span class="keyword">float64</span>(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct))</span><br><span class="line"><span class="keyword">if</span> restoreTokens &lt;= <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码就是计算需要归还多少的 Token。其中：</p><ol><li><code>r.tokens</code> 指的是本次消费的 Token 数</li><li><code>r.timeToAct</code> 指的是 Token 桶可以满足本次消费数目的时刻，也就是消费的时刻 + 等待的时长。</li><li><code>r.lim.lastEvent</code> 指的是最近一次消费的 timeToAct 值</li></ol><p>其中：<code>r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct))</code> 指的是，从该次消费到当前时间，一共又新消费了多少 Token 数目。</p><p>根据代码来看，要归还的 Token 要是该次消费的 Token 减去新消费的 Token。<br>不过这里我还没有想明白，为什么归还的时候，要减去新消费数目。</p><p>按照我的理解，直接归还全部 Token 数目，这样对于下一次消费是无感知影响的。这块的具体原因还需要进一步探索。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>Token Bucket 其实非常适合互联网突发式请求的场景，其请求 Token 时并不是严格的限制为固定的速率，而是中间有一个桶作为缓冲。<br>只要桶中还有 Token，请求就还可以一直进行。当突发量激增到一定程度，则才会按照预定速率进行消费。</p><p>此外在维基百科中，也提到了分层 Token Bucket(HTB) 作为传统 Token Bucket 的进一步优化，Linux 内核中也用它进行流量控制。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">Wiki: Token bucket</a></li></ul><h1 id="相关文章"><a class="markdownIt-Anchor" href="#相关文章"></a> 相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/usage-of-golang-rate/">Golang 限流器 time/rate 使用介绍</a></li><li><a href="https://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/">uber-go 漏桶限流器使用与原理分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章 &lt;a href=&quot;https://www.cyhone.com/articles/usage-of-golang-rate/&quot;&gt;《Golang 限流器 time/rate 使用介绍》&lt;/a&gt; 简单介绍了 time/rate 的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。&lt;/p&gt;
&lt;p&gt;上一篇文章讲到，time/rate 是基于 Token Bucket(令牌桶) 算法实现的限流。本文将会基于源码，深入剖析下 Golang 是如何实现 Token Bucket 的。其代码也非常简洁，去除注释后，也就 200 行左右的代码量。&lt;/p&gt;
&lt;p&gt;同时，我也提供了 &lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/go/x/time&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;time/rate 注释版&lt;/a&gt;，辅助大家理解该组件的实现。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Golang 限流器 time/rate 使用介绍</title>
    <link href="http://www.cyhone.com/articles/usage-of-golang-rate/"/>
    <id>http://www.cyhone.com/articles/usage-of-golang-rate/</id>
    <published>2019-11-02T12:21:54.000Z</published>
    <updated>2019-12-10T05:07:50.067Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本主题为系列文章，分上下两篇。本文主要介绍 <code>time/rate</code> 的具体使用方法，另外一篇文章 <a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">《Golang 限流器 time/rate 实现剖析》</a> 则着重介绍其内部实现原理。</p></blockquote><p>限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。<br>限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket 等。</p><p>其实 golang 标准库中就自带了限流算法的实现，即 <code>golang.org/x/time/rate</code>。<br>该限流器是基于 Token Bucket(令牌桶) 实现的。</p><p>简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。<br>而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。</p><a id="more"></a><p>本文则主要集中介绍下该组件的具体使用方法：</p><h1 id="构造一个限流器"><a class="markdownIt-Anchor" href="#构造一个限流器"></a> 构造一个限流器</h1><p>我们可以使用以下方法构造一个限流器对象：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">limiter := NewLimiter(<span class="number">10</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>这里有两个参数：</p><ol><li>第一个参数是 <code>r Limit</code>。代表每秒可以向 Token 桶中产生多少 token。Limit 实际上是 float64 的别名。</li><li>第二个参数是 <code>b int</code>。b 代表 Token 桶的容量大小。</li></ol><p>那么，对于以上例子来说，其构造出的限流器含义为，其令牌桶大小为 1, 以每秒 10 个 Token 的速率向桶中放置 Token。</p><p>除了直接指定每秒产生的 Token 个数外，还可以用 Every 方法来指定向 Token 桶中放置 Token 的间隔，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">limit := Every(<span class="number">100</span> * time.Millisecond);</span><br><span class="line">limiter := NewLimiter(limit, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>以上就表示每 100ms 往桶中放一个 Token。本质上也就是一秒钟产生 10 个。</p><p>Limiter 提供了三类方法供用户消费 Token，用户可以每次消费一个 Token，也可以一次性消费多个 Token。<br>而每种方法代表了当 Token 不足时，各自不同的对应手段。</p><h1 id="waitwaitn"><a class="markdownIt-Anchor" href="#waitwaitn"></a> Wait/WaitN</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Wait</span><span class="params">(ctx context.Context)</span> <span class="params">(err error)</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">WaitN</span><span class="params">(ctx context.Context, n <span class="keyword">int</span>)</span> <span class="params">(err error)</span></span></span><br></pre></td></tr></table></figure><p>Wait 实际上就是 <code>WaitN(ctx,1)</code>。</p><p>当使用 Wait 方法消费 Token 时，如果此时桶内 Token 数组不足 (小于 N)，那么 Wait 方法将会阻塞一段时间，直至 Token 满足条件。如果充足则直接返回。</p><p>这里可以看到，Wait 方法有一个 context 参数。<br>我们可以设置 context 的 Deadline 或者 Timeout，来决定此次 Wait 的最长时间。</p><h1 id="allowallown"><a class="markdownIt-Anchor" href="#allowallown"></a> Allow/AllowN</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Allow</span><span class="params">()</span> <span class="title">bool</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">AllowN</span><span class="params">(now time.Time, n <span class="keyword">int</span>)</span> <span class="title">bool</span></span></span><br></pre></td></tr></table></figure><p>Allow 实际上就是 <code>AllowN(time.Now(),1)</code>。</p><p>AllowN 方法表示，截止到某一时刻，目前桶中数目是否至少为 n 个，满足则返回 true，同时从桶中消费 n 个 token。<br>反之返回不消费 Token，false。</p><p>通常对应这样的线上场景，如果请求速率过快，就直接丢到某些请求。</p><h1 id="reservereserven"><a class="markdownIt-Anchor" href="#reservereserven"></a> Reserve/ReserveN</h1><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Reserve</span><span class="params">()</span> *<span class="title">Reservation</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">ReserveN</span><span class="params">(now time.Time, n <span class="keyword">int</span>)</span> *<span class="title">Reservation</span></span></span><br></pre></td></tr></table></figure><p>Reserve 相当于 <code>ReserveN(time.Now(), 1)</code>。</p><p>ReserveN 的用法就相对来说复杂一些，当调用完成后，无论 Token 是否充足，都会返回一个 Reservation * 对象。</p><p>你可以调用该对象的 Delay() 方法，该方法返回了需要等待的时间。如果等待时间为 0，则说明不用等待。<br>必须等到等待时间之后，才能进行接下来的工作。</p><p>或者，如果不想等待，可以调用 Cancel() 方法，该方法会将 Token 归还。</p><p>举一个简单的例子，我们可以这么使用 Reserve 方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">r := lim.Reserve()</span><br><span class="line">f !r.OK() &#123;</span><br><span class="line">    <span class="comment">// Not allowed to act! Did you remember to set lim.burst to be &gt; 0 ?</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(r.Delay())</span><br><span class="line">Act() <span class="comment">// 执行相关逻辑</span></span><br></pre></td></tr></table></figure><h1 id="动态调整速率"><a class="markdownIt-Anchor" href="#动态调整速率"></a> 动态调整速率</h1><p>Limiter 支持可以调整速率和桶大小：</p><ol><li>SetLimit(Limit) 改变放入 Token 的速率</li><li>SetBurst(int) 改变 Token 桶大小</li></ol><p>有了这两个方法，可以根据现有环境和条件，根据我们的需求，动态的改变 Token 桶大小和速率。</p><h1 id="相关文章"><a class="markdownIt-Anchor" href="#相关文章"></a> 相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">Golang 限流器 time/rate 实现剖析</a></li><li><a href="https://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/">uber-go 漏桶限流器使用与原理分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本主题为系列文章，分上下两篇。本文主要介绍 &lt;code&gt;time/rate&lt;/code&gt; 的具体使用方法，另外一篇文章 &lt;a href=&quot;https://www.cyhone.com/articles/analisys-of-golang-rate/&quot;&gt;《Golang 限流器 time/rate 实现剖析》&lt;/a&gt; 则着重介绍其内部实现原理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。&lt;br&gt;
限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket 等。&lt;/p&gt;
&lt;p&gt;其实 golang 标准库中就自带了限流算法的实现，即 &lt;code&gt;golang.org/x/time/rate&lt;/code&gt;。&lt;br&gt;
该限流器是基于 Token Bucket(令牌桶) 实现的。&lt;/p&gt;
&lt;p&gt;简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。&lt;br&gt;
而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>微信 libco 协程库源码分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-libco/"/>
    <id>http://www.cyhone.com/articles/analysis-of-libco/</id>
    <published>2019-10-08T09:58:26.000Z</published>
    <updated>2020-01-14T11:40:26.563Z</updated>
    
    <content type="html"><![CDATA[<p>libco 是微信后台开发和使用的协程库，同时也是极少数的直接将 C/C++ 协程运用到如此大规模的生产环境中的案例。</p><p>在 <a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">《云风 coroutine 协程库源码分析》</a> 中，介绍了有栈协程的实现原理。相比 coroutine，libco 在性能上号称可以调度千万级协程。 从使用上来说，不仅提供了一套类 pthread 的协程通信机制，同时可以零改造地将三方库的阻塞 IO 调用协程异步化。<br>本文将从源码角度着重分析 libco 的高效之道。</p><p>在正式阅读本文之前，如果对有栈协程的实现原理不是特别了解，建议提前阅读 <a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">《云风 coroutine 协程库源码分析》</a>。</p><p>同时，我也提供了 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/libco" target="_blank" rel="noopener">libco 注释版</a>，用以辅助理解 libco 的源码</p><a id="more"></a><h1 id="libco-和-coroutine-的基本差异"><a class="markdownIt-Anchor" href="#libco-和-coroutine-的基本差异"></a> libco 和 coroutine 的基本差异</h1><p>相比于 coroutine 协程库, libco 整体更成熟，性能更高，使用上也更加方便。主要体现在以下几个方面：</p><ol><li>协程上下文切换性能更好</li><li>协程在 IO 阻塞时可自动切换，包括 gethostname、mysqlclient 等。</li><li>协程可以嵌套创建，即一个协程内部可以再创建一个协程。</li><li>提供了超时管理，以及一套类 pthread 的接口，用于协程间通信。</li></ol><p>关于 libco 的如何实现有栈协程的切换，co_resume、co_yield 是如何实现的。此部分内容已在 <a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">云风 coroutine 协程库源码分析</a> 中进行了详细的剖析。各个协程库这里的实现大同小异，本文就不再重复讲述此部分内容了。</p><p>不过，libco 在协程的栈空间上有不一样的地方：</p><ol><li>共享栈是可选的，如果想要使用共享栈模式，则需要用户自行创建栈空间，在 co_create 时传递给 libco。(参数 <code>stCoRoutineAttr_t* attr</code>)</li><li>支持协程使用独立的栈空间，不使用共享栈模式。(默认每个协程有 128k 的栈空间)</li><li>libco 默认是独立的栈空间，不使用共享栈。</li></ol><p>除此之外，出于性能考虑，libco 不使用 ucontext 进行用户态上下文的切换，而是自行写了一套汇编来进行上下文切换。</p><p>另外，libco 利用 <code>co_create</code> 创建的协程, 需要自行调用 <code>co_release</code> 进行释放。这里和 coroutine 不太一样。</p><h1 id="协程上下文切换性能更好"><a class="markdownIt-Anchor" href="#协程上下文切换性能更好"></a> 协程上下文切换性能更好</h1><p>我们之前提到，云风的 coroutine 库使用 ucontext 来实现用户态的上下文切换，这也是实现协程的关键。</p><p>而 <strong>libco 基于性能优化的考虑，没有使用 ucontext</strong>，而是自行编写了一套汇编来处理上下文的切换, 具体代码在 <a href="https://github.com/Tencent/libco/blob/master/coctx_swap.S" target="_blank" rel="noopener">coctx_swap.S</a>。</p><p>libco 的上下文切换大体只保存和交换了两类东西：</p><ol><li>寄存器：函数参数类寄存器、函数返回值、数据存储类寄存器等。</li><li>栈：rsp 栈顶指针</li></ol><p>相比于 ucontext，缺少了浮点数上下文和 sigmask(信号屏蔽掩码)。具体可对比 <a href="https://github.com/lattera/glibc/blob/master/sysdeps/unix/sysv/linux/i386/getcontext.S" target="_blank" rel="noopener">glibc 的相关源码</a>。</p><ul><li>取消 sigmask 是因为 sigmask 会引发一次 syscall，在性能上会所损耗。</li><li>取消浮点数上下文，主要是在服务端编程几乎用不到浮点数计算。</li></ul><p>此外，libco 的上下文切换只支持 x86，不支持其他架构的 cpu，这是因为在服务端也几乎都是 x86 架构的，不用太考虑 CPU 的通用性。</p><p>据 <a href="https://www.zhihu.com/question/52193579/answer/156692295" target="_blank" rel="noopener">知乎网友的实验</a> 证明：libco 的上下文切换效率大致是 ucontext 的 3.6 倍。</p><p>总结来说，libco 牺牲了通用性，把运营环境中用不到的寄存器拷贝去掉，对代码进行了极致优化，但是换取到了很高的性能。</p><h1 id="协程在-io-阻塞时可自动切换"><a class="markdownIt-Anchor" href="#协程在-io-阻塞时可自动切换"></a> 协程在 IO 阻塞时可自动切换</h1><p>我们希望的是，当协程中遇到阻塞 IO 的调用时，协程可以自行 yield 出去，等到调用结束，可以再 resume 回来，这些流程不用用户关心。</p><p>** 然而难点在于：** 对于自己代码中的阻塞类调用尚且容易改造，可以把它改成非阻塞 IO，然后框架内部进行 yield 和 resume。但是大量三方库也存在着阻塞 IO 调用，如知名的 mysqlclient 就是阻塞 IO，对于此类的 IO 调用，我们无法直接改造，不便于和我们现有的协程框架进行配合。</p><p>然而，libco 的协程不仅可以做到 IO 阻塞协程的自动切换，甚至包括三方库的阻塞 IO 调用都可以零改造的自动切换。</p><p>libco 巧妙运用了 Linux 的 hook 技术，同时配合了 epoll 事件循环，完美的完成了阻塞 IO 的协程化改造。</p><p>所谓系统函数 hook，简单来说，就是替换原有的系统函数，例如 read、write 等，替换为自己的逻辑。所有关于 hook 系统函数的代码都在 <code>co_hook_sys_call.cpp</code> 中可以看到。</p><p>在分析具体代码之前，有个点需要先注意下：**libco 的 hook 逻辑用于 client 行为的阻塞类 IO 调用 **。</p><p>client 行为指的是，本地主动 connect 一个远程的服务，使用的时候一般先往 socket 中 write 数据，然后再 read 回包这种形式。</p><h2 id="read-函数的-hook-流程"><a class="markdownIt-Anchor" href="#read-函数的-hook-流程"></a> read 函数的 hook 流程</h2><p>我们以 read 函数为例，看下都做了什么：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> read(<span class="keyword">int</span> fd, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte)</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span> <span class="title">pf</span> = &#123;</span><span class="number">0</span>&#125;;</span><br><span class="line">pf.fd = fd;</span><br><span class="line">pf.events = (POLLIN | POLLERR | POLLHUP);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> pollret = poll(&amp;pf,<span class="number">1</span>,timeout);</span><br><span class="line"></span><br><span class="line"><span class="keyword">ssize_t</span> readret = g_sys_read_func(fd,(<span class="keyword">char</span>*)buf ,nbyte );</span><br><span class="line"><span class="keyword">return</span> readret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码对原有代码进行了简略，只保留了最核心的 hook 逻辑。</p><p>注意：这里 poll 函数实际上也是被 hook 过的函数，在这个函数中，最终会交由 <code>co_poll_inner</code> 函数处理。</p><p><code>co_poll_inner</code> 函数主要有三个作用：</p><ol><li>将 poll 的相关事件转换为 epoll 相关事件，并注册到当前线程的 epoll 中。</li><li>注册超时事件，到当前的 epoll 中</li><li>调用 co_yield_ct, 让出该协程。</li></ol><p>可以看到，调用 poll 函数之后，相关事件注册到了 EventLoop 中后，该协程就 yield 走了。</p><p>那么，什么时候，协程会再 resume 回来呢？<br>答案是：<strong>当 epoll 相关事件触发或者超时触发时</strong>，会再次 resume 该协程，处理接下来的流程。</p><p>协程 resume 之后，会接着处理 poll 之后的逻辑，也就是调用了 <code>g_sys_read_func</code>。这个函数就是真实的 linux 的 read 函数。</p><p>libco 使用 dlsym 函数获取了系统函数, 如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">ssize_t</span> <span class="params">(*<span class="keyword">read_pfn_t</span>)</span><span class="params">(<span class="keyword">int</span> fildes, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte)</span></span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">read_pfn_t</span> g_sys_read_func = (<span class="keyword">read_pfn_t</span>)dlsym(RTLD_NEXT,<span class="string">"read"</span>);</span><br></pre></td></tr></table></figure><p>这个逻辑就非常巧妙了：</p><ul><li>从内部来看，本质上是个异步流程，在 EventLoop 中注册相关事件，当事件触发时就执行接下来的处理函数。</li><li>从外部来看，调用方使用的时候函数行为和普通的阻塞函数基本一样，无需关系底层的注册事件、yield 等过程。</li></ul><p>这个就是 libco 的巧妙之处了，通过 hook 系统函数的方式，几乎无感知的改造了阻塞 IO 调用。</p><p>此外，libco 也 hook 了系统的 socket 函数。在 libco 实现的 socket 函数中，会将 fd 变成非阻塞的 (O_NONBLOCK)。</p><p>那么，为什么 libco 连 mysql_client 都可以一并协程化改造呢？</p><p>这是因为 mysql_client 里面的具体网络 IO 实现，也是用的 Linux 的那些系统函数 connect、read、write 这些函数。<br>所以，libco 只用 hook 十几个 socket 相关的 api，就可以将用到的三方库中的 IO 调用也一起协程化改造了。</p><h2 id="read-的超时处理"><a class="markdownIt-Anchor" href="#read-的超时处理"></a> read 的超时处理</h2><p>libco 的 read 函数和普通的阻塞 IO 中的 read 函数，行为上稍微有一点不一样。</p><p>普通的 read 函数，如果一直没有消息可读，则会一直阻塞。<br>但是 libco 中的 read 函数，如果 1 秒钟之内 socket 依然不可读，则就认为 read 失败，返回 - 1。这也是 read 中注册超时事件的原因。</p><p>在 client 侧网络的 IO 调用里面，一般行为都是，write 请求，然后 read 回包。<br>所以一定是会引入一个超时判断，判断该次调用是否超时。<br>同时，还要保证要保证 read 的行为和语义，与原有的系统函数保持一致。毕竟 hook 的目标是 mysql_client 这种三方库。<br>所以这个超时只能做在 read 内部，把超时当成一次 read 失败处理。</p><p>这样即能保证 read 原有行为，也能保证 read 不会一直阻塞。</p><p>但这里有个问题：libco 把 read 的超时时间硬编码为 1s，那么所有被 hook 的阻塞 IO 的 read，一旦超过 1s，就会被认为失败。<br>但对于某些特殊场景，会存在一些耗时请求，server 端的处理时间确实有可能会超过 1s。<br>对于这种情况，libco 似乎也没有提供一个自定义超时时间的办法。</p><h2 id="stcoepoll_t-结构体分析"><a class="markdownIt-Anchor" href="#stcoepoll_t-结构体分析"></a> stCoEpoll_t 结构体分析</h2><p>libco 的事件循环同时支持 epoll 和 kqueue，libco 会在每个线程维护一个 <code>stCoEpoll_t</code> 对象。<br><code>stCoEpoll_t</code> 结构体中维护了事件循环需要的数据。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stCoEpoll_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">int</span> iEpollFd;</span><br><span class="line">co_epoll_res *result;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeout_t</span> *<span class="title">pTimeout</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeoutItemLink_t</span> *<span class="title">pstTimeoutList</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeoutItemLink_t</span> *<span class="title">pstActiveList</span>;</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>iEpollFd：epoll 或者 kqueue 的 fd</li><li>result: 当前已触发的事件，给 epoll 或 kevent 用。如果是 epoll 的话，则是 epoll_wait 的已触发事件</li><li>pTimeout：时间轮定时管理器。记录了所有的定时事件</li><li>pstTimeoutList：本轮超时的事件</li><li>pstActiveList: 本轮触发的事件。</li></ol><p>此外，libco 使用了时间轮来做超时管理，关于时间轮的原理分析网上比较多，这块也不是 libco 最核心的东西，就不在本文讨论了。</p><h1 id="协程可以嵌套创建"><a class="markdownIt-Anchor" href="#协程可以嵌套创建"></a> 协程可以嵌套创建</h1><p>libco 的协程可以嵌套创建，协程内部可以创建一个新的协程。这里其实没有什么黑科技，只不过云风 coroutine 中不能实现协程嵌套创建，所以在这里单独讲下。<br>libco 使用了一个栈维护协程调用过程。<br>我们模拟下这个调用栈的运行过程, 如下图所示：<br><img src="/img/libco/co_process_stack.png" alt="协程调用栈"></p><p>图中绿色方块代表栈顶，同时也是当前正在运行的协程。</p><ol><li>当在主协程中 co_resume 到 A 协程时，当前运行的协程变更为 A，同时协程 A 入栈。</li><li>A 协程中 co_resume 到 B 协程，当前运行的协程变更为 B，同时协程 B 入栈。</li><li>协程 B 中调用 co_yield_ct。协程 B 出栈，同时当前协程切换到协程 A。</li><li>协程 A 中调用 co_yield_ct。协程 B 出栈，同时当前协程切换到主协程。</li></ol><p>libco 的协程调用栈维护 stCoRoutineEnv_t 结构体中，如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stCoRoutineEnv_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">stCoRoutine_t *pCallStack[<span class="number">128</span>];</span><br><span class="line"><span class="keyword">int</span> iCallStackSize;</span><br><span class="line">stCoEpoll_t *pEpoll;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中 pCallStack 即是协程的调用栈，从参数可以看出，libco 只能支持 128 层协程的嵌套调用，这个深度已经足够使用了。<br>iCallStackSize 代表当前的调用深度。</p><h1 id="libco-的运营经验"><a class="markdownIt-Anchor" href="#libco-的运营经验"></a> libco 的运营经验</h1><p>libco 的负责人 leiffyli 在 purecpp 大会上分享了 <a href="http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf" target="_blank" rel="noopener">libco 的一些运营经验</a>，个人觉得还是非常值得学习的，这里直接引用过来。</p><blockquote><p>协程栈大小有限，接入协程的服务谨慎使用栈空间；</p></blockquote><p>libco 中默认每个协程的栈大小是 128k，虽然可以自定义每个协程栈的大小，但是其大小依然是有限资源。避免在栈上分配大内存对象 (如大数组等)。</p><blockquote><p>池化使用，对系统中资源使用心中有数。随手创建与释放协程不是一个好的方式，有可能系统被过多的协程拖垮；</p></blockquote><p>关于这点，libco 的实例 <code>example_echosvr.cpp</code> 就是一个池化使用的例子。</p><blockquote><p>协程不适合运行 cpu 密集型任务。对于计算较重的服务，需要分离计算线程与网络线程，避免互相影响；</p></blockquote><p>这是因为计算比较耗时的任务，会严重拖慢 EventLoop 的运行过程，导致事件响应和协程调度受到了严重影响。</p><blockquote><p>过载保护。对于基于事件循环的协程调度框架，建议监控完成一次事件循环的时间，若此时间过长，会导致其它协程被延迟调度，需要与上层框架配合，减少新任务的调度；</p></blockquote><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>libco 巧妙的利用了 hook 技术，将协程的威力发挥的更加彻底，可以改良 C++ 的 RPC 框架异步化后的回调痛苦。整个库除了基本的协程函数，又加入类 pthread 的一些辅助功能，让协程的通信更加好用。</p><p>然而遗憾的是，libco 在开源方面做得并不是很好，后续 bug 维护和功能更新都不是很活跃。</p><p>但好消息是，据 leiffyli 的分享，目前有一些 libco 有一些实验中的特性，如事件回调、类 golang 的 channel 等，目前正在内部使用。相信后期也会同步到开源社区中。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf" target="_blank" rel="noopener">leiffyli：Libco 分享</a></li><li><a href="https://www.infoq.cn/article/CplusStyleCorourtine-At-Wechat" target="_blank" rel="noopener">C/C++ 协程库 libco：微信怎样漂亮地完成异步化改造</a></li><li><a href="https://www.zhihu.com/question/52193579/answer/156692295" target="_blank" rel="noopener">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么? - 江哈莫夫斯基的回答</a></li><li><a href="https://zhuanlan.zhihu.com/p/27409164" target="_blank" rel="noopener">libco 协程库上下文切换原理详解</a></li><li><a href="https://github.com/Tencent/libco/issues/41" target="_blank" rel="noopener">libco Github issue#41</a></li><li><a href="https://linux.die.net/man/3/dlsym" target="_blank" rel="noopener">man: dlsym</a></li><li><a href="http://walkerdu.com/2017/01/09/ucontext-theory/" target="_blank" rel="noopener">协程：posix::ucontext 用户级线程实现原理分析</a></li><li><a href="http://man7.org/linux/man-pages/man2/read.2.html" target="_blank" rel="noopener">man: read</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;libco 是微信后台开发和使用的协程库，同时也是极少数的直接将 C/C++ 协程运用到如此大规模的生产环境中的案例。&lt;/p&gt;
&lt;p&gt;在 &lt;a href=&quot;http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/&quot;&gt;《云风 coroutine 协程库源码分析》&lt;/a&gt; 中，介绍了有栈协程的实现原理。相比 coroutine，libco 在性能上号称可以调度千万级协程。 从使用上来说，不仅提供了一套类 pthread 的协程通信机制，同时可以零改造地将三方库的阻塞 IO 调用协程异步化。&lt;br&gt;
本文将从源码角度着重分析 libco 的高效之道。&lt;/p&gt;
&lt;p&gt;在正式阅读本文之前，如果对有栈协程的实现原理不是特别了解，建议提前阅读 &lt;a href=&quot;http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/&quot;&gt;《云风 coroutine 协程库源码分析》&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;同时，我也提供了 &lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/libco&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;libco 注释版&lt;/a&gt;，用以辅助理解 libco 的源码&lt;/p&gt;
    
    </summary>
    
      <category term="协程" scheme="http://www.cyhone.com/categories/%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="协程" scheme="http://www.cyhone.com/tags/%E5%8D%8F%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>C++ 智能指针的正确使用方式</title>
    <link href="http://www.cyhone.com/articles/right-way-to-use-cpp-smart-pointer/"/>
    <id>http://www.cyhone.com/articles/right-way-to-use-cpp-smart-pointer/</id>
    <published>2019-10-05T03:00:54.000Z</published>
    <updated>2019-12-17T11:00:17.502Z</updated>
    
    <content type="html"><![CDATA[<p>C++11 中推出了三种智能指针，unique_ptr、shared_ptr 和 weak_ptr，同时也将 auto_ptr 置为废弃 (deprecated)。</p><p>但是在实际的使用过程中，很多人都会有这样的问题：</p><ol><li>不知道三种智能指针的具体使用场景</li><li>无脑只使用 shared_ptr</li><li>认为应该禁用 raw pointer(裸指针，即 Widget * 这种形式)，全部使用智能指针</li></ol><p>本文将从这几方面讲解智能指针：</p><ol><li>智能指针的应用场景分析</li><li>智能指针的性能分析: 为什么 shared_ptr 性能比 unique_ptr 差</li><li>指针作为函数参数时应该传，传值、传引用，还是裸指针？</li></ol><a id="more"></a><h1 id="对象所有权"><a class="markdownIt-Anchor" href="#对象所有权"></a> 对象所有权</h1><p>首先需要理清楚的概念就是对象所有权的概念。所有权在 rust 语言中非常严格，写 rust 的时候必须要清楚自己创建的每个对象的所有权。</p><p>但是 C++ 比较自由，似乎我们不需要明白对象的所有权，写的代码也能正常运行。但是明白了对象所有权，我们才可以正确管理好对象生命周期和内存问题。</p><p>C++ 引入了智能指针，也是为了更好的描述对象所有权，简化内存管理，从而大大减少我们 C++ 内存管理方面的犯错机会。</p><h1 id="unique_ptr专属所有权"><a class="markdownIt-Anchor" href="#unique_ptr专属所有权"></a> unique_ptr：专属所有权</h1><p>** 我们大多数场景下用到的应该都是 unique_ptr**。<br>unique_ptr 代表的是专属所有权，即由 unique_ptr 管理的内存，只能被一个对象持有。<br>所以，**unique_ptr 不支持复制和赋值 **，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_unique&lt;Widget&gt;();</span><br><span class="line"><span class="keyword">auto</span> w2 = w; <span class="comment">// 编译错误</span></span><br></pre></td></tr></table></figure><p>如果想要把 w 复制给 w2, 是不可以的。因为复制从语义上来说，两个对象将共享同一块内存。</p><p>因此，<strong>unique_ptr 只支持移动</strong>, 即如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_unique&lt;Widget&gt;();</span><br><span class="line"><span class="keyword">auto</span> w2 = <span class="built_in">std</span>::move(w); <span class="comment">// w2 获得内存所有权，w 此时等于 nullptr</span></span><br></pre></td></tr></table></figure><p>unique_ptr 代表的是专属所有权，如果想要把一个 unique_ptr 的内存交给另外一个 unique_ptr 对象管理。<strong>只能使用 std::move 转移当前对象的所有权</strong>。转移之后，当前对象不再持有此内存，新的对象将获得专属所有权。</p><p>如上代码中，将 w 对象的所有权转移给 w2 后，w 此时等于 nullptr，而 w2 获得了专属所有权。</p><h2 id="性能"><a class="markdownIt-Anchor" href="#性能"></a> 性能</h2><p>因为 C++ 的 zero cost abstraction 的特点，unique_ptr 在默认情况下和裸指针的大小是一样的。<br>所以 <strong>内存上没有任何的额外消耗，性能是最优的</strong></p><h2 id="使用场景-1忘记-delete"><a class="markdownIt-Anchor" href="#使用场景-1忘记-delete"></a> 使用场景 1：忘记 delete</h2><p>unique_ptr 一个最简单的使用场景是用于类属性。代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Box() : w(<span class="keyword">new</span> Widget())</span><br><span class="line">    &#123;&#125;</span><br><span class="line">    ~Box()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 忘记 delete w</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Widget* w;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>如果因为一些原因，w 必须建立在堆上。如果用裸指针管理 w，那么需要在析构函数中 <code>delete w</code>;<br>这种写法虽然没什么问题，但是容易漏写 delete 语句，造成内存泄漏。</p><p>如果按照 unique_ptr 的写法，不用在析构函数手动 delete 属性，当对象析构时，属性 <code>w</code> 将会自动释放内存。</p><h2 id="使用场景-2异常安全"><a class="markdownIt-Anchor" href="#使用场景-2异常安全"></a> 使用场景 2：异常安全</h2><p>假如我们在一段代码中，需要创建一个对象，处理一些事情后返回，返回之前将对象销毁，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Widget* w = <span class="keyword">new</span> Widget();</span><br><span class="line">    w-&gt;do_something(); <span class="comment">// 可能会发生异常</span></span><br><span class="line">    <span class="keyword">delete</span> w;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在正常流程下，我们会在函数末尾 delete 创建的对象 w，正常调用析构函数，释放内存。</p><p>但是如果 w-&gt;do_something() 发生了异常，那么 <code>delete w</code> 将不会被执行。此时就会发生 <strong>内存泄漏</strong>。<br>我们当然可以使用 try…catch 捕捉异常，在 catch 里面执行 delete，但是这样代码上并不美观，也容易漏写。</p><p>如果我们用 std::unique_ptr，那么这个问题就迎刃而解了。无论代码怎么抛异常，在 unique_ptr 离开函数作用域的时候，内存就将会自动释放。</p><h1 id="shared_ptr共享所有权"><a class="markdownIt-Anchor" href="#shared_ptr共享所有权"></a> shared_ptr：共享所有权</h1><p>在使用 shared_ptr 之前应该考虑，是否真的需要使用 shared_ptr, 而非 unique_ptr。</p><p>shared_ptr 代表的是共享所有权，即多个 shared_ptr 可以共享同一块内存。<br>因此，从语义上来看，**shared_ptr 是支持复制的 **。如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_shared&lt;Widget&gt;();</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">auto</span> w2 = w;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt;w.use_count() &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt;w.use_count() &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 1</span></span><br></pre></td></tr></table></figure><p>shared_ptr 内部是利用引用计数来实现内存的自动管理，每当复制一个 shared_ptr，引用计数会 + 1。当一个 shared_ptr 离开作用域时，引用计数会 - 1。当引用计数为 0 的时候，则 delete 内存。</p><p>同时，**shared_ptr 也支持移动 **。从语义上来看，移动指的是所有权的传递。如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto w = std::make_shared&lt;Widget&gt;();</span><br><span class="line">auto w2 = std::move(w); // 此时 w 等于 nullptr，w2.use_count() 等于 1</span><br></pre></td></tr></table></figure><p>我们将 w 对象 move 给 w2，意味着 w 放弃了对内存的所有权和管理，此时 w 对象等于 nullptr。<br>而 w2 获得了对象所有权，但因为此时 w 已不再持有对象，因此 w2 的引用计数为 1。</p><h2 id="性能-2"><a class="markdownIt-Anchor" href="#性能-2"></a> 性能</h2><ol><li><p><strong>内存占用高</strong><br>shared_ptr 的内存占用是裸指针的两倍。因为除了要管理一个裸指针外，还要维护一个引用计数。<br>因此相比于 unique_ptr, shared_ptr 的内存占用更高</p></li><li><p><strong>原子操作性能低</strong><br>考虑到线程安全问题，引用计数的增减必须是原子操作。而原子操作一般情况下都比非原子操作慢。</p></li><li><p><strong>使用移动优化性能</strong><br>shared_ptr 在性能上固然是低于 unique_ptr。而通常情况，我们也可以尽量避免 shared_ptr 复制。<br>如果，一个 shared_ptr 需要将所有权共享给另外一个新的 shared_ptr，而我们确定在之后的代码中都不再使用这个 shared_ptr，那么这是一个非常鲜明的移动语义。<br>对于此种场景，我们尽量使用 std::move，将 shared_ptr 转移给新的对象。因为移动不用增加引用计数，因此性能比复制更好。</p></li></ol><h2 id="使用场景"><a class="markdownIt-Anchor" href="#使用场景"></a> 使用场景</h2><ol><li>shared_ptr 通常使用在共享权不明的场景。有可能多个对象同时管理同一个内存时。</li><li>对象的延迟销毁。陈硕在《Linux 多线程服务器端编程》中提到，当一个对象的析构非常耗时，甚至影响到了关键线程的速度。可以使用 <code>BlockingQueue&lt;std::shared_ptr&lt;void&gt;&gt;</code> 将对象转移到另外一个线程中释放，从而解放关键线程。</li></ol><h2 id="为什么要用-shared_from_this"><a class="markdownIt-Anchor" href="#为什么要用-shared_from_this"></a> 为什么要用 shared_from_this?</h2><p>我们往往会需要在类内部使用自身的 shared_ptr，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">do_something</span><span class="params">(A&amp; a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        a.widget = 该对象的 <span class="built_in">shared_ptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们需要把当前 shared_ptr 对象同时交由对象 a 进行管理。意味着，当前对象的生命周期的结束不能早于对象 a。因为对象 a 在析构之前还是有可能会使用到 <code>a.widget</code>。</p><p>如果我们直接 <code>a.widget = this;</code>， 那肯定不行， 因为这样并没有增加当前 shared_ptr 的引用计数。shared_ptr 还是有可能早于对象 a 释放。</p><p>如果我们使用 <code>a.widget = std::make_shared&lt;Widget&gt;(this);</code>，肯定也不行，因为这个新创建的 shared_ptr，跟当前对象的 shared_ptr 毫无关系。当前对象的 shared_ptr 生命周期结束后，依然会释放掉当前内存，那么之后 <code>a.widget</code> 依然是不合法的。</p><p>对于这种，需要在对象内部获取该对象自身的 shared_ptr, 那么该类必须继承 <code>std::enable_shared_from_this&lt;T&gt;</code>。代码如下:</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;Widget&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">do_something</span><span class="params">(A&amp; a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        a.widget = shared_from_this();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样才是合法的做法。</p><h1 id="weak_ptr"><a class="markdownIt-Anchor" href="#weak_ptr"></a> weak_ptr</h1><p>weak_ptr 是为了解决 shared_ptr 双向引用的问题。即：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;B&gt; b;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;A&gt; a;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">auto</span> pa = make_shared&lt;A&gt;();</span><br><span class="line"><span class="keyword">auto</span> pb = make_shared&lt;B&gt;();</span><br><span class="line">pa-&gt;b = pb;</span><br><span class="line">pb-&gt;a = pa;</span><br></pre></td></tr></table></figure><p>pa 和 pb 存在着循环引用，根据 shared_ptr 引用计数的原理，pa 和 pb 都无法被正常的释放。<br>对于这种情况, 我们可以使用 weak_ptr：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;B&gt; b;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>&#123;</span></span><br><span class="line">    weak_ptr&lt;A&gt; a;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">auto</span> pa = make_shared&lt;A&gt;();</span><br><span class="line"><span class="keyword">auto</span> pb = make_shared&lt;B&gt;();</span><br><span class="line">pa-&gt;b = pb;</span><br><span class="line">pb-&gt;a = pa;</span><br></pre></td></tr></table></figure><p>weak_ptr 不会增加引用计数，因此可以打破 shared_ptr 的循环引用。<br>通常做法是 parent 类持有 child 的 shared_ptr, child 持有指向 parent 的 weak_ptr。这样也更符合语义。</p><h1 id="如何指针作为函数传参"><a class="markdownIt-Anchor" href="#如何指针作为函数传参"></a> 如何指针作为函数传参</h1><p>很多时候，函数的参数是个指针。这个时候就会面临选择困难症，这个参数应该怎么传，应该是 shared_ptr<t>，还是 const shared_ptr<t>&amp;，还是直接 raw pointer 更合适。</t></t></p><ol><li><strong>只在函数使用指针，但并不保存</strong><br>假如我们只需要在函数中，用这个对象处理一些事情，但不打算涉及其生命周期的管理，不打算通过函数传参延长 shared_ptr 的生命周期。<br>对于这种情况，可以使用 raw pointer 或者 const shared_ptr<t>&amp;。<br>即：</t></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(Widget*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Widget&gt;&amp;)</span></span></span><br></pre></td></tr></table></figure><p>实际上第一种裸指针的方式可能更好，从语义上更加清楚，函数也不用关心智能指针的类型。</p><ol start="2"><li><strong>在函数中保存智能指针</strong><br>假如我们需要在函数中把这个智能指针保存起来，这个时候建议直接传值。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Widget&gt; ptr)</span></span>;</span><br></pre></td></tr></table></figure><p>这样的话，外部传过来值的时候，可以选择 move 或者赋值。函数内部直接把这个对象通过 move 的方式保存起来。<br>这样性能更好，而且外部调用也有多种选择。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>对于智能指针的使用，实际上是对所有权和生命周期的思考，一旦想明白了这两点，那对智能指针的使用也就得心应手了。<br>同时理解了每种智能指针背后的性能消耗、使用场景，那智能指针也不再是黑盒子和洪水猛兽。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li>《Effective Modern cpp》</li><li>《Linux 多线程服务器端编程》</li><li><a href="https://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/" target="_blank" rel="noopener">GotW #91 Solution: Smart Pointer Parameters</a></li><li><a href="https://www.zhihu.com/question/30957800" target="_blank" rel="noopener">std::enable_shared_from_this 有什么意义？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++11 中推出了三种智能指针，unique_ptr、shared_ptr 和 weak_ptr，同时也将 auto_ptr 置为废弃 (deprecated)。&lt;/p&gt;
&lt;p&gt;但是在实际的使用过程中，很多人都会有这样的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不知道三种智能指针的具体使用场景&lt;/li&gt;
&lt;li&gt;无脑只使用 shared_ptr&lt;/li&gt;
&lt;li&gt;认为应该禁用 raw pointer(裸指针，即 Widget * 这种形式)，全部使用智能指针&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将从这几方面讲解智能指针：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;智能指针的应用场景分析&lt;/li&gt;
&lt;li&gt;智能指针的性能分析: 为什么 shared_ptr 性能比 unique_ptr 差&lt;/li&gt;
&lt;li&gt;指针作为函数参数时应该传，传值、传引用，还是裸指针？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="cpp" scheme="http://www.cyhone.com/categories/cpp/"/>
    
    
      <category term="智能指针" scheme="http://www.cyhone.com/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"/>
    
      <category term="C++" scheme="http://www.cyhone.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>c++ lambda 内 std::move 失效问题的思考</title>
    <link href="http://www.cyhone.com/articles/why-move-no-work-in-lambda/"/>
    <id>http://www.cyhone.com/articles/why-move-no-work-in-lambda/</id>
    <published>2019-09-29T10:07:00.000Z</published>
    <updated>2019-12-30T10:22:45.286Z</updated>
    
    <content type="html"><![CDATA[<p>最近在写 C++ 时，有这样一个代码需求：在 lambda 中，将一个捕获参数 move 给另外一个变量。<br>看似一个很简单常规的操作，然而这个 move 动作却没有生效。</p><p>具体代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> func = [=]()&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt;vec.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt;vec2.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码可在 <a href="https://wandbox.org/permlink/et6ZTBhwpz5SH6w0" target="_blank" rel="noopener">wandbox</a> 运行。</p><p>我们期望的是，将对变量 <code>vec</code> 调用 std::move 后，数据将会移动至变量 <code>vec2</code>, 此时 <code>vec</code> 里面应该没有数据了。但是通过打印 <code>vec.size()</code> 发现 vec 中的数据并没有按预期移走。</p><p>这也就意味着，构造 vec2 时并没有按预期调用移动构造函数，而是调用了拷贝构造函数。</p><p>为什么会造成这个问题呢, 我们需要结合 <code>std::move</code> 和 <code>lambda</code> 的原理看下。（最终的解决方案可以直接看 <a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88">这里</a>）</p><a id="more"></a><h1 id="stdmove-的本质"><a class="markdownIt-Anchor" href="#stdmove-的本质"></a> std::move 的本质</h1><p>对于 std::move，有两点需要注意：</p><ol><li>std::move 中到底做了什么事情</li><li>std::move 是否可以保证数据一定能移动成功</li></ol><p>对于第二点来说，答案显然是不能。这也是本文的问题所在。那么 std::move 实际上是做了什么事情呢？</p><p>对于 std::move，其实现大致如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) move(T&amp;&amp; param)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">using</span> ReturnType = <span class="keyword">remove_reference_t</span>&lt;T&gt;&amp;&amp;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;ReturnType&gt;(param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码可以看出，std::move 本质上是调用了 static_cast 做了一层强制转换，强制转换的目标类型是 <code>remove_reference_t&lt;T&gt;&amp;&amp;</code>，remove_reference_t 是为了去除类型本身的引用，例如左值引用。总结来说，std::move 本质上是将对象强制转换为了右值引用。</p><p>那么，为什么我们通常使用 std::move 实现移动语义，可以将一个对象的数据移给另外一个对象？</p><p>这是因为 std::move 配合了移动构造函数使用，本质上是移动构造函数起了作用。移动构造函数的一般定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class A&#123;</span><br><span class="line">public:</span><br><span class="line">    A(A &amp;&amp;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>可以看到移动构造函数的参数就是个右值引用 <code>A&amp;&amp;</code>，因此 <code>A a = std::move(b);</code>, 本质上是先将 b 强制转化了右值引用 <code>A&amp;&amp;</code>,<br>然后触发了移动构造函数，在移动构造函数中，完成了对象 b 的数据到对象 a 的移动。</p><p>那么，在哪些情况下，<code>A a = std::move(b);</code> 会失效呢？<br>显然是，当 std::move 强转后的类型不是 <code>A&amp;&amp;</code>，这样就不会命中移动构造函数。</p><p>例如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> str = <span class="string">"123"</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> str2(<span class="built_in">std</span>::move(str));</span><br></pre></td></tr></table></figure><p>这个时候，对 str 对象调用 <code>std::move</code>，强转出来的类型将会是 <code>const string&amp;&amp;</code>, 这样移动构造函数就不会起作用了，但是这个类型却可以令复制构造函数生效。</p><p>结合本文最初的问题，在 lambda 中 move 没有生效，显然也是 std::move 强转的类型不是 <code>std::vector&lt;int&gt;&amp;&amp;</code>, 才导致了没有 move 成功。</p><p>那么，为什么会出现这个问题呢，我们需要理解下 lambda 的工作原理。</p><h1 id="lambda-闭包原理"><a class="markdownIt-Anchor" href="#lambda-闭包原理"></a> lambda 闭包原理</h1><p>对于 c++ 的 lambda，编译器会将 lambda 转化为一个独一无二的闭包类。而 lambda 对象最终会转化成这个闭包类的对象。<br>对于本文最初的这个 lambda 来说，最终实际上转化成了这么一个类型</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 转换前</span></span><br><span class="line"><span class="keyword">auto</span> func = [=]()&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换后</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClosureFunc</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ClosureFunc func;</span><br></pre></td></tr></table></figure><p>这里需要注意, lambda 的默认行为是，<strong>生成的闭包类的 <code>operator()</code> 默认被 const 修饰</strong>。</p><p>那么这里问题就来了，当调用 <code>operator()</code> 时, 该闭包类所有的成员变量也是被 const 修饰的，此时对成员变量调用 <code>std::move</code> 将会引发上文中提到的，<strong>强转出来的类型将会是 <code>const string&amp;&amp;</code> 问题</strong>。因此，移动构造函数将不会被匹配到。</p><p>我们最初的问题 lambda 中 std::move 失效的问题，也是因为这个原因。这也很符合 const 函数的语义: const 函数是不能修改成员变量的值。</p><h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1><p>那么，这个应该怎么解决呢？答案是 <code>mutable</code>。即在 lambda 尾部声明一个 mutable，如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> func = [=]() <span class="keyword">mutable</span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这样编译器生成的闭包类的 <code>operator()</code> 将会不带 const 了。我们的 std::move 也可以正常转换，实现移动语义了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> func = [=]() <span class="keyword">mutable</span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt;vec.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：0</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt;vec2.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码可以在 <a href="https://wandbox.org/permlink/ox4SBxNrAi8M8ZLp" target="_blank" rel="noopener">wandbox</a> 运行。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://zh.cppreference.com/w/cpp/language/lambda" target="_blank" rel="noopener">Lambda 表达式 - cppreference</a></li><li>Effective Modern c++</li><li><a href="https://www.zhihu.com/question/50652989" target="_blank" rel="noopener">关于 C++ 右值及 std::move() 的疑问？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在写 C++ 时，有这样一个代码需求：在 lambda 中，将一个捕获参数 move 给另外一个变量。&lt;br&gt;
看似一个很简单常规的操作，然而这个 move 动作却没有生效。&lt;/p&gt;
&lt;p&gt;具体代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;&amp;gt; vec = &amp;#123;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; func = [=]()&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; vec2 = &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::move(vec);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt;vec.size() &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;// 输出：3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt;vec2.size() &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;// 输出：3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;代码可在 &lt;a href=&quot;https://wandbox.org/permlink/et6ZTBhwpz5SH6w0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;wandbox&lt;/a&gt; 运行。&lt;/p&gt;
&lt;p&gt;我们期望的是，将对变量 &lt;code&gt;vec&lt;/code&gt; 调用 std::move 后，数据将会移动至变量 &lt;code&gt;vec2&lt;/code&gt;, 此时 &lt;code&gt;vec&lt;/code&gt; 里面应该没有数据了。但是通过打印 &lt;code&gt;vec.size()&lt;/code&gt; 发现 vec 中的数据并没有按预期移走。&lt;/p&gt;
&lt;p&gt;这也就意味着，构造 vec2 时并没有按预期调用移动构造函数，而是调用了拷贝构造函数。&lt;/p&gt;
&lt;p&gt;为什么会造成这个问题呢, 我们需要结合 &lt;code&gt;std::move&lt;/code&gt; 和 &lt;code&gt;lambda&lt;/code&gt; 的原理看下。（最终的解决方案可以直接看 &lt;a href=&quot;#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88&quot;&gt;这里&lt;/a&gt;）&lt;/p&gt;
    
    </summary>
    
      <category term="cpp" scheme="http://www.cyhone.com/categories/cpp/"/>
    
    
      <category term="cpp" scheme="http://www.cyhone.com/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>云风 coroutine 协程库源码分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/"/>
    <id>http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/</id>
    <published>2019-09-19T06:26:19.000Z</published>
    <updated>2019-12-17T10:57:36.458Z</updated>
    
    <content type="html"><![CDATA[<p>随着 Golang 的兴起，协程尤其是有栈协程 (stackful coroutine) 越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。</p><p>云风实现了一套 <a href="https://github.com/cloudwu/coroutine/" target="_blank" rel="noopener">C 语言的协程库</a>，整体背景可以参考其 <a href="https://blog.codingnow.com/2012/07/c_coroutine.html" target="_blank" rel="noopener">博客</a>。</p><p>这个协程库非常轻量级，一共也才 200 多行代码，使用上更贴近于 lua 的写法（众所周知，云风是知名的 lua 粉)。整体基于 ucontext 和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。</p><p>同时，我也提供了 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine" target="_blank" rel="noopener">coroutine 注释版</a>，辅助大家理解 coroutine 的代码。</p><a id="more"></a><h1 id="协程的背景"><a class="markdownIt-Anchor" href="#协程的背景"></a> 协程的背景</h1><p>协程主要有两大优点：</p><ol><li>相比线程更加轻量级<ul><li>线程的创建和调度都是在内核态，而协程是在用户态完成的</li><li>线程的个数往往受限于 CPU 核数，线程过多，会造成大量的核间切换。而协程无需考虑这些</li></ul></li><li>将异步流程同步化处理：此问题在知乎上有非常多的 <a href="https://www.zhihu.com/question/32218874/answer/216801915" target="_blank" rel="noopener">经典回答</a>。尤其在 RPC 中进行多服务并发协作的时候，相比于回调式的做法，协程的好处更加明显。这个对于后端程序员的意义更大，非常解放生产力。这里就不再赘述了。</li></ol><p>微信基于 c++ 实现的协程库 <a href="https://github.com/Tencent/libco/" target="_blank" rel="noopener">libco</a>，hook 了网络 IO 所需要大部分的系统函数，实现了当 IO 阻塞时协程的自动切换。<br>而 Golang 做的则更加极致，直接将协程和自动切换的概念集成进了语言。这里不细讲 libco 和 GoRoutine 的实现了，有机会会对这些做更详细的剖析。</p><p>协程再细分可以分为有栈协程和无栈协程：我们今天讲的云风的 coroutine，包括微信的 libco、GoRoutine，都是属于有栈协程。无栈协程包括 ES6 中的 await/async、Python 中的协程等。两种协程实现原理有很大的不同，本文主要基于 coroutine 对有栈协程的原理进行详细的分析。</p><h1 id="有栈协程的原理"><a class="markdownIt-Anchor" href="#有栈协程的原理"></a> 有栈协程的原理</h1><p>一个程序要真正运行起来，需要两个因素：可执行代码段、数据。体现在 CPU 中，主要包含以下几个方面：</p><ol><li>EIP 寄存器，用来存储 CPU 要读取指令的地址</li><li>ESP 寄存器：指向当前线程栈的栈顶位置</li><li>其他通用寄存器的内容：包括代表函数参数的 rdi、rsi 等等。</li><li>线程栈中的内存内容。</li></ol><p>这些数据内容，我们一般将其称为 “上下文” 或者 “现场”。</p><p>有栈协程的原理，就是从线程的上下文下手，如果把线程的上下文完全改变。即：改变 EIP 寄存的内容，指向其他指令地址；改变线程栈的内存内容等等。<br>这样的话，当前线程运行的程序也就完全改变了，是一个全新的程序。</p><p>Linux 下提供了一套函数，叫做 ucontext 簇函数，可以用来获取和设置当前线程的上下文内容。这也是 coroutine 的核心方法。</p><h1 id="coroutine-的使用"><a class="markdownIt-Anchor" href="#coroutine-的使用"></a> coroutine 的使用</h1><p>我们首先基于 coroutine 的例子来讲下 coroutine 的基本使用，以方便后面原理的讲解</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(struct schedule * S, <span class="keyword">void</span> *ud)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> * <span class="title">arg</span> = <span class="title">ud</span>;</span></span><br><span class="line"><span class="keyword">int</span> start = arg-&gt;n;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"coroutine %d : %d\n"</span>,coroutine_running(S) , start + i);</span><br><span class="line"><span class="comment">// 切出当前协程</span></span><br><span class="line">coroutine_yield(S);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">(struct schedule *S)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> <span class="title">arg1</span> = &#123;</span><span class="number">0</span>&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> <span class="title">arg2</span> = &#123;</span><span class="number">100</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建两个协程</span></span><br><span class="line"><span class="keyword">int</span> co1 = coroutine_new(S, foo, &amp;arg1);</span><br><span class="line"><span class="keyword">int</span> co2 = coroutine_new(S, foo, &amp;arg2);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"main start\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (coroutine_status(S,co1) &amp;&amp; coroutine_status(S,co2)) &#123;</span><br><span class="line"><span class="comment">// 使用协程 co1</span></span><br><span class="line">coroutine_resume(S,co1);</span><br><span class="line"><span class="comment">// 使用协程 co2</span></span><br><span class="line">coroutine_resume(S,co2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"main end\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 创建一个协程调度器</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">schedule</span> * <span class="title">S</span> = <span class="title">coroutine_open</span>();</span></span><br><span class="line"></span><br><span class="line">test(S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭协程调度器</span></span><br><span class="line">coroutine_close(S);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码看来，首先利用 <code>coroutine_open</code> 创建了协程调度器 S，用来统一管理全部的协程。<br>同时在 test 函数中，创建了两个协程 co1 和 co2，不断的反复 yield 和 resume 协程，直至两个协程执行完毕。</p><p>可以看出，最核心的几个对象和函数是:</p><ol><li><code>struct schedule* S</code> 协程调度器</li><li><code>coroutine_resume(S,co1);</code> 切入该协程</li><li><code>coroutine_yield(S);</code> 切出该协程</li></ol><p>接下来，会从这几点出发，分析 coroutine 的原理。建议大家在阅读下文时，同时对照我做的 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine" target="_blank" rel="noopener">coroutine 注释版</a>。</p><h1 id="struct-schedule-协程调度器"><a class="markdownIt-Anchor" href="#struct-schedule-协程调度器"></a> struct schedule 协程调度器</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">schedule</span> &#123;</span></span><br><span class="line"><span class="keyword">char</span> <span class="built_in">stack</span>[STACK_SIZE];<span class="comment">// 运行时栈，此栈即是共享栈</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ucontext_t</span> main; <span class="comment">// 主协程的上下文</span></span><br><span class="line"><span class="keyword">int</span> nco;        <span class="comment">// 当前存活的协程个数</span></span><br><span class="line"><span class="keyword">int</span> cap;        <span class="comment">// 协程管理器的当前最大容量，即可以同时支持多少个协程。如果不够了，则进行 2 倍扩容</span></span><br><span class="line"><span class="keyword">int</span> running;    <span class="comment">// 正在运行的协程 ID</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">coroutine</span> **<span class="title">co</span>;</span> <span class="comment">// 一个一维数组，用于存放所有协程。其长度等于 cap</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>协程调度器 schedule 负责管理所有协程，有几个属性非常重要：</p><ol><li><code>struct coroutine **co;</code> 是一个一维数组，存放了目前所有的协程。</li><li><code>ucontext_t main;</code> 主协程的上下文，方便后面协程执行完后切回到主协程。</li><li><code>char stack[STACK_SIZE];</code> 这个非常重要，是所有协程的运行时栈。具体共享栈的原理会在下文讲到。</li></ol><p>此外，<code>coroutine_open</code> 负责创建并初始化一个协程调度器，<code>coroutine_close</code> 负责销毁协程调度器以及清理其管理的所有协程。</p><h1 id="协程的创建-coroutine_new"><a class="markdownIt-Anchor" href="#协程的创建-coroutine_new"></a> 协程的创建: coroutine_new</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct coroutine &#123;</span><br><span class="line">coroutine_func func; <span class="comment">// 协程所用的函数</span></span><br><span class="line"><span class="keyword">void</span> *ud;  <span class="comment">// 协程参数</span></span><br><span class="line">ucontext_t ctx; <span class="comment">// 协程上下文</span></span><br><span class="line">struct schedule * sch; <span class="comment">// 该协程所属的调度器</span></span><br><span class="line">ptrdiff_t cap;  <span class="comment">// 已经分配的内存大小</span></span><br><span class="line">ptrdiff_t size; <span class="comment">// 当前协程运行时栈，保存起来后的大小</span></span><br><span class="line"><span class="keyword">int</span> status;<span class="comment">// 协程当前的状态</span></span><br><span class="line"><span class="keyword">char</span> *stack; <span class="comment">// 当前协程的保存起来的运行时栈</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>coroutine_new</code> 负责创建并初始化一个新协程对象，同时将该协程对象放到协程调度器里面。</p><p>这里的实现有两个非常有意思的点：</p><ol><li><strong>扩容</strong>：当目前尚存活的线程个数 <code>nco</code> 已经等于协程调度器的容量 <code>cap</code> 了，这个时候需要对协程调度器进行扩容，这里直接就是非常经典简单的 2 倍扩容。</li><li><strong>如果无需扩容，则需要找到一个空的位置，放置初始化好的协程</strong>。这里一般直接从数组第一位开始找，直到找到空的位置即可。但是云风把这里处理成从第 <code>nco</code> 位开始寻找（<code>nco</code> 代表当前存活的个数。因为一般来说，前面几位最开始都是存活的，从第 <code>nco</code> 位开始找，效率会更高。</li></ol><p>这样，一个协程对象就被创建好，此时该协程的状态是 <code>READY</code>，但尚未正式执行。</p><p><code>coroutine_resume</code> 函数会切入到指定协程中执行。当前正在执行的协程的上下文会被保存起来，同时上下文替换成新的协程，该协程的状态将被置为 <code>RUNNING</code>。</p><p>进入 <code>coroutine_resume</code> 函数的前置状态有两个 <code>READY</code> 和 <code>SUSPEND</code>，这两个状态下 <code>coroutine_resume</code> 的处理方法也是有很大不同。我们先看下协程在 READY 状态下进行 <code>coroutine_resume</code> 的流程。</p><h1 id="coroutine_resumeready-running"><a class="markdownIt-Anchor" href="#coroutine_resumeready-running"></a> coroutine_resume(READY -&gt; RUNNING）</h1><p>这块代码比较短，但是非常重要，所以我就直接贴代码了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化 ucontext_t 结构体，将当前的上下文放到 C-&gt;ctx 里面</span></span><br><span class="line">getcontext(&amp;C-&gt;ctx);</span><br><span class="line"><span class="comment">// 将当前协程的运行时栈的栈顶设置为 S-&gt;stack，每个协程都这么设置，这就是所谓的共享栈。（注意，这里是栈顶）</span></span><br><span class="line">C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;</span><br><span class="line">C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;</span><br><span class="line">C-&gt;ctx.uc_link = &amp;S-&gt;main;</span><br><span class="line">S-&gt;running = id;</span><br><span class="line">C-&gt;status = COROUTINE_RUNNING;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置执行 C-&gt;ctx 函数, 并将 S 作为参数传进去</span></span><br><span class="line">uintptr_t ptr = (uintptr_t)S;</span><br><span class="line">makecontext(&amp;C-&gt;ctx, (<span class="keyword">void</span> (*)(<span class="keyword">void</span>)) mainfunc, <span class="number">2</span>, (uint32_t)ptr, (uint32_t)(ptr&gt;&gt;<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将当前的上下文放入 S-&gt;main 中，并将 C-&gt;ctx 的上下文替换到当前上下文</span></span><br><span class="line">swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx);</span><br></pre></td></tr></table></figure><p>这段函数非常的重要，有几个不可忽视的点：</p><ol><li><code>getcontext(&amp;C-&gt;ctx);</code> 初始化 ucontext_t 结构体，将当前的上下文放到 C-&gt;ctx 里面</li><li><code>C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;</code> 设置当前协程的运行时栈，也是共享栈。</li><li><code>C-&gt;ctx.uc_link = &amp;S-&gt;main;</code> 如果协程执行完，则切换到 <code>S-&gt;main</code> 主协程中进行执行。如果不设置, 则默认为 NULL，那么协程执行完，整个程序就结束了。</li></ol><p>接下来是 makecontext，这个函数用来设置对应 ucontext 的执行函数。如上，将 <code>C-&gt;ctx</code> 的执行函数体设置为了 mainfunc。</p><p>makecontext 后面的两个参数也非常有意思，这个可以看出来是把一个指针掰成了两个 int 作为参数传给 mainfunc 了。而在 mainfunc 的实现可以看出来，又会把这两个 int 拼成了一个 <code>struct schedule*</code>。</p><p>那么，为什么不直接传 <code>struct schedule*</code> 呢，而要这么做，通过先拆两半，再在函数中拼起来？</p><p>这是因为 makecontext 的函数指针的参数是 <code>uint32_t</code> 类型，在 64 位系统下，一个 <code>uint32_t</code> 没法承载一个指针, 所以基于兼容性的考虑，才采用了这种做法。</p><p>接下来调用了 <code>swapcontext</code> 函数，这个函数比较简单，但也非常核心。作用是将当前的上下文内容放入 <code>S-&gt;main</code> 中，并将 <code>C-&gt;ctx</code> 的上下文替换到当前上下文。这样的话，将会执行新的上下文对应的程序了。在 coroutine 中, 也就是开始执行 <code>mainfunc</code> 这个函数。(<code>mainfunc</code> 是对用户提供的协程函数的封装)。</p><h1 id="协程的切出coroutine_yield"><a class="markdownIt-Anchor" href="#协程的切出coroutine_yield"></a> 协程的切出：coroutine_yield</h1><p>调用 <code>coroutine_yield</code> 可以使当前正在运行的协程切换到主协程中运行。此时，该协程会进入 <code>SUSPEND</code> 状态</p><p><code>coroutine_yield</code> 的具体实现依赖于两个行为：</p><ol><li>调用 <code>_save_stack</code> 将当前协程的栈保存起来。因为 coroutine 是基于共享栈的，所以协程的栈内容需要单独保存起来。</li><li><code>swapcontext</code> 将当前上下文保存到当前协程的 ucontext 里面，同时替换当前上下文为主协程的上下文。 这样的话，当前协程会被挂起，主协程会被继续执行。</li></ol><p>这里也有个点极其关键, 就是如何保存当前协程的运行时栈, 也就是如何获取整个栈的内存空间。</p><p>这里我们需要了解下栈内存空间的布局，即栈的生长方向是从高地址往低地址。我们只要找到栈的栈顶和栈底的地址，就可以找到整个栈内存空间了。</p><p>在 coroutine 中，因为协程的运行时栈的内存空间是自己分配的。在 coroutine_resume 阶段设置了 <code>C-&gt;ctx.uc_stack.ss_sp = S.S-&gt;stack</code>。根据以上理论，栈的生长方向是高地址到低地址，因此栈底的就是内存地址最大的位置，即 <code>S-&gt;stack + STACK_SIZE</code> 就是栈底位置。</p><p>那么，如何找到栈顶的位置呢？coroutine 是基于以下方法做的：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> _save_stack(C,S-&gt;<span class="built_in">stack</span> + STACK_SIZE);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> _save_stack(struct coroutine *C, <span class="keyword">char</span> *top) &#123;</span><br><span class="line"><span class="keyword">char</span> dummy = <span class="number">0</span>;</span><br><span class="line">assert(top - &amp;dummy &lt;= STACK_SIZE);</span><br><span class="line">    <span class="comment">// 如果已分配内存小于当前栈的大小，则释放内存重新分配</span></span><br><span class="line"><span class="keyword">if</span> (C-&gt;cap &lt; top - &amp;dummy) &#123;</span><br><span class="line"><span class="built_in">free</span>(C-&gt;<span class="built_in">stack</span>);</span><br><span class="line">C-&gt;cap = top-&amp;dummy;</span><br><span class="line">C-&gt;<span class="built_in">stack</span> = <span class="built_in">malloc</span>(C-&gt;cap);</span><br><span class="line">&#125;</span><br><span class="line">C-&gt;size = top - &amp;dummy;</span><br><span class="line">    <span class="comment">// 从 dummy 拷贝 size 内存到 C-&gt;stack</span></span><br><span class="line"><span class="built_in">memcpy</span>(C-&gt;<span class="built_in">stack</span>, &amp;dummy, C-&gt;size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里特意用到了一个 dummy 变量，这个 dummy 的作用非常关键也非常巧妙，大家可以细细体会下。因为 dummy 变量是刚刚分配到栈上的，此时就位于 <strong>栈的最顶部位置</strong>。整个内存布局如下图所示：<br><img src="/img/coroutine/coroutine_dummy.png" alt=""></p><p>因此整个栈的大小就是从栈底到栈顶，<code>S-&gt;stack + STACK_SIZE - &amp;dummy</code>。</p><p>最后又调用了 memcpy 将当前运行时栈的内容，拷贝到了 <code>C-&gt;stack</code> 中保存了起来。</p><h1 id="coroutine_resumesuspend-running"><a class="markdownIt-Anchor" href="#coroutine_resumesuspend-running"></a> coroutine_resume(SUSPEND -&gt; RUNNING）</h1><p>当协程被 yield 之后会进入 <code>SUSPEND</code> 阶段，对该协程调用 <code>coroutine_resume</code> 会再次切入该协程。</p><p>这里的实现有两个重要的点：</p><ol><li><p><code>memcpy(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);</code><br>我们知道，在 yield 的时候，协程的栈内容保存到了 C-&gt;stack 数组中。<br>这个时候，就是用 memcpy 把协程的之前保存的栈内容，重新拷贝到运行时栈里面。这里有个点，拷贝的开始位置，需要简单计算下<br><code>S-&gt;stack + STACK_SIZE - C-&gt;size</code> 这个位置就是之前协程的栈顶位置。</p></li><li><p><code>swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx);</code> 交换上下文。这点在上文有具体描述。</p></li></ol><h1 id="状态机转换"><a class="markdownIt-Anchor" href="#状态机转换"></a> 状态机转换</h1><p>在 coroutine 中协程定义了四种状态，整个运行期间，也是根据这四种状态进行轮转。</p><p><img src="/img/coroutine/coroutine-state-machine.png" alt=""></p><h1 id="共享栈"><a class="markdownIt-Anchor" href="#共享栈"></a> 共享栈</h1><p>共享栈这个词在 libco 中提到的多，其实 coroutine 也是用的共享栈模型。<br>共享栈这个东西说起来很玄乎，实际原理不复杂，本质就是所有的协程在运行的时候都使用同一个栈空间。</p><p>共享栈对标的是非共享栈，也就是每个协程的栈空间都是独立的，固定大小。好处是协程切换的时候，内存不用拷贝来拷贝去。坏处则是 <strong>内存空间浪费</strong>.</p><p>因为栈空间在运行时不能随时扩容，为了防止栈内存不够，所以要预先每个协程都要预先开一个足够的栈空间使用。当然很多协程用不了这么大的空间，就必然造成内存的浪费。</p><p>共享栈则是提前开了一个足够大的栈空间 (coroutine 默认是 1M)。所有的栈运行的时候，都使用这个栈空间。<br>conroutine 是这么设置每个协程的运行时栈：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C-&gt;ctx.uc_stack.ss_sp = S-&gt;<span class="built_in">stack</span>;</span><br><span class="line">C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;</span><br></pre></td></tr></table></figure><p>对协程调用 yield 的时候，该协程栈内容暂时保存起来，保存的时候需要用到多少内存就开多少，这样就减少了内存的浪费。(即_save_stack 函数的内容)。<br>当 resume 该协程的时候，协程之前保存的栈内容，会被重新拷贝到运行时栈中。</p><p>这就是所谓的共享栈的原理。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>云风的协程库代码非常简约，可以帮助我们更好的理解协程实现的基本原理。后面有机会也会细讲下微信 libco 的实现原理，这个更贴近于工业级的使用，用法也非常强大。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="https://github.com/zfengzhen/Blog/blob/master/article/ucontext%E7%B0%87%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0.md" target="_blank" rel="noopener">ucontext 簇函数学习</a></li><li><a href="https://www.zhihu.com/question/32218874" target="_blank" rel="noopener">为什么觉得协程是趋势?</a></li><li><a href="https://gameinstitute.qq.com/community/detail/107515" target="_blank" rel="noopener">天涯明月刀 - 无栈协程的应用</a></li><li><a href="https://zhengyinyong.com/ucontext-usage-and-coroutine.html" target="_blank" rel="noopener">ucontext 函数族的使用及协程库的实现</a></li><li><a href="https://langzi989.github.io/tags/ucontext-t/" target="_blank" rel="noopener">C++ 协程实现及原理</a></li><li><a href="https://www.zhihu.com/question/52193579/answer/129597362" target="_blank" rel="noopener">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么?</a></li><li><a href="https://blog.csdn.net/u011228889/article/details/79759834" target="_blank" rel="noopener">基于云风协程库的协程原理解读</a></li><li><a href="https://zhuanlan.zhihu.com/p/27339191" target="_blank" rel="noopener">x86-64 下函数调用及栈帧原理</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着 Golang 的兴起，协程尤其是有栈协程 (stackful coroutine) 越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。&lt;/p&gt;
&lt;p&gt;云风实现了一套 &lt;a href=&quot;https://github.com/cloudwu/coroutine/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;C 语言的协程库&lt;/a&gt;，整体背景可以参考其 &lt;a href=&quot;https://blog.codingnow.com/2012/07/c_coroutine.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;博客&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;这个协程库非常轻量级，一共也才 200 多行代码，使用上更贴近于 lua 的写法（众所周知，云风是知名的 lua 粉)。整体基于 ucontext 和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。&lt;/p&gt;
&lt;p&gt;同时，我也提供了 &lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;coroutine 注释版&lt;/a&gt;，辅助大家理解 coroutine 的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="协程" scheme="http://www.cyhone.com/categories/%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="协程" scheme="http://www.cyhone.com/tags/%E5%8D%8F%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>WebSocket 订单推送稳定性优化方案</title>
    <link href="http://www.cyhone.com/articles/optimization-of-websocket-push-system/"/>
    <id>http://www.cyhone.com/articles/optimization-of-websocket-push-system/</id>
    <published>2019-08-17T06:36:12.000Z</published>
    <updated>2019-12-17T11:00:17.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cloud.tencent.com/document/product/569/33102" target="_blank" rel="noopener">微信云支付 Android 智能 POS</a> 使用 WebSocket 实现了用户订单的实时推送。即，顾客在扫描了门店的付款码，客户端会随即进行语音播报和打印等动作。</p><p>客户端利用 WebSocket 与后端维持长连接，当后端收到该门店订单时，即将成功态的订单通过对应的连接中。</p><p>然而，商户网络环境的多样性会导致 WebSocket 链路出现各种异常，从而引发漏单问题。</p><p>我们根据实际的场景，对此订单推送系统在稳定性上进行了大量优化，尽可能地提升了服务的可用性及自我恢复的能力。</p><a id="more"></a><h2 id="客户端的弱网环境"><a class="markdownIt-Anchor" href="#客户端的弱网环境"></a> 客户端的弱网环境</h2><p>在网络应用的开发过程中，网络的稳定性始终是不可靠的。这点在网络环境多样的客户侧来说，特点尤为明显。</p><ol><li>客户往往会基于成本考虑，所使用的网络质量不高。如部分用户还会使用 2G、3G 网络。</li><li>在移动设备中，客户会进行网络切换。例如，从 wifi 切换到移动数据，或暂时把网络关闭掉。</li><li>后端服务变更或者其他问题可能会引起 WebSocket 链接暂时不可用。</li></ol><p>对于以上几种场景，都会引起 WebSocket 连接异常，导致连接关闭，从而会引发漏单现象。</p><p>一旦订单没有得到及时推送，店员虽然可以到交易查询中确认订单状态，但这样的异常行为如果频发，对于客户来说也是很难接受的。</p><p>我们引入了以下多种措施来解决此问题</p><h2 id="一-应用层心跳尽快发现问题"><a class="markdownIt-Anchor" href="#一-应用层心跳尽快发现问题"></a> 一、应用层心跳：尽快发现问题</h2><p>在浏览器端 WebSocket 相关接口非常简单，但缺了一个设置心跳的接口。我们需要设计一个应用层的心跳机制，来保证线路质量。</p><p>在设计应用层心跳时，主要出于以下几个方面：</p><ol><li>**nginx 的 proxy_read_timeout 参数 **:<br>nginx 在反向代理 WebSocket 请求时，有一个 proxy_read_timeout 参数。当连接在此超时时间内没有数据传输，则会主动断开，<br>默认行为是 60s。因此我们需要一个应用层心跳，在 proxy_read_timeout 的时间内，发送心跳包，以保证连接不被断开。</li><li><strong>应用层心跳可以帮助我们快速检测和发现链路的健康程度</strong> :<br>为了快速检测到链路的异常问题，我们可以将心跳时间缩短到可接受范围内。</li></ol><p>在最初的版本设计中，我们的应用层心跳只涉及了 ping 接口。</p><p>即客户端主动发生向 server 端发生 ping，如果发送成功，则说明链路正常，反之意味着链路不正常。</p><p>整个过程中，ping 是否成功，都依赖于 WebSocket 是否触发了 onError 错误回调。</p><p>但在实际的开发过程中，<strong>我们发现，这样一种特殊场景</strong>：</p><p>使用手机发热点供收银设备使用网络，在正常使用过程中，如果关闭手机的网络数据连接（wifi 或者移动数据），但保持热点的正常开放，那么收银设备将无法快速感知到网络的异常，大概需要 3-5 分钟才能触发异常回调。</p><p>因此，针对此情况我们对应用层心跳进行了进一步的优化，让 server 端收到 ping 之后，回复一个 pong 包。我们根据 ping 和 pong 的时间间隔，来决定当前链路的健康程度。</p><h2 id="二-断线重连自我恢复"><a class="markdownIt-Anchor" href="#二-断线重连自我恢复"></a> 二、断线重连：自我恢复</h2><p>当 WebSocket 连接一旦发生了中断，将不会自动的恢复。因此，WebSocket 的断线重连机制也是我们首要考虑的一个方面。</p><p>断线重连的实现过程比较简单，即当发生 <strong>心跳超时</strong>、<strong>链路错误</strong>或者<strong>链路非正常关闭</strong> 等问题时，我们将触发 WebSocket 的重连机制。</p><p>重连过程也非常简单，即不断重新连接 WebSocket、重新鉴权等过程，直至连接成功。</p><p>这里需要注意的一个小小的点就是：在重新连接的时候, WebSocket 的各种回调 (onmessage、onopen)，都需要重新设置。</p><p>有了断线重连机制，可以实现 WebSocket 简单的自我恢复功能。</p><h2 id="三-推拉结合兜底行为"><a class="markdownIt-Anchor" href="#三-推拉结合兜底行为"></a> 三、推拉结合：兜底行为</h2><p>引入了 WebSocket 的应用层心跳检测和断线重连，可以快速地帮我们发现链路的异常问题，同时尽快恢复到健康状态。</p><p>但是，当 WebSocket 服务侧发生了短时异常（如变更等），或者重连时间过长。</p><p>在应用层发现异常到重连成功的这个过程，整个推送服务最长可能有十秒左右的不可用时间，这个时长取决于心跳的间隔时长。且万一重连也不成功，这个不可用时间将会持续增大。</p><p>在设计中，需要考虑到这种异常情况，且在商户网络环境不稳定的情况下，此问题可能会被放大。</p><p>我们引入了主动拉取的方案，在网络异常时，将会切换为主动拉取模式，定时向后端拉取订单。</p><p>这里需要注意的有几点：</p><ol><li>每次主动拉取时，最好拉取时间有重叠。即：本次拉取的开始时间，是上次拉取的结束时间前 1 秒。<br>这样可以尽量减少因为定时器等环境原因，导致漏单问题</li><li>每次主动拉取后，检测当前 WebSocket 是否链路健康，如果健康则关闭主动拉取模式。</li></ol><p>因为我们主动拉取的范围重叠性以及主动拉取也可能和推送模式有一段时间的重叠，我们得到的订单可能会重复。</p><p>这里我们需要注意对订单进行一个简单的去重逻辑，即：</p><ol><li>万一订单已存在，就忽略该订单。这个可以用简单的 set 实现即可</li><li>根据订单范围的时效性，可以定时删除过期的订单号即可。</li></ol><p>引入主动拉取模式，一方面尽可能的减少了漏单可能的发生，另一方面对主动推送来说，也是一个兜底行为。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>总结来说，我们选择使用了 WebSocket 长连接的方式，实现了支付订单的实时推送，为了解决推送的不稳定性，我们主要采取了以下几种措施：</p><ul><li>定时发送应用层心跳，来快速地帮我们发现链路的异常问题</li><li>引入了断线重连机制，实现了 WebSocket 自我恢复</li><li>加入主动拉取模式，尽可能的减少了漏单可能的发生</li></ul><p>我们利用这几点措施，使得整个服务的可用性大大增强。</p><h2 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h2><ul><li><a href="http://nginx.org/en/docs/http/WebSocket.html" target="_blank" rel="noopener">WebSocket proxying</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://cloud.tencent.com/document/product/569/33102&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微信云支付 Android 智能 POS&lt;/a&gt; 使用 WebSocket 实现了用户订单的实时推送。即，顾客在扫描了门店的付款码，客户端会随即进行语音播报和打印等动作。&lt;/p&gt;
&lt;p&gt;客户端利用 WebSocket 与后端维持长连接，当后端收到该门店订单时，即将成功态的订单通过对应的连接中。&lt;/p&gt;
&lt;p&gt;然而，商户网络环境的多样性会导致 WebSocket 链路出现各种异常，从而引发漏单问题。&lt;/p&gt;
&lt;p&gt;我们根据实际的场景，对此订单推送系统在稳定性上进行了大量优化，尽可能地提升了服务的可用性及自我恢复的能力。&lt;/p&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Websocket" scheme="http://www.cyhone.com/tags/Websocket/"/>
    
  </entry>
  
  <entry>
    <title>重新理解 IO 模型</title>
    <link href="http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/"/>
    <id>http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/</id>
    <published>2018-11-03T18:50:00.000Z</published>
    <updated>2019-12-17T10:57:36.458Z</updated>
    
    <content type="html"><![CDATA[<p>在进行 Linux 网络编程开发的时候，免不了会涉及到 IO 模型的讨论。《Unix 网络编程》一书中提到的几种 IO 模型，我们在开发过程中，讨论最多的应该就是三种： <code>阻塞 IO</code>、<code>非阻塞 IO</code> 以及 <code>异步 IO</code>。</p><p>本文试图理清楚几种 IO 模型的根本性区别，同时分析了为什么在 Linux 网络编程中最好要用非阻塞式 IO。</p><a id="more"></a><h1 id="网络-io-概念准备"><a class="markdownIt-Anchor" href="#网络-io-概念准备"></a> 网络 IO 概念准备</h1><p>在讨论网络 IO 之前，一定要有一个概念上的准备前提: ** 不要用操作磁盘文件的经验去看待网络 IO。** 具体的原因我们在下文中会介绍到。</p><p>相比于传统的网络 IO 来说，一个普通的文件描述符的操作可以分为两部分。以 <code>read</code> 为例，我们利用 read 函数从 socket 中同步阻塞的读取数据，整个流程如下所示：</p><p><img src="/img/noblocking-io/block-read.png" alt="read 示意图"></p><ol><li>调用 read 后，该调用会转入内核调用</li><li>内核会等待该 socket 的可读事件，直到远程向 socket 发送了数据。可读事件成立 (这里还需要满足 TCP 的低水位条件，但是不做太详细的讨论)</li><li>数据包到达内核，接着内核将数据拷贝到用户进程中，也就是 read 函数指定的 buffer 参数中。至此，read 调用结束。</li></ol><p>可以看到除了转入内核调用，与传统的磁盘 IO 不同的是，网络 IO 的读写大致可以分为两个阶段：</p><ol><li>等待阶段：等待 socket 的可读或者可写事件成立</li><li>拷贝数据阶段：将数据从内核拷贝到用户进程，或者从用户进程拷贝到内核中，</li></ol><h1 id="三种-io-模型的区别"><a class="markdownIt-Anchor" href="#三种-io-模型的区别"></a> 三种 IO 模型的区别</h1><p>我们日常开发遇到最多的三种 IO 模型分别是：同步阻塞 IO、同步非阻塞 IO、异步 IO。</p><p>这些名词非常容易混淆，为什么一个 IO 会有两个限定词：同步和阻塞？同步和阻塞分别代表什么意思？<br>简单来说：</p><ol><li>等待 <strong>阻塞</strong>: 在 socket 操作的第一个阶段，也就是用户等待 socket 可读可写事件成立的这个阶段。如果一直等待下去，直到成立后，才进行下个阶段，则称为阻塞式 IO；如果发现 socket 非可读可写状态，则直接返回，不等待，也不进行下个阶段，则称为非阻塞式 IO。</li><li>拷贝 <strong>同步</strong>: 从内核拷贝到用户空间的这个阶段，如果直到从开始拷贝直到拷贝结束，read 函数才返回，则称为同步 IO。如果在调用 read 的时候就直接返回了，等到数据拷贝结束，才通过某种方式 (例如回调) 通知到用户，这种被称为异步 IO。</li></ol><p>所谓异步，实际上就是非同步非阻塞。</p><h2 id="同步阻塞-io"><a class="markdownIt-Anchor" href="#同步阻塞-io"></a> 同步阻塞 IO</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">read(fd, buffer, count)</span><br></pre></td></tr></table></figure><p>Linux 下面如果直接不对 fd 进行特殊处理，直接调用 read，就是同步阻塞 IO。同步阻塞 IO 的两个阶段都需要等待完成后，read 才会返回。</p><p>** 也就是说，如果远程一直没有发送数据，则 read 一直就不会返回，整个线程就会阻塞到这里了。**</p><h1 id="同步非阻塞-io"><a class="markdownIt-Anchor" href="#同步非阻塞-io"></a> 同步非阻塞 IO</h1><p>对于同步非阻塞 IO 来说，如果没有可读可写事件，则直接返回；如果有，则进行第二个阶段，复制数据。<br>在 linux 下面，需要使用 fcntl 将 fd 变为非阻塞的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> flags = fcntl(socket, F_GETFL, <span class="number">0</span>);</span><br><span class="line">fcntl(socket, F_SETFL, flags | O_NONBLOCK);</span><br></pre></td></tr></table></figure><p>同时，如果 read 的时候，fd 不可读，则 read 调用会触发一个 EWOULDBLOCK 错误 (或者 EAGAIN，EWOULDBLOCK 和 EAGAIN 是一样的)。用户只要检查下 <code>errno == EWOULDBLOCK</code>, 即可判断 read 是否返回正常。</p><p>基本在 Linux 下进行网络编程，非阻塞 IO 都是不二之选。</p><h2 id="异步-io"><a class="markdownIt-Anchor" href="#异步-io"></a> 异步 IO</h2><p>Linux 开发者应该很少使用纯粹的异步 IO。因为目前来说，Linux 并没有一个完美的异步 IO 的解决方案。pthread 虽然提供了 aio 的接口，但是这里不做太具体的讨论了。</p><p>我们平常接触到的异步 IO 库或者框架都是在代码层面把操作封装成了异步。但是在具体调用 read 或者 write 的时候，一般还是用的非阻塞式 IO。</p><h1 id="不能用操作磁盘-io-的经验看待网络-io"><a class="markdownIt-Anchor" href="#不能用操作磁盘-io-的经验看待网络-io"></a> 不能用操作磁盘 IO 的经验看待网络 IO</h1><p>为什么不能用操作磁盘 IO 的经验看待网络 IO。实际上在磁盘 IO 中，等待阶段是不存在的，因为磁盘文件并不像网络 IO 那样，需要等待远程传输数据。</p><p>所以有的时候，习惯了操作磁盘 IO 的开发者会无法理解同步阻塞 IO 的工作过程，无法理解为什么 read 函数不会返回。</p><p>关于磁盘 IO 与同步非阻塞的讨论，在知乎上有一篇帖子 <a href="https://www.zhihu.com/question/52989189" target="_blank" rel="noopener">为什么书上说同步非阻塞 io 在对磁盘 io 上不起作用?</a> 讨论了这个问题。</p><h1 id="为什么在-linux-网络编程中最好要用非阻塞式-io"><a class="markdownIt-Anchor" href="#为什么在-linux-网络编程中最好要用非阻塞式-io"></a> 为什么在 Linux 网络编程中最好要用非阻塞式 IO？</h1><p>上文说到，在 linux 网络编程中，如果使用阻塞式的 IO，假如某个 fd 长期不可读，那么一个线程相应将会被长期阻塞，那么线程资源就会被白白浪费。</p><p>那么，如果我们用了 epoll，还必须要使用非阻塞 IO 吗？ 因为如果使用 epoll 监听了 fd 的可读事件，在 epoll_wait 之后调用 read，此时 fd 一定是可读的， 那么此时非阻塞 IO 相比于阻塞 IO 的优势不就没了吗？</p><p>实际上，并不是这样的。<strong>epoll 也必须要搭配非阻塞 IO 使用。</strong><br>这个帖子 <a href="https://www.zhihu.com/question/37271342" target="_blank" rel="noopener">为什么 IO 多路复用要搭配非阻塞 IO?</a> 详细讨论了这个问题？</p><p>总结来说，原因有二：</p><ol><li>fd 在 read 之前有可能会重新进入不可读的状态。要么被其他方式读走了 (参考惊群问题), 还有可能被内核抛弃了，总的来说，fd 因为在 read 之前，数据被其他方式读走，fd 重新变为不可读。此时，用阻塞式 IO 的 read 函数就会阻塞整个线程。</li><li>epoll 只是返回了可读事件，但是并没有返回可以读多少数据量。因此，非阻塞 IO 的做法是读多次，直到不能读。而阻塞 io 却只能读一次，因为万一一次就读完了缓冲区所有数据，第二次读的时候，read 就会又阻塞了。但是对于 epoll 的 ET 模式来说，缓冲区的数据只会在改变的通知一次，如果此次没有消费完，在下次数据到来之前，可读事件再也不会通知了。那么对于只能调用一次 read 的阻塞式 IO 来说，未读完的数据就有可能永远读不到了。</li></ol><p>因此，在 Linux 网络编程中最好使用非阻塞式 IO。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li><a href="http://man7.org/linux/man-pages/man2/read.2.html" target="_blank" rel="noopener">http://man7.org/linux/man-pages/man2/read.2.html</a></li><li><a href="http://matt33.com/2017/08/06/unix-io/" target="_blank" rel="noopener">http://matt33.com/2017/08/06/unix-io/</a></li><li><a href="https://www.zhihu.com/question/52989189" target="_blank" rel="noopener">https://www.zhihu.com/question/52989189</a></li><li><a href="https://www.zhihu.com/question/37271342" target="_blank" rel="noopener">https://www.zhihu.com/question/37271342</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在进行 Linux 网络编程开发的时候，免不了会涉及到 IO 模型的讨论。《Unix 网络编程》一书中提到的几种 IO 模型，我们在开发过程中，讨论最多的应该就是三种： &lt;code&gt;阻塞 IO&lt;/code&gt;、&lt;code&gt;非阻塞 IO&lt;/code&gt; 以及 &lt;code&gt;异步 IO&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;本文试图理清楚几种 IO 模型的根本性区别，同时分析了为什么在 Linux 网络编程中最好要用非阻塞式 IO。&lt;/p&gt;
    
    </summary>
    
      <category term="网络编程" scheme="http://www.cyhone.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.cyhone.com/tags/Linux/"/>
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="epoll" scheme="http://www.cyhone.com/tags/epoll/"/>
    
  </entry>
  
  <entry>
    <title>客户端秒级时间同步方案</title>
    <link href="http://www.cyhone.com/articles/client-time-calibration/"/>
    <id>http://www.cyhone.com/articles/client-time-calibration/</id>
    <published>2018-10-25T12:08:06.000Z</published>
    <updated>2019-12-10T05:07:50.067Z</updated>
    
    <content type="html"><![CDATA[<p>在客户端开发中，往往会有一些功能对时间要求比较严格，客户端需要获取到当前最准确的时间。但由于客户端环境多种多样，我们无法保证直接在客户端设备上获取到的时间是最准确的时间。<br>对于某些问题设备来说，设备时间与比当前实际的时间差了几个小时，甚至几天的情况都存在。倘若某功能依赖于当前时间，而客户端所提供的时间不准，就往往会给客户造成一些困扰。</p><p>那么，客户端如何能够获取到当前最准确的时间呢？</p><a id="more"></a><h2 id="从服务器同步时间"><a class="markdownIt-Anchor" href="#从服务器同步时间"></a> 从服务器同步时间</h2><p>我们首先想到的是，服务器可以提供一个获取当前时间戳的接口。客户端每次获取当前时间时，都直接从服务器拉数据就可以了。</p><p>这个方案简单粗暴，但是问题也可以一眼看出：<br>每次都从服务器拉时间，一方面会对服务器造成一些压力；另一方面网络也存在时延损耗和不稳定的可能，将会减低客户端的体验。</p><h2 id="只拉取一次时间"><a class="markdownIt-Anchor" href="#只拉取一次时间"></a> 只拉取一次时间</h2><p>那么，能不能只从服务器拉取一次时间，不用每次都访问服务器呢？<br>我们可以在客户端初始化的时候，拉取一次时间接口。<br>记此时的服务器时间为 <code>server_init_time</code>，同时获取到当前客户端的时间, 记为 <code>local_init_time</code>。</p><p>当客户端需要获取当前的准确时间的时候，首先得到客户端的当前时间 记为 local_now_time<br>那么，当前最准确的时间就可以通过一个简单的差值计算得到。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server_now_time = server_init_time + (local_now_time - local_init_time)</span><br></pre></td></tr></table></figure><p>通过计算两次本地时间的差值，就可以推出当前服务器的时间了。</p><h2 id="网络时延的损耗"><a class="markdownIt-Anchor" href="#网络时延的损耗"></a> 网络时延的损耗</h2><p>上述方案实际上已经能够准确的获取到当前服务器的时间了。<br>但是仍然有个不严谨的地方：<br>在该方案中，我们假设 server_init_time 和 local_init_time 是同一时刻。<br>但实际上并不是这样的。server_init_time 只是 http 请求到达服务器的时间。<br>server_init_time 和 local_init_time 还差一个请求返回时间。</p><p><img src="/img/network.png" alt="网络时延"></p><p>我们都知道网络是不可靠的，严重情况下，一次网络时延可以达到数秒。这对于时间校准的也会造成一些小小的干扰。</p><p>基于这个问题，我们可以假设 <code>客户端发出请求到服务器的时间</code> 与 <code>服务器回复请求到客户端的时间</code> 基本是一致的。虽然在实际情况下，有可能存在偏差。</p><p>此时</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server_init_time = server_init_time - delta / <span class="number">2</span>;</span><br></pre></td></tr></table></figure><p>其中 delta 是指一次请求的总时延。</p><h2 id="防止客户端运行期间时间改变"><a class="markdownIt-Anchor" href="#防止客户端运行期间时间改变"></a> 防止客户端运行期间时间改变</h2><p>基于以上考虑，我们的时间校准方案已经基本上可以满足大多数客户端的需求了。</p><p>但是，你永远也不会知道客户端会出现什么情况。<br>假如，在软件运行期间，无论是出于被动还是用户有意主动的修改，客户端的时间发生了变化。那么，以上通过计算两次本地时间差值来获取准确时间的方案将会失效。</p><p>因此，我们需要使用一个不随本地时间变化的维度作为校对的标准。我们首先想到了开机时长，开机时长是指当前时刻距离设备开机时刻的毫秒数，而这个东西是不随设备的时钟变化的。<br>因此我们的公式可以修改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server_now_time = server_init_time + (local_now_tickcount - local_init_tickout)</span><br></pre></td></tr></table></figure><p>local_now_tickcount 和 local_init_tickout 分别指的是设备当前的开机时长和初始化阶段用户的开机时长。</p><h2 id="时间溢出"><a class="markdownIt-Anchor" href="#时间溢出"></a> 时间溢出</h2><p>使用开机时长作为校对的标准的方案，看似完美无缺，实际上仍然存在着一些意想不到的问题…</p><p>以 Windows 为例，C# 用来返回开机时长的方法 <code>Environment.TickCount</code> 是 int32 类型的，单位为 ms。<br>我们可以简单计算下，一天大概有 <code>24 * 60 * 60 * 1000 = 86400000</code> 毫秒，而 int32 的最大值是 <code>2^31 - 1 = 2147483647</code></p><p>这也就意味着，当开机时间超过 <code>2147483647 / 86400000 = 24.85</code> 天的时候 int32 就溢出了。。<br>也就意味着，如果我们的客户端软件运行在一个 25 天未关机的设备上，那么软件的时间校准将会出现严重的问题。。。</p><p>在真实的情况下，客户端设备 25 天不关机的情况太常见了。<br>那么，如果解决此问题呢？</p><p>我们发现 C# 有一个 StopWatch 函数，常常用来统计函数运行时长。而它的时间表示 <code>stopWatch.ElapsedMilliseconds</code> 是 long 型的。同时，StopWatch 是基于 Timer 实现的时间统计，也不与本地时钟相关。</p><p>那么，与利用开机时长的方案类似，我们在软件初始化时，开启一个 StopWatch。每次获取准确时间的时候，将 stopWatch 中记录的当前耗时时间与服务器初始时间相加，即可得到当前的准确时间。</p><p>最终的时间校准方案如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server_init_time = server_init_time - delta / 2;</span><br><span class="line">server_now_time = server_init_time + stopWatch.ElapsedMilliseconds / 1000</span><br></pre></td></tr></table></figure><h2 id="定期校准"><a class="markdownIt-Anchor" href="#定期校准"></a> 定期校准</h2><p>考虑到时间越长，有可能本地时间与服务器时间的偏差逐渐加大。可以采用定时器，定时对本地时间进行重新校准。</p><p>基于以上方案，我们就实现了客户端与后台时间的秒级时间同步方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在客户端开发中，往往会有一些功能对时间要求比较严格，客户端需要获取到当前最准确的时间。但由于客户端环境多种多样，我们无法保证直接在客户端设备上获取到的时间是最准确的时间。&lt;br&gt;
对于某些问题设备来说，设备时间与比当前实际的时间差了几个小时，甚至几天的情况都存在。倘若某功能依赖于当前时间，而客户端所提供的时间不准，就往往会给客户造成一些困扰。&lt;/p&gt;
&lt;p&gt;那么，客户端如何能够获取到当前最准确的时间呢？&lt;/p&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
  </entry>
  
  <entry>
    <title>muduo 源码剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-muduo/"/>
    <id>http://www.cyhone.com/articles/analysis-of-muduo/</id>
    <published>2018-06-12T15:51:37.000Z</published>
    <updated>2019-12-17T11:00:17.502Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/chenshuo/muduo" target="_blank" rel="noopener">muduo</a>是 <a href="http://chenshuo.com" target="_blank" rel="noopener">陈硕</a> 大神个人开发的 C++ 的 TCP 网络编程库。muduo 基于 Reactor 模式实现。Reactor 模式也是目前大多数 Linux 端高性能网络编程框架和网络应用所选择的主要架构，例如内存数据库 Redis 和 Java 的 Netty 库等。</p><p>陈硕的《Linux 多线程服务器端编程》一书对 muduo 整个架构进行了非常详尽的介绍和分析，可以说是学习 muduo 源码和设计理念最好的资料了。这本书也非常推荐大家购买阅读，感觉是后台开发的必读书目了。</p><p>而本文则主要是从源码角度辅助理解整个 muduo 的实现，同时也姑且算是对 muduo 的一个小小的补充。</p><p>同时我也提供了一个 <a href="https://github.com/chenyahui/AnnotatedCode/tree/master/muduo" target="_blank" rel="noopener">muduo 注释版</a>，用以辅助理解 muduo 的源码。</p><a id="more"></a><h1 id="muduo-的架构和概念"><a class="markdownIt-Anchor" href="#muduo-的架构和概念"></a> muduo 的架构和概念</h1><p>muduo 中类的职责和概念划分的非常清晰，在《Linux 多线程服务器端编程》一书的 6.3.1 章节有详细的介绍。实际上目前很多网络库的接口设计也都受到了 muduo 的影响，例如 360 的 evpp 等。</p><p>而 muduo 的整体风格受到 netty 的影响，整个架构依照 Reactor 模式，基本与如下图所示相符：</p><p><img src="/img/reactor/single_thread_reactor.png" alt="单线程 Reactor 模式"></p><p>所谓 Reactor 模式，是有一个循环的过程，监听对应事件是否触发，触发时调用对应的 callback 进行处理。</p><p>这里的事件在 muduo 中包括 Socket 可读写事件、定时器事件。在其他网络库中如 libevent 也包括了 signal、用户自定义事件等。</p><p>负责事件循环的部分在 muduo 命名为 <code>EventLoop</code>，其他库如 netty、libevent 也都有对应的组件。</p><p>负责监听事件是否触发的部分，在 muduo 中叫做 <code>Poller</code>。muduo 提供了 epoll 和 poll 两种来实现，默认是 epoll 实现。<br>通过环境变量 <code>MUDUO_USE_POLL</code> 来决定是否使用 poll:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Poller* Poller::newDefaultPoller(EventLoop* loop)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 通过此环境变量来决定使用 poll 还是 epoll</span></span><br><span class="line">  <span class="keyword">if</span> (::getenv(<span class="string">"MUDUO_USE_POLL"</span>))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> PollPoller(loop);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> EPollPoller(loop);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外，图中的 acceptor 负责 accept 新连接，并将新连接分发到 subReactor。这个组件在 muduo 中也叫做 <code>Acceptor</code>。<br>关于图中的其他部分，会在 [muduo 的线程模型](#muduo 的线程模型) 一节有详细介绍。</p><h1 id="一个简单的例子"><a class="markdownIt-Anchor" href="#一个简单的例子"></a> 一个简单的例子</h1><p>本文首先从最简单的 echo server 入手，来介绍 muduo 的基本使用，同时也方便后面概念的理解。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onMessage</span><span class="params">(<span class="keyword">const</span> muduo::net::TcpConnectionPtr&amp; conn,</span></span></span><br><span class="line"><span class="function"><span class="params">                           muduo::net::Buffer* buf,</span></span></span><br><span class="line"><span class="function"><span class="params">                           muduo::Timestamp time)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  conn-&gt;send(buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    muduo::net::EventLoop loop;</span><br><span class="line">    muduo::net::<span class="function">InetAddress <span class="title">listenAddr</span><span class="params">(<span class="number">2007</span>)</span></span>;</span><br><span class="line">    <span class="function">TcpServer <span class="title">server</span><span class="params">(&amp;loop, listenAddr)</span></span>;</span><br><span class="line">    server.setMessageCallback(onMessage);</span><br><span class="line">    server.start();</span><br><span class="line">    loop.loop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>echo-server 的代码量非常简洁。一个典型的 muduo 的 TcpServer 工作流程如下：</p><ol><li>建立一个事件循环器 EventLoop</li><li>建立对应的业务服务器 TcpServer</li><li>设置 TcpServer 的 Callback</li><li>启动 server</li><li>开启事件循环</li></ol><p>陈硕认为，TCP 网络编程的本质是处理三个半事件，即：</p><ol><li>连接的建立</li><li>连接的断开：包括主动断开和被动断开</li><li>消息到达，文件描述符可读。</li><li>消息发送完毕。这个算半个事件。</li></ol><p>我们接下来分析下 muduo 是怎么处理和实现这三个半事件的</p><h1 id="连接的建立"><a class="markdownIt-Anchor" href="#连接的建立"></a> 连接的建立</h1><p>在我们单纯使用 linux 的 API，编写一个简单的 Tcp 服务器时，建立一个新的连接通常需要四步：</p><blockquote><p>步骤 1. socket() // 调用 socket 函数建立监听 socket<br>步骤 2. bind()   // 绑定地址和端口<br>步骤 3. listen() // 开始监听端口<br>步骤 4. accept() // 返回新建立连接的 fd</p></blockquote><p>我们接下来分析下，这四个步骤在 muduo 中都是何时进行的：</p><p>首先在 TcpServer 对象构建时，TcpServer 的属性 acceptor 同时也被建立。<br>在 Acceptor 的构造函数中分别调用了 socket 函数和 bind 函数完成了 ** 步骤 1<strong>和</strong> 步骤 2**。<br>即，当 <code>TcpServer server(&amp;loop, listenAddr);</code> 执行结束时，监听 socket 已经建立好，并已绑定到对应地址和端口了。</p><p>而当执行 <code>server.start()</code> 时，主要做了两个工作：</p><ol><li>在监听 socket 上启动 listen 函数，也就是 ** 步骤 3**；</li><li>将监听 socket 的可读事件注册到 EventLoop 中。</li></ol><p>此时，程序已完成对地址的监听，但还不够，因为此时程序的主角 <code>EventLoop</code> 尚未启动。<br>当调用 <code>loop.loop()</code> 时，程序开始监听该 socket 的可读事件。</p><p>当新连接请求建立时，可读事件触发，此时该事件对应的 callback 在 EventLoop::loop() 中被调用。<br>该事件的 callback 实际上就是 Acceptor::handleRead() 方法。</p><p>在 Acceptor::handleRead() 方法中，做了三件事：</p><ol><li>调用了 accept 函数，完成了 ** 步骤 4**，实现了连接的建立。得到一个已连接 socket 的 fd</li><li>创建 TcpConnection 对象</li><li>将已连接 socket 的可读事件注册到 EventLoop 中。</li></ol><p>这里还有一个需要注意的点，创建的 TcpConnnection 对象是个 shared_ptr，该对象会被保存在 TcpServer 的 connections 中。这样才能保证引用计数大于 0，对象不被释放。</p><p>至此，一个新的连接已完全建立好，其可读事件也已注册到 EventLoop 中了。</p><h1 id="消息的读取"><a class="markdownIt-Anchor" href="#消息的读取"></a> 消息的读取</h1><p>上节讲到，在新连接建立的时候，会将新连接的 socket 的可读事件注册到 EventLoop 中。<br>假如客户端发送消息，导致已连接 socket 的可读事件触发，该事件对应的 callback 同样也会在 EventLoop::loop() 中被调用。</p><p>该事件的 callback 实际上就是 TcpConnection::handleRead 方法。<br>在 TcpConnection::handleRead 方法中，主要做了两件事：</p><ol><li>从 socket 中读取数据，并将其放入 inputbuffer 中</li><li>调用 messageCallback，执行业务逻辑。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);</span><br><span class="line"><span class="keyword">if</span> (n&gt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>messageCallback 是在建立新连接时，将 <code>TcpServer::messageCallback</code> 方法 bind 到了 <code>TcpConnection::messageCallback</code> 的方法。</p><p>TcpServer::messageCallback 就是业务逻辑的主要实现函数。通常情况下，我们可以在里面实现消息的编解码、消息的分发等工作，这里就不再深入探讨了。</p><p>在我们上面给出的示例代码中，echo-server 的 messageCallback 非常简单，就是直接将得到的数据，重新 send 回去。在实际的业务处理中，一般都会调用 TcpConnection::send() 方法，给客户端回复消息。</p><p>这里需要注意的是，在 messageCallback 中，用户会有可能会把任务抛给自定义的 Worker 线程池处理。<br>但是这个在 Worker 线程池中任务，切忌直接对 Buffer 的操作。因为 Buffer 并不是线程安全的。</p><p>我们需要记住一个准则:</p><blockquote><p>所有对 IO 和 buffer 的读写，都应该在 IO 线程中完成。</p></blockquote><p>一般情况下，先在交给 Worker 线程池之前，应该现在 IO 线程中把 Buffer 进行切分解包等动作。将解包后的消息交由线程池处理，避免多个线程操作同一个资源。</p><h1 id="消息的发送"><a class="markdownIt-Anchor" href="#消息的发送"></a> 消息的发送</h1><p>用户通过调用 TcpConnection::send() 向客户端回复消息。由于 muduo 中使用了 OutputBuffer，因此消息的发送过程比较复杂。</p><p>首先需要注意的是线程安全问题, 对于消息的读写必须都在 EventLoop 的同一个线程 (通常称为 IO 线程) 中进行：<br>因此，TcpConnection::send 保证了线程安全性，它是这么做的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> TcpConnection::send(<span class="keyword">const</span> StringPiece&amp; message)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (state_ == kConnected)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (loop_-&gt;isInLoopThread())</span><br><span class="line">    &#123;</span><br><span class="line">      sendInLoop(message);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      loop_-&gt;runInLoop(</span><br><span class="line">          boost::bind(&amp;TcpConnection::sendInLoop,</span><br><span class="line">                      <span class="keyword">this</span>,     <span class="comment">// FIXME</span></span><br><span class="line">                      message.as_string()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>检测 send 的时候，是否在当前 IO 线程，如果是的话，直接进行写相关操作 <code>sendInLoop</code>。<br>如果不在一个线程的话，需要将该任务抛给 IO 线程执行 <code>runInloop</code>, 以保证 write 动作是在 IO 线程中执行的。我们后面会讲解 <code>runInloop</code> 的具体实现。</p><p>在 sendInloop 中，做了下面几件事：</p><ol><li>假如 OutputBuffer 为空，则直接向 socket 写数据</li><li>如果向 socket 写数据没有写完，则统计剩余的字节个数，并进行下一步。没有写完可能是因为此时 socket 的 TCP 缓冲区已满了。</li><li>如果此时 OutputBuffer 中的旧数据的个数和未写完字节个数之和大于 highWaterMark，则将 highWaterMarkCallback 放入待执行队列中</li><li><strong>将对应 socket 的可写事件注册到 EventLoop 中</strong></li></ol><p>注意，直到发送的时候，才把 socket 的可写事件注册到了 EventLoop 中。之前只注册了可读事件。</p><p>连接 socket 的可写事件对应的 callback 是 TcpConnection::handleWrite()<br>当某个 socket 的可写事件触发时，TcpConnection::handleWrite 会做两个工作：</p><ol><li>尽可能将数据从 OutputBuffer 中向 socket 中 write 数据</li><li>如果 OutputBuffer 没有剩余的，则 <strong>将该 socket 的可写事件移除</strong>，并调用 writeCompleteCallback</li></ol><h2 id="为什么要移除可写事件"><a class="markdownIt-Anchor" href="#为什么要移除可写事件"></a> 为什么要移除可写事件</h2><p>因为当 OutputBuffer 中没数据时，我们不需要向 socket 中写入数据。但是此时 socket 一直是处于可写状态的， 这将会导致 TcpConnection::handleWrite() 一直被触发。然而这个触发毫无意义，因为并没有什么可以写的。</p><p>所以 muduo 的处理方式是，当 OutputBuffer 还有数据时，socket 可写事件是注册状态。当 OutputBuffer 为空时，则将 socket 的可写事件移除。</p><p>此外，highWaterMarkCallback 和 writeCompleteCallback 一般配合使用，起到限流的作用。在《linux 多线程服务器端编程》一书的 8.9.3 一节中有详细讲解。这里就不再赘述了</p><h1 id="连接的断开"><a class="markdownIt-Anchor" href="#连接的断开"></a> 连接的断开</h1><p>我们看下 muduo 对于连接的断开是怎么处理的。<br>连接的断开分为被动断开和主动断开。主动断开和被动断开的处理方式基本一致，因此本文只讲下被动断开的部分。</p><p>被动断开即远程端断开了连接，server 端需要感知到这个断开的过程，然后进行的相关的处理。</p><p>其中感知远程断开这一步是在 Tcp 连接的可读事件处理函数 <code>handleRead</code> 中进行的：当对 socket 进行 read 操作时，返回值为 0，则说明此时连接已断开。</p><p>接下来会做四件事情：</p><ol><li>将该 TCP 连接对应的事件从 EventLoop 移除</li><li>调用用户的 ConnectionCallback</li><li>将对应的 TcpConnection 对象从 Server 移除。</li><li>close 对应的 fd。此步骤是在析构函数中被动触发的，当 TcpConnection 对象被移除后，引用计数为 0，对象析构时会调用 close。</li></ol><h1 id="runinloop-的实现"><a class="markdownIt-Anchor" href="#runinloop-的实现"></a> runInLoop 的实现</h1><p>在讲解消息的发送过程时候，我们讲到为了保证对 buffer 和 socket 的写动作是在 io 线程中进行，使用了一个 <code>runInLoop</code> 函数，将该写任务抛给了 io 线程处理。</p><p>我们接下来看下 <code>runInLoop</code> 的实现：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::runInLoop(<span class="keyword">const</span> Functor&amp; cb)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (isInLoopThread())</span><br><span class="line">  &#123;</span><br><span class="line">    cb();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    queueInLoop(cb);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里可以看到，做了一层判断。如果调用时是此 EventLoop 的运行线程，则直接执行此函数。<br>否则调用 <code>queueInLoop</code> 函数。我们看下 <code>queueInLoop</code> 的实现。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::queueInLoop(<span class="keyword">const</span> Functor&amp; cb)</span><br><span class="line">&#123;</span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  pendingFunctors_.push_back(cb);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!isInLoopThread() || callingPendingFunctors_)</span><br><span class="line">  &#123;</span><br><span class="line">    wakeup();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有两个动作：</p><ol><li>加锁，然后将该函数放到该 EventLoop 的 pendingFunctors_队列中。</li><li>判断是否要唤醒 EventLoop，如果是则调用 wakeup() 唤醒该 EventLoop。</li></ol><p>这里有几个问题：</p><ul><li>为什么要唤醒 EventLoop？</li><li>wakeup 是怎么实现的?</li><li>pendingFunctors_是如何被消费的?</li></ul><h2 id="为什么要唤醒-eventloop"><a class="markdownIt-Anchor" href="#为什么要唤醒-eventloop"></a> 为什么要唤醒 EventLoop</h2><p>我们首先调用了 <code>pendingFunctors_.push_back(cb);</code>, 将该函数放在 pendingFunctors_中。EventLoop 的每一轮循环最后会调用 doPendingFunctors 依次执行这些函数。</p><p>而 EventLoop 的唤醒是通过 epoll_wait 实现的，如果此时该 EventLoop 中迟迟没有事件触发，那么 epoll_wait 一直就会阻塞。<br>这样会导致，pendingFunctors_迟迟不能被执行了。</p><p>所以对 EventLoop 的唤醒是必要的。</p><h2 id="wakeup-是怎么实现的"><a class="markdownIt-Anchor" href="#wakeup-是怎么实现的"></a> wakeup 是怎么实现的</h2><p>muduo 这里采用了对 eventfd 的读写来实现对 EventLoop 的唤醒。</p><p>在 EventLoop 建立之后，就创建一个 eventfd，并将其可读事件注册到 EventLoop 中。</p><p><code>wakeup()</code> 的过程本质上是对这个 eventfd 进行写操作，以触发该 eventfd 的可读事件。这样就起到了唤醒 EventLoop 的作用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::wakeup()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">uint64_t</span> one = <span class="number">1</span>;</span><br><span class="line">  sockets::write(wakeupFd_, &amp;one, <span class="keyword">sizeof</span> one);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很多库为了兼容 macos，往往使用 pipe 来实现这个功能。muduo 采用了 eventfd，性能更好些，但代价是不能支持 macos 了。不过 muduo 似乎从一开始的定位就不打算支持？</p><h2 id="dopendingfunctors-的实现"><a class="markdownIt-Anchor" href="#dopendingfunctors-的实现"></a> doPendingFunctors 的实现</h2><p>本部分讲下 <code>doPendingFunctors</code> 的实现，muduo 是如何处理这些待处理的函数的，以及中间用了哪些优化操作。<br>代码如下所示：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::doPendingFunctors()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Functor&gt; functors;</span><br><span class="line"></span><br><span class="line">  callingPendingFunctors_ = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  functors.swap(pendingFunctors_);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; functors.size(); ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    functors[i]();</span><br><span class="line">  &#125;</span><br><span class="line">  callingPendingFunctors_ = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码可以看到，函数非常简单。大概只有十行代码，但是这十行却有两个非常巧妙的措施。</p><p>**callingPendingFunctors_的作用 **</p><p>从代码可以看出，如果 callingPendingFunctors_为 false，则说明此时尚未开始执行 doPendingFunctors 函数。<br>这个有什么作用呢，我们需要结合下 queueInLoop 中，对是否执行 wakeup() 的判断</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (!isInLoopThread() || callingPendingFunctors_)</span><br><span class="line">&#123;</span><br><span class="line">  wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里还需要结合下 EventLoop 循环的实现，其中 <code>doPendingFunctors()</code> 是 <strong>每轮循环的最后一步处理</strong>。<br>如果调用 queueInLoop 和 EventLoop 在同一个线程，且 callingPendingFunctors_为 false 时，则说明：** 此时尚未执行到 doPendingFunctors()。**<br>那么此时即使不用 wakeup，也可以在之后照旧执行 doPendingFunctors() 了。</p><p>这么做的好处非常明显，可以减少对 eventfd 的 io 读写。</p><p><strong>锁范围的减少</strong><br>在此函数中，有一段特别的代码：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Functor&gt; functors;</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  functors.swap(pendingFunctors_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个作用是 pendingFunctors_和 functors 的内容进行交换，实际上就是此时 functors 持有了 pendingFunctors_的内容，而 pendingFunctors_被清空了。</p><p>这个好处是什么呢？<br>如果不这么做，直接遍历 pendingFunctors_, 然后处理对应的函数。这样的话，锁会一直等到所有函数处理完才会被释放。在此期间，queueInLoop 将不可用。</p><p>而以上的写法，可以极大减小锁范围，整个锁的持有时间就是 swap 那一下的时间。待处理函数执行的时候，其他线程还是可以继续调用 queueInLoop。</p><h1 id="muduo-的线程模型"><a class="markdownIt-Anchor" href="#muduo-的线程模型"></a> muduo 的线程模型</h1><p>muduo 默认是单线程模型的，即只有一个线程，里面对应一个 EventLoop。这样整体对于线程安全的考虑可能就比较简单了，<br>但是 muduo 也可以支持以下几种线程模型：</p><h2 id="主从-reactor-模式"><a class="markdownIt-Anchor" href="#主从-reactor-模式"></a> 主从 reactor 模式</h2><p>主从 reactor 是 netty 的默认模型，一个 reactor 对应一个 EventLoop。主 Reactor 只有一个，只负责监听新的连接，accept 后将这个连接分配到子 Reactor 上。子 Reactor 可以有多个。这样可以分摊一个 Eventloop 的压力，性能方面可能会更好。如下图所示：</p><p><img src="/img/reactor/main_sub_reactor.jpg" alt="主从 Reactor 模式"></p><p>在 muduo 中也可以支持主从 Reactor，其中主 Reactor 的 EventLoop 就是 TcpServer 的构造函数中的 <code>EventLoop*</code> 参数。Acceptor 会在此 EventLoop 中运行。</p><p>而子 Reactor 可以通过 <code>TcpServer::setThreadNum(int)</code> 来设置其个数。因为一个 Eventloop 只能在一个线程中运行，所以线程的个数就是子 Reactor 的个数。</p><p>如果设置了子 Reactor，新的连接会通过 Round Robin 的方式分配给其中一个 EventLoop 来管理。如果没有设置子 Reactor，则是默认的单线程模型，新的连接会再由主 Reactor 进行管理。</p><p>但其实这里似乎有些不合适的地方：多个 TcpServer 之间可以共享同一个主 EventLoop，但是子 Eventloop 线程池却不能共享，这个是每个 TcpServer 独有的。<br>这里不太清楚是 muduo 的设计问题，还是作者有意为之。不过 netty 的主 EventLoop 和子 Eventloop 池都是可以共享的。</p><h2 id="业务线程池"><a class="markdownIt-Anchor" href="#业务线程池"></a> 业务线程池</h2><p>对于一些阻塞型或者耗时型的任务，例如 MySQL 操作等。这些显然是不能放在 IO 线程（即 EventLoop 所在的线程）中运行的，因为会严重影响 EventLoop 的正常运行。具体原理可以查看 <a href="http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/">另外一篇博客</a>。</p><p>对于这类耗时型的任务，一般做法是可以放在另外单独线程池中运行，这样就不会阻塞 IO 线程的运行了。我们一般把这种处理耗时任务的线程叫做 Worker 线程。</p><p>muduo 本身没有提供一套直接使用 Worker 线程池的方式，但是 muduo 本身提供了线程池的相关类 <code>ThreadPool</code>。muduo 官方的推荐做法是，在 OnMessage 中，自行进行包的切分，然后将数据和对应的处理函数打包成 Task 的方式提交给线程池。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>个人认为，muduo 源码对于学习网络编程和项目设计非常有帮助, 里面几乎包含了大部分网络编程和框架设计的最佳实践，配合《Linux 多线程服务器端编程》一书，可以学到很多东西。<br>基于这几个方面来说，muduo 绝对是一个值得一探究竟的优质源码。<br>此外，不但是网络编程方面，如何将复杂的底层细节封装好，暴露出友好的通用业务层接口，如何设计类的职责，对象的生命周期管理等方面，muduo 都给了我们一个很好的示范。</p><h1 id="参考"><a class="markdownIt-Anchor" href="#参考"></a> 参考</h1><ul><li>《Linux 多线程服务器端编程》</li><li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf" target="_blank" rel="noopener">Scalable IO in Java</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/chenshuo/muduo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;muduo&lt;/a&gt;是 &lt;a href=&quot;http://chenshuo.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈硕&lt;/a&gt; 大神个人开发的 C++ 的 TCP 网络编程库。muduo 基于 Reactor 模式实现。Reactor 模式也是目前大多数 Linux 端高性能网络编程框架和网络应用所选择的主要架构，例如内存数据库 Redis 和 Java 的 Netty 库等。&lt;/p&gt;
&lt;p&gt;陈硕的《Linux 多线程服务器端编程》一书对 muduo 整个架构进行了非常详尽的介绍和分析，可以说是学习 muduo 源码和设计理念最好的资料了。这本书也非常推荐大家购买阅读，感觉是后台开发的必读书目了。&lt;/p&gt;
&lt;p&gt;而本文则主要是从源码角度辅助理解整个 muduo 的实现，同时也姑且算是对 muduo 的一个小小的补充。&lt;/p&gt;
&lt;p&gt;同时我也提供了一个 &lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/muduo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;muduo 注释版&lt;/a&gt;，用以辅助理解 muduo 的源码。&lt;/p&gt;
    
    </summary>
    
      <category term="网络编程" scheme="http://www.cyhone.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="网络编程" scheme="http://www.cyhone.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Reactor" scheme="http://www.cyhone.com/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>自动生成数据库文档小工具的诞生</title>
    <link href="http://www.cyhone.com/articles/db-doc-generator/"/>
    <id>http://www.cyhone.com/articles/db-doc-generator/</id>
    <published>2018-01-30T11:00:54.000Z</published>
    <updated>2019-12-10T05:07:50.067Z</updated>
    
    <content type="html"><![CDATA[<p>最近我用 Golang 开发了一个可以将数据库每张表的各个列信息转化成文档的小工具。开发的缘由是因为写后端时，经常需要为数据库写说明文档，对于稍微有些规模的项目来说，就动辄几十张上百张数据表，开发人员在文档中不断的写各个列的列名、类型、描述实在是无聊、枯燥和苦不堪言。所以就有了这个小工具的诞生。</p><p>项目地址在 <a href="https://github.com/chenyahui/db_doc_generator" target="_blank" rel="noopener">这里</a></p><a id="more"></a><h1 id="工具使用介绍"><a class="markdownIt-Anchor" href="#工具使用介绍"></a> 工具使用介绍</h1><p>工具用 golang 开发的，所以直接使用 release 的可执行文件就可以, 无需复杂任何编译安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dbdoc -c config.json</span><br></pre></td></tr></table></figure><p>在 config.json 文件中，按照格式配置好数据库信息，具体的配置方法如下:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"db_info"</span>: &#123;</span><br><span class="line">    "db_type": "mysql",  // required</span><br><span class="line">    "ip_port": "127.0.0.1:3306", // required</span><br><span class="line">    "username": "root", // required</span><br><span class="line">    "password": "", // required</span><br><span class="line">    "schema": "cms" // required</span><br><span class="line">  &#125;,</span><br><span class="line">  "includes": [  // optional</span><br><span class="line">  ],</span><br><span class="line">  "excludes": [  // optional</span><br><span class="line">  ],</span><br><span class="line">  "template_path": "", // optional</span><br><span class="line">  "out_path": ""  // optional</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单两步，就可以自动生成数据库的说明文档了。如下图<br><img src="/img/db_doc/markdown_preview.png" alt="展示图"></p><p>展示图中的文档模板是使用工具内置的 markdown 模板</p><h1 id="开发过程"><a class="markdownIt-Anchor" href="#开发过程"></a> 开发过程</h1><p>整个项目的思路其实非常简单，说起来其实就三步</p><ol><li>读取数据库的各个表</li><li>依次读取每个表的列信息</li><li>将列信息转化成 markdown</li></ol><p>虽然步骤简单，但是还是有些值得谈的东西。</p><h2 id="数据库适配"><a class="markdownIt-Anchor" href="#数据库适配"></a> 数据库适配</h2><p>目前这个小工具支持 MySQL 和 SQL Server, 这俩数据库在 SQL 语句上有着很大的区别。比如<br>MySQL 的读取当前数据库下的所有表名的语句是 <code>show tables</code>，而 SQL Server 的是 <code>SELECT Distinct TABLE_NAME FROM information_schema.TABLES</code>。除此之外，两个数据库的连接语句，查询列信息的语句，都有很大区别。<br>所以适配各个数据库，让这个工具支持多个数据库，是件非常复杂的事情。</p><p>我目前的做法给每个用到的 SQL 语句做一个工厂方法，给定一个数据库的类型，返回对应的 sql 语句。这种方法虽然复杂繁琐，但是有效。好在我们用到的 SQL 语句也不多，所以效率上也算还好。</p><p>目前还在调研各大 ORM 库是怎么实现的这个功能。这个也是以后着重要做的功能。</p><h2 id="文档模板"><a class="markdownIt-Anchor" href="#文档模板"></a> 文档模板</h2><p>我最初的本意是直接将信息转化成固定的 markdown 格式就可以了，想想既然都提取了表信息为何不做些更自由的做法——用户可以自己定义文档的格式。<br>比如，这个工具默认生成的格式是这样的:<br><img src="/img/db_doc/markdown_preview.png" alt="markdown_preview"></p><p>但是万一用户不想用这个格式，想给每个表格的标题加个编号，或者给每一列加个编号啥的。那这个工具生成的结果就完全没法用了。<br>不能将我的喜好强加给用户，那么，可以给用户提供足够自由的接口。</p><p>所以我提供了一个扩展的做法, 用户可以在配置文件的 <code>template_path</code> 项，配置一个自己定义的文档模板给工具。如果不提供的话，可以使用默认的模板，如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;- .schema&#125;&#125; Document</span><br><span class="line">&#123;&#123;range .tables -&#125;&#125;</span><br><span class="line"># &#123;&#123;.TableName&#125;&#125;</span><br><span class="line">|column|type|description|</span><br><span class="line">| ------| ------ | ------ |</span><br><span class="line">&#123;&#123;- range .Columns&#125;&#125;</span><br><span class="line">|&#123;&#123;.ColumnName&#125;&#125;|&#123;&#123;.ColumnType&#125;&#125;|&#123;&#123;.Description -&#125;&#125;|</span><br><span class="line">&#123;&#123;- end&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure><p>这个模板的语法直接用的是 golang 标准库的 <code>text/template</code>, 文档在 <a href="https://golang.org/pkg/text/template/" target="_blank" rel="noopener">这里</a>。开始我本来想着随便搜个模板引擎用下，没想到 golang 直接在标准库里自带了。再次感叹下 golang 真是为工业化而生。</p><p>有了这个文档模板的功能，这个工具的想象空间变得很大。文档的格式不再局限于 markdown 了，用户可以随便定义文档的格式, html、json 都行。当然 word 的 doc 格式就是另外一个次元的事情了，我也在考虑是否以后加入进去。</p><h2 id="以后要加的功能"><a class="markdownIt-Anchor" href="#以后要加的功能"></a> 以后要加的功能</h2><ul><li>支持更多的数据库.</li><li>支持导出格式为 Word、Excel.</li><li>更人性化的命令行接口。目前我为了图省事，就直接传了个 - c。后期打算做成 MySQL 那样直观的接口</li></ul><h1 id="谈谈-golang"><a class="markdownIt-Anchor" href="#谈谈-golang"></a> 谈谈 Golang</h1><p>这个项目是我用 Golang 做的第一个项目，Golang 在这种跨平台小工具，且完全无需考虑安装依赖的情况下是最好的选择了。Golang 的熟悉之后用起来几乎和 Python 一样快速。我在 <code>文档模板</code> 一节感叹，Golang 真是为工业化而生，把很多在其他语言里是三方库的东西直接做到了标准库。但是另一方面，由于 Golang 中模板和泛型的缺失，有些东西本该内置的又没有了。比如判断一个元素是否在数组中的方法 InArray,String 的 IsBlank 方法，都需要用户在项目中再单独写一遍。实在是无法理解</p><p>总而言之，如果以后有类似的小工具的需求，我依然会选择 Golang 或者 Python 作为首选的开发语言。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近我用 Golang 开发了一个可以将数据库每张表的各个列信息转化成文档的小工具。开发的缘由是因为写后端时，经常需要为数据库写说明文档，对于稍微有些规模的项目来说，就动辄几十张上百张数据表，开发人员在文档中不断的写各个列的列名、类型、描述实在是无聊、枯燥和苦不堪言。所以就有了这个小工具的诞生。&lt;/p&gt;
&lt;p&gt;项目地址在 &lt;a href=&quot;https://github.com/chenyahui/db_doc_generator&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="数据库" scheme="http://www.cyhone.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>2017 年读了哪些书？</title>
    <link href="http://www.cyhone.com/articles/2017-reading-records/"/>
    <id>http://www.cyhone.com/articles/2017-reading-records/</id>
    <published>2018-01-03T06:00:54.000Z</published>
    <updated>2019-12-10T05:07:50.063Z</updated>
    
    <content type="html"><![CDATA[<p>2017 年总共阅读了 21 本书，相比于 2016 年减少了 4 本。<br>今年读的这些书相对于去年来说种类比较全而且质量比较高, 但是有一个非常大的缺点就是没有留下可用的笔记，尤其是像《北宋名家词选讲》这种书，没有好的笔记留下，书里的精髓就会流失很多。<br>希望 2018 年的阅读能够做到以下几点:</p><ol><li>读的每本非小说类书，都要认真的做笔记或者思维图</li><li>2018 年可以阅读 30 本书以上</li><li>多把空闲时间放在用 kindle 读书上</li></ol><a id="more"></a><h2 id="计算机-1-本"><a class="markdownIt-Anchor" href="#计算机-1-本"></a> 计算机 (1 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/25723064/" target="_blank" rel="noopener">大型网站技术架构</a></td><td>四星</td><td>2017-01-07</td><td>这本书是一本很好的网站架构科普读物。虽然薄薄的一本书，但是方方面面也都涉及。在一致性 Hash、分布式 Session 方面都讲的蛮清楚</td></tr></tbody></table><h2 id="思想-3-本"><a class="markdownIt-Anchor" href="#思想-3-本"></a> 思想 (3 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/26895993/" target="_blank" rel="noopener">刻意练习</a></td><td>五星</td><td>2017-01-17</td><td>对我而言这本书的意义有三点：1. 打破 “天才论” 2. 辩证看待 “一万小时专家理论” 3. 用于教育界或者自教育</td></tr><tr><td><a href="https://book.douban.com/subject/25985021/" target="_blank" rel="noopener">人类简史</a></td><td>五星</td><td>2017-02-15</td><td>19 分的好书。9 分给原著，10 分给翻译。完全感觉不到这是本经过翻译的书！一本开了卫星视角的书，看完后刷新了世界观。</td></tr><tr><td><a href="https://book.douban.com/subject/25928708/" target="_blank" rel="noopener">佛祖都说了些什么</a></td><td>五星</td><td>2017-03-19</td><td>语言非常的轻松诙谐。对于了解佛教的历史、宗派、思想非常有益。很明显地可以看出来作者是个唯物主义者，这使得这本书在整体气质上与佛教徒所写的书有本质的区别。</td></tr></tbody></table><h2 id="历史-传记-6-本"><a class="markdownIt-Anchor" href="#历史-传记-6-本"></a> 历史 / 传记 (6 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/3239549/" target="_blank" rel="noopener">夹边沟记事</a></td><td>五星</td><td>2017-01-26</td><td>荒唐时代的牺牲品。一段不应该被忘记的历史</td></tr><tr><td><a href="https://book.douban.com/subject/26819435/" target="_blank" rel="noopener">胡适四十自述</a></td><td>五星</td><td>2017-01-05</td><td>大师的自传满满的真情实感。在传记中，经常能够代入式的感受到同样的迷茫与坚持</td></tr><tr><td><a href="https://book.douban.com/subject/6538430/" target="_blank" rel="noopener">人类群星闪耀时</a></td><td>五星</td><td>2017-02-13</td><td>不同于一般的传记，茨威格列举的十四位人类群星，在勇敢、努力这些词之前更强调命运和上帝。此外语句翻译的也非常有力</td></tr><tr><td><a href="https://book.douban.com/subject/26291984/" target="_blank" rel="noopener">最后的耍猴人</a></td><td>四星</td><td>2017-03-20</td><td>“和你们这些少爷不同, 我们光是活着就已经拼尽全力了”</td></tr><tr><td><a href="https://book.douban.com/subject/26872888/" target="_blank" rel="noopener">人类砍头小史</a></td><td>四星</td><td>2017-09-03</td><td>非常冷静地、近距离地打量头颅，不背过身正视它。砍头史是人类的文明史</td></tr><tr><td><a href="https://book.douban.com/subject/26698660/" target="_blank" rel="noopener">巨人的陨落</a></td><td>五星</td><td>2017-12-03</td><td></td></tr></tbody></table><h2 id="随笔-2-本"><a class="markdownIt-Anchor" href="#随笔-2-本"></a> 随笔 (2 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/6126821/" target="_blank" rel="noopener">远方的鼓声</a></td><td>四星</td><td>2017-04-24</td><td>以人为主的游记书，很好。一个旅行者最渴望的大概也是可以在旅行的地方长住一个月到一年，而非走马观花式的旅游</td></tr><tr><td><a href="https://book.douban.com/subject/10826904/" target="_blank" rel="noopener">蒙田随笔集</a></td><td>五星</td><td>2017-06-10</td><td>很明显蒙田是一个喜欢和自己对话的人，看这本书的时候几乎可以看到他思考的轨迹。有种和良师益友交谈的感觉</td></tr></tbody></table><h2 id="小说-8-本"><a class="markdownIt-Anchor" href="#小说-8-本"></a> 小说 (8 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/26892084/" target="_blank" rel="noopener">降临 (特德. 姜小说集)</a></td><td>五星</td><td>2017-02-24</td><td>特德 · 姜的八篇小说，每一篇的立意毫无重复，每一篇都是精琢的艺术品。用科幻来定义他的小说实在是太狭隘了</td></tr><tr><td><a href="https://book.douban.com/subject/26839300/" target="_blank" rel="noopener">局外人</a></td><td>五星</td><td>2017-04-25</td><td>一直想读加缪的书，这是第一本。在我看来，主人公默尔索是一个坦诚的、拒绝伪饰感情的真实的人。“人生在世，永远也不该演戏作假”</td></tr><tr><td><a href="https://book.douban.com/subject/26416777/" target="_blank" rel="noopener">罗生门</a></td><td>五星</td><td>2017-04-27</td><td>看完这本书永远的记住了芥川龙之介这个绕口的名字。非常喜欢《竹林中》一篇，短短的故事可以把人性描述得淋漓尽致。有机会要找来黑泽明的《罗生门》片子看看。</td></tr><tr><td><a href="https://book.douban.com/subject/6518605/" target="_blank" rel="noopener">三体</a></td><td>五星</td><td>2017-07-12</td><td>高三毕业后用小屏功能机看完了前两部，以为最后罗辑用黑暗森林法则要挟三体人而地球获救是最终结局。最后重看时发现了第三部死神永生。如果说前两部中人类总是化险为夷，第三部中大刘直接毁了整个宇宙。印象最深的是一幕智子用滴血的武士刀指着人类，“人类自由堕落的时代结束了，要想活下去，必须重新拾起人的尊严”。我想这应该也是大刘的想法</td></tr><tr><td><a href="https://book.douban.com/subject/3266609/" target="_blank" rel="noopener">流浪地球</a></td><td>四星</td><td>2017-08-04</td><td>据说要拍成电影了，有些期待。整部书的水平当然不如三体，但是还是可以看的</td></tr><tr><td><a href="https://book.douban.com/subject/3266609/" target="_blank" rel="noopener">十日谈</a></td><td>三星</td><td>2017-09-24</td><td></td></tr><tr><td><a href="https://book.douban.com/subject/20473505/" target="_blank" rel="noopener">山月记</a></td><td>四星</td><td></td><td></td></tr><tr><td><a href="https://book.douban.com/subject/4105446/" target="_blank" rel="noopener">十一种孤独</a></td><td>四星</td><td>2017-10-25</td><td>每个人有每个人的孤独</td></tr></tbody></table><h2 id="诗词-1-本"><a class="markdownIt-Anchor" href="#诗词-1-本"></a> 诗词 (1 本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/2005704/" target="_blank" rel="noopener">北宋名家词选讲</a></td><td>五星</td><td>2017-06-26</td><td>想要把它推荐给所有爱词的人。我认为它的定位是诗词启蒙、美感启蒙与中国古典文化的启蒙。非常赞同叶嘉莹先生两点。1. 宋词的美感绝不仅在于意向，而在于音律。2. 要读懂一首词的前提是需要了解作词人的生平</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2017 年总共阅读了 21 本书，相比于 2016 年减少了 4 本。&lt;br&gt;
今年读的这些书相对于去年来说种类比较全而且质量比较高, 但是有一个非常大的缺点就是没有留下可用的笔记，尤其是像《北宋名家词选讲》这种书，没有好的笔记留下，书里的精髓就会流失很多。&lt;br&gt;
希望 2018 年的阅读能够做到以下几点:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读的每本非小说类书，都要认真的做笔记或者思维图&lt;/li&gt;
&lt;li&gt;2018 年可以阅读 30 本书以上&lt;/li&gt;
&lt;li&gt;多把空闲时间放在用 kindle 读书上&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="生活和思考" scheme="http://www.cyhone.com/categories/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E8%80%83/"/>
    
    
      <category term="读书" scheme="http://www.cyhone.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>ClassViewer 的介绍及实现</title>
    <link href="http://www.cyhone.com/articles/classviewer/"/>
    <id>http://www.cyhone.com/articles/classviewer/</id>
    <published>2018-01-01T03:45:00.000Z</published>
    <updated>2019-12-10T05:07:50.063Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://chenyahui.github.io/ClassViewer" target="_blank" rel="noopener">ClassViewer</a>是我最近开发的一个用于展示 jvm class 字节码的小工具。它是一个单纯的静态网页，完全使用浏览器端的 Javascript 开发。之所以开发这款工具，是因为我在开发 <a href="https://github.com/chenyahui/ToyJVM" target="_blank" rel="noopener">ToyJVM</a> 的时候，需要常常校验 class 文件某一部分的字节码, 所以如果一款工具能够很方便的显示 class 文件各个部分的信息和字节码，对于 ToyJVM 的开发将会是一个非常大的帮助。</p><p>在开始写代码之前调研了一些类似的产品，主要有 jdk 自带的 javap、国外的 Java-Class-Viewer 以及国人开发的 classpy，它们都是非常不错的 class 文件分析工具，但是也存在着一些算不上缺陷的小问题。所以最终还是决定自己写一个适合自己小工具，同时也加深下 class 结构的理解。</p><p>在调研了目前的产品后，我也更加清晰了自己的目标。首先它的受众应该是有兴趣研究 jvm 的程序员，而它应该有这些特性:</p><ul><li>不依赖于特定操作系统平台<br>它应该具备基本的跨平台的能力，因为程序员的 Mac 和 Linux 使用率很高。</li><li>无需复杂的安装和编译，无需用户有特定的知识背景<br>我不太希望用户拿到我的代码后，还需要安装相应的环境、了解一堆无关知识。</li></ul><p>最终实现出来的工具是这样的:</p><a id="more"></a><p><img src="/img/classviewer/welcome.png" alt="welcome"><br><img src="/img/classviewer/show.png" alt="show"></p><h2 id="技术选型"><a class="markdownIt-Anchor" href="#技术选型"></a> 技术选型</h2><p>基于浏览器来实现这个工具是非常符合我的需求的。首先网页跨平台能力是毋庸置疑的，只要有浏览器的电脑就可以运行这个工具。<br>其次，它不需要任何的编译和安装，也不需要用户有任何的背景知识才能使用。只要在 Github 下载好源码，在浏览器中打开 index.html 就可以运行使用。或者，直接访问 <a href="https://chenyahui.github.io/ClassViewer" target="_blank" rel="noopener">Github Page</a>。所以我在开发这个工具的时候完全没有使用后台，也避免使用了各种前端工具链，尽可能的降低使用的复杂度。<br>我在开发中大量使用了 ES6 的特性，比如 let、模板字符串、类等和 ES7 中的 async。这是因为我实在是对 ES5 及其之前的 js 语法提不起太多兴趣，用起来实在是不爽。好在 ES6 提供了许多语法糖，解决了很多问题，用起来也算顺手。<br>也正因为我使用了一些 ES6 的特性，导致这个工具在低版本的浏览器上无法 work。这个问题后期也没打算解决，因为我认为程序员的浏览器应该都会支持这些特性。</p><p>使用 JavaScript 开发还有个问题就是，js 里面没有 int、short 和无符号类型，所有数字都是统一使用 Number 类型表示了。而对 jvm 的分析需要严格地按读取每个字节来说，是个非常头疼的问题。<br>好在 ES6 提供了 ArrayBuffer 和 DataView，可以方便的实现这些功能。</p><h2 id="class-文件的解析"><a class="markdownIt-Anchor" href="#class-文件的解析"></a> Class 文件的解析</h2><p>在官方的 <a href="https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf" target="_blank" rel="noopener">JVM S8 标准</a> 的第四章中，给出了 Class 文件的格式结构。我们可以根据 jvm 标准来严格读取字节。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ClassFile &#123;</span><br><span class="line">    u4 magic;</span><br><span class="line">    u2 minor_version;</span><br><span class="line">    u2 major_version;</span><br><span class="line">    u2 constant_pool_count;</span><br><span class="line">    cp_info constant_pool[constant_pool_count-<span class="number">1</span>];</span><br><span class="line">    u2 access_flags;</span><br><span class="line">    u2 this_class;</span><br><span class="line">    u2 super_class;</span><br><span class="line">    u2 interfaces_count;</span><br><span class="line">    u2 interfaces[interfaces_count];</span><br><span class="line">    u2 fields_count;</span><br><span class="line">    field_info fields[fields_count];</span><br><span class="line">    u2 methods_count;</span><br><span class="line">    method_info methods[methods_count];</span><br><span class="line">    u2 attributes_count;</span><br><span class="line">    attribute_info attributes[attributes_count];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码定义了从上到下依次每部分的字节大小。<br>如果仔细看下这个结构定义，发现大部分数据都以 u2、u4 定义。其中 u4、u2 分别代表该部分占据 4 个字节和 2 个字节。比如 class 文件的前 4 字节，代表了 magic 这部分。接下来的 2 个字节代表了 minor_version。对于这种类型的数据，我们只要简单读取对应数目的字节就可以了。<br>但是还有两部分特殊的定义: <code>cp_info</code> 和 <code>attribute_info</code>。它们都属于复合结构，可以理解为 <code>struct</code>。<br>其中 <code>cp_info constant_pool[constant_pool_count-1]</code> 代表常量池，共有 <code>constant_pool_count-1</code> 项，每一项都是一个 cp_info 结构的数据。cp_info 的结构定义如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp_info&#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    data..</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>cp_info</code> 包含多种类型的数据，比如 <code>CONSTANT_Class_info</code>、<code>CONSTANT_String_Info</code> 等，在 jvms8 中定义了 14 种 cp_info。每个 cp_info 的第一个字节都以 1 个字节的 tag 开头，代表了这个 cp_info 的类型。接下来每种 cp_info 各自的数据都不一样，比如 <code>CONSTANT_Class_info</code> 和 <code>CONSTANT_Integer_info</code> 的定义如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CONSTANT_Class_info &#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    u2 name_index;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CONSTANT_Integer_info &#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    u4 bytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>CONSTANT_Class_info 代表在 tag 后，有 2 个字节的 name_index，就读取结束了。而 CONSTANT_Integer_info 在 tag 后有 4 个字节才能读取结束。<br>对于这种常量池的解析来说，一种最直观的方法是可以这么做:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; constant_pool_count; i++)&#123;</span><br><span class="line">   u1 tag = read <span class="number">1</span> <span class="keyword">byte</span></span><br><span class="line">   <span class="keyword">switch</span>(tag)&#123;</span><br><span class="line">       <span class="keyword">case</span> CONSTANT_Class_info:</span><br><span class="line">        read <span class="number">2</span> <span class="keyword">byte</span></span><br><span class="line">       <span class="keyword">case</span> CONSTANT_Integer_info:</span><br><span class="line">        read <span class="number">4</span> <span class="keyword">byte</span></span><br><span class="line">       ...</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于我们后期要用到 cp_info 的每个字段，所以需要把每个 <code>cp_info</code> 的定义表示为一个类。使用工厂方法来根据 tag 生成相应的对象，将读取的部分包含在各自类的 read 方法中。代码如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cp_info <span class="title">cpInfoFactory</span><span class="params">(u1 tag)</span></span>&#123;</span><br><span class="line">    <span class="keyword">switch</span>(tag)&#123;</span><br><span class="line">         <span class="keyword">case</span> CONSTANT_Class_info:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ConstClassInfo();</span><br><span class="line">         <span class="keyword">case</span> CONSTANT_Integer_info:</span><br><span class="line">             <span class="keyword">return</span> <span class="keyword">new</span> ConstClassInfo();</span><br><span class="line">         ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cp_info info = cpInfoFactory(tag)</span><br><span class="line">info.read()</span><br></pre></td></tr></table></figure><p>目前这样看起来似乎我们只需要为 cp_info 定义 14 种不同的类，然后在类中为每个不同的 cp_info 定义不同的读取方法即可。<br>我目前在 ToyJVM 中是这么做的，但是这么做有个问题就是太繁琐了。我们需要为每个类定义不同的属性，然后在 read 方法中为这些属性读取不同的字节，极易出现编写错误。一旦一个字节读取错误，就会导致后面的字节全部错误。<br>由于 ClassViewer 采用了 js 实现，可以使用 eval 动态定义变量。我采用了这么一种做法，来简化 constant_pool 的读取:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    read(reader)&#123;</span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.properties.length; i += <span class="number">2</span>) &#123;</span><br><span class="line">               <span class="keyword">let</span> len = <span class="keyword">this</span>.properties[i]</span><br><span class="line">               <span class="keyword">let</span> property = <span class="keyword">this</span>.properties[i + <span class="number">1</span>]</span><br><span class="line">               <span class="built_in">eval</span>(<span class="string">`this.<span class="subst">$&#123;property&#125;</span> = reader.read(<span class="subst">$&#123;len&#125;</span>)`</span>)</span><br><span class="line">         &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstClassInfo</span> <span class="keyword">extends</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.properties = [</span><br><span class="line">            <span class="number">2</span>, <span class="string">'name_index'</span>,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstFieldRefInfo</span> <span class="keyword">extends</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.properties = [</span><br><span class="line">            <span class="number">2</span>, <span class="string">"class_index"</span>,</span><br><span class="line">            <span class="number">2</span>, <span class="string">"name_and_type_index"</span>,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先在这里我定义了一个 BaseCpInfo, 作为所有 cp_info 的类。在子类中，只需要在 this.properties 定义相关字段的名称和字节长度就可以。在 read 的时候，使用父类公共的 read 方法，使用 eval 为每个子类读取字段内容。<br>这里需要注意的是，this.properties 我使用了数组来实现，而非字典。是因为这些属性是必须严格有序的，不可以颠倒顺序。而字典常常使用 Hash 来实现，并不保证顺序。</p><p>使用这种方法子类可以不用写 read 方法，减少了出错的可能。对于 constant_pool 来说，大概可以少写 14 个 read 方法。后面 attributes 也采用了同样的策略，也可以少写十几个方法。这对于开发效率的提升程度还是非常客观的。</p><p>这种写法代码写起来很爽，只是有个缺点就是 eval 的速度实在太慢，会极大降低运行效率。但是因为写起来实在是太爽了，只要从 jvm 标准中把每个类型的字节信息抄过来，定义一个公共的 read 方法就可以了。所以在后面我也没打算把它改写成非 eval 方式的读写，或许有可能写一个 codegen 脚本，但是都是后话了。</p><h2 id="字节显示区域"><a class="markdownIt-Anchor" href="#字节显示区域"></a> 字节显示区域</h2><p>在预览图中可以看到，中间有一块区域用于显示 Hex 字节码信息，这是一块超大的排列整齐的方格区域，用普通的 div+css 显然没法很好的实现。在我的实现中，使用了 canvas 绘制了字节码区域。具体代码可以参考 <a href="https://github.com/chenyahui/ClassViewer/blob/master/js/ui/byte_painter.js" target="_blank" rel="noopener">byte_painter.js</a><br>除了正常的绘制之外，还实现了部分区域高亮以及滚动到指定区域的功能。</p><h2 id="左侧栏"><a class="markdownIt-Anchor" href="#左侧栏"></a> 左侧栏</h2><p>左侧栏实际上就是直接调用了 <a href="http://www.treejs.cn/v3/main.php#_zTreeInfo" target="_blank" rel="noopener">ztree</a>。在<a href="https://github.com/chenyahui/ClassViewer/blob/master/js/ui/class_to_ztree.js" target="_blank" rel="noopener">class_to_ztree.js</a> 中，将读取到的 class 文件转换成了 ztree 的 node 节点。</p><p>为什么要特意提下左侧栏。哈哈，因为我是 jetbtrains 粉，特意从 jetbrians 官网上找了 IDE 中的 <a href="https://www.jetbrains.com/help/idea/symbols.html" target="_blank" rel="noopener">符号图标</a>，替换了 ztree 的默认样式，算是对 jetbrains 的一个小小的致敬吧！</p><h2 id="todo"><a class="markdownIt-Anchor" href="#todo"></a> TODO</h2><p>目前 ClassViewer 的初版已经发布，可以直接 <a href="https://chenyahui.github.io/ClassViewer/" target="_blank" rel="noopener">通过 Github Page 查看页面</a> 或者直接<a href="https://github.com/chenyahui/ClassViewer" target="_blank" rel="noopener">在 Github 上查看源码</a>。接下来我会继续把开发重心放在 ToyJVM 上，但同时也会抽时间继续优化 ClassViewer 的使用体验。</p><p>接下的开发方向主要会集中在以下几点:</p><ul><li>Method 的字节码信息展示<br>当用户点击了 method 的时候，直接在中间区域显示对应的 jvm 命令。这部分需要对 jvm 的命令进行解析，相应的功能我在 ToyJVM 中做过一遍，所以这个会是首选的实现功能。</li><li>Index 之间跳转<br>jvm 中很多部分都是直接给了一个 index。比如 this_class，就是给了一个 2 个字节的 index，这个 index 表示 <code>constant_pool</code> 某一项的索引，这一项必须是 <code>CONSTANT_Class_info</code> 类型的。诸如此类，所以打算做一个可以根据 index 跳转对应真实数据的功能。</li><li>支持 jar 包的解析<br>故名思意，可以直接解析 jar 包。jar 包可以理解成一个 zip 压缩包，里面是一堆的 class 文件。所以这里我可能要借助第三方的 js 的 zip 解析包来实现。</li><li>jvm s9 的支持<br>目前的 ClassViewer 是根据 jvms8 来实现的，接下来会跟进 jvm s9 的标准。</li><li>Java modified UTF8 的解析<br>JVM 对标准 UTF8 进行了一些轻微的修改，称为 M-UTF8。我目前的实现都是直接使用标准的 UTF8 来解析的，这么做可以适合大部分的场景，对于一些特定字符会有问题，接下来会对这部分进行处理。</li></ul><p>有感兴趣的可以和我一起跟进这个项目。</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>开发这个工具的最大目的还是自用，实现一个适合自己和大部分人的 Class 字节码工具，除此之外也是对 JVM class 的进一步的研究。这个项目如果继续深入下去，甚至可以使用 js 来实现一个玩具版的虚拟机。但是对我来说没必要了，我会把对 JVM 的实现都放在 <a href="https://github.com/chenyahui/ToyJVM" target="_blank" rel="noopener">ToyJVM</a> 中。</p><p>我在开发过程中最初打算尽可能地不依赖任何三方库，以便界面和功能上更贴近自己的体验。但是个人的能力始终有限，把时间花在工具的核心内容之外，实在有些得不偿失。所以还是用了一些开源项目，比如使用 ztree 实现了左侧信息栏，iziModal 实现了遮罩层，也用了 fontawesome 的一些图标来美化界面。最后也非常感谢这些项目对 ClassViewer 的帮助。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://chenyahui.github.io/ClassViewer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ClassViewer&lt;/a&gt;是我最近开发的一个用于展示 jvm class 字节码的小工具。它是一个单纯的静态网页，完全使用浏览器端的 Javascript 开发。之所以开发这款工具，是因为我在开发 &lt;a href=&quot;https://github.com/chenyahui/ToyJVM&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ToyJVM&lt;/a&gt; 的时候，需要常常校验 class 文件某一部分的字节码, 所以如果一款工具能够很方便的显示 class 文件各个部分的信息和字节码，对于 ToyJVM 的开发将会是一个非常大的帮助。&lt;/p&gt;
&lt;p&gt;在开始写代码之前调研了一些类似的产品，主要有 jdk 自带的 javap、国外的 Java-Class-Viewer 以及国人开发的 classpy，它们都是非常不错的 class 文件分析工具，但是也存在着一些算不上缺陷的小问题。所以最终还是决定自己写一个适合自己小工具，同时也加深下 class 结构的理解。&lt;/p&gt;
&lt;p&gt;在调研了目前的产品后，我也更加清晰了自己的目标。首先它的受众应该是有兴趣研究 jvm 的程序员，而它应该有这些特性:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不依赖于特定操作系统平台&lt;br&gt;
它应该具备基本的跨平台的能力，因为程序员的 Mac 和 Linux 使用率很高。&lt;/li&gt;
&lt;li&gt;无需复杂的安装和编译，无需用户有特定的知识背景&lt;br&gt;
我不太希望用户拿到我的代码后，还需要安装相应的环境、了解一堆无关知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终实现出来的工具是这样的:&lt;/p&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="JVM" scheme="http://www.cyhone.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>首次半马记</title>
    <link href="http://www.cyhone.com/articles/my-first-half-marathon/"/>
    <id>http://www.cyhone.com/articles/my-first-half-marathon/</id>
    <published>2017-04-17T14:20:47.000Z</published>
    <updated>2019-12-10T05:07:50.067Z</updated>
    
    <content type="html"><![CDATA[<p>4 月 9 号，在武汉参加了人生第一次半程马拉松，风里雨里的 21.0975 公里。虽然已时隔一周，但想到那天一路的奔跑、疲惫、欣喜，还是想记记这半马的流水账。</p><a id="more"></a><h1 id="赛前训练"><a class="markdownIt-Anchor" href="#赛前训练"></a> 赛前训练</h1><p>关于赛前训练这一块，我自己真的是非常的汗颜，被自己的记性给坑了一把。本来 4 月 9 号的马拉松，硬是记成了 5 月 9 号。所以本来安排的提前 1 个月训练半马，也恰好完美地错过。汉马马拉松官网提前 10 天发送了备赛的消息，我还在想提前 40 天就发消息会不会太早，直到赛前一周的时候去东湖玩看到了路上马拉松赛道的标牌，才知道记错了时间。。</p><p>但是由于我这几年一直有跑步的习惯，基本不下雨的晚上都会去跑个 5km(虽然武汉下雨的天气居多…)，之前也有跑过 10km，1 个小时左右的水平，所以对于三个小时完赛 21km 还是比较有信心的。<br>在野心勃勃地列了赛前一周训练计划后，伴随着武汉连绵一周的阴雨，基本我的赛前训练计划就这么泡汤了。</p><img src="/img/emoji/emoji2.jpg" width="200" height="200px" style="margin-left:auto;margin-right:auto;"><p>比赛时间是周日，虽然天公不作美，还是在周三晚上停雨的间歇跑个了 5km，周五晚上跑了 3km 热了身，就这么草率地开始我的半马历程。</p><p>言归正传，对于普通的业余跑者如我来说，至少要留足一个月的时间去准备马拉松，训练多次 10km，至少一次半程马拉松的模拟，学习充足热身、恢复知识，才具备跑半马的资格。<br>要不然都像我今天这样右脚贴着膏药坐电脑打字总归是不好的。</p><h1 id="比赛前夕的准备"><a class="markdownIt-Anchor" href="#比赛前夕的准备"></a> 比赛前夕的准备</h1><h2 id="饮食"><a class="markdownIt-Anchor" href="#饮食"></a> 饮食</h2><p>虽然咱练得不行，但起码得吃好。。</p><p>赛前饮食还是需要十分注意的，少油腻、多能量的摄入, 不至于赛前精神的萎靡。在赛前三天每天也都要多喝水，每天保证 2L 的水，让身体充满水。</p><h2 id="住宿与交通"><a class="markdownIt-Anchor" href="#住宿与交通"></a> 住宿与交通</h2><p>关于住宿这一块，如果想要住到赛点周围，要至少提前一周甚至更早预定，要不然只剩下比平常贵几倍或者是比较远的酒店了。</p><p>同时，武汉当天的公交、地铁也都会提前开放，这是武汉马拉松官网赛前给我发的短信。</p><blockquote><p>【武汉马拉松】温馨提示：4 月 9 日比赛日当天，参赛选手可凭号码布，免费乘公交、地铁和轮渡。建议乘坐地铁 2 号线和 6 号线抵达起点附近江汉路站，全程和半程选手从地铁 C 口出，13 公里跑选手从地铁 B 口出。其中 2、6 号线运营始发时间调整为 5:30，提前一小时，祝您顺利参赛，取得好成绩。</p></blockquote><p>虽然我就在武汉住，但是想到第二天要五点爬起来吃饭赶地铁，头一天在宿舍还有睡不好的可能，还是在赛点 2 公里远的地方订了宾馆。</p><h2 id="装备"><a class="markdownIt-Anchor" href="#装备"></a> 装备</h2><p>我在周六下午去了马拉松指定的地方领取了武汉马拉松组织发的装备，主要有号码牌、短袖、存衣袋、能量胶和能量棒，天气预报说周日可能中雨，所以主办单位也准备了一次性的雨衣，这点还是很贴心的。</p><p>关于号码牌要多说一句，此次半马采用的计时芯片直接和号码牌固定到一起、一次性使用，并不是和常见的绑到鞋带上的计时芯片。我觉得一次性芯片在使用上非常方便，而且减少了芯片的发放、回收的时间，个人在跑的时候也完全不用注意芯片的事情。</p><p>此外，特步赞助的短袖穿起来非常的舒服，所以如果不是专业的跑步者，有自己的固定装备，我觉得使用赠送的统一的小黄衫就足够了。</p><p>关于鞋子，要求不漏水，平常跑起来舒服的就可以，在跑前一定要试跑下鞋子，确定鞋子的舒适度才可在半马上正式使用。</p><p>裤子方面我本来打算简单穿下之前本科发的校服配套的运动裤，周六晚上在江汉路逛的时候，被女朋友怂恿去买了一条跑步专用的运动裤，不得不说，专业的穿起来要舒服很多，我半马一路跑下来它功不可没。</p><p>赛前在京东买了一个腰袋，用来放手机，买了之后周五跑步的时候就试了下，一直后悔没有提前买，实在是太好用了除了影响颜值。</p><h2 id="线路和补给点"><a class="markdownIt-Anchor" href="#线路和补给点"></a> 线路和补给点</h2><p>在武汉马拉松官网上会给出线路和补给点的情况，在 <a href="http://www.wuhanmarathon.org/html/saishixinxi_Event/bisaixianlu/" target="_blank" rel="noopener">这里</a> 可以看到, 对于首次跑马拉松的人来说，这个还是要提前记清楚，以调整自己的状态。</p><h1 id="万人雨中马拉松"><a class="markdownIt-Anchor" href="#万人雨中马拉松"></a> 万人雨中马拉松</h1><p>头天晚上收拾好东西，记了下半马的路线图，大概 9 点半就入睡了，保证了 7 个半个小时睡眠时间，这点也是在宾馆住的优点。<br>早上五点半起床，吃了两片面包一瓶牛奶就吃不下去了，进场地前又啃了半个巧克力和一瓶红牛。关于早餐这块，我在半马后半段的时候后悔莫及。。</p><p>进入赛场后我志气满满地开始戴号码牌，咦，别针呢！我看着漏了的号码牌袋欲哭无泪，估计是来的路上把别针全丢光了。想着可能要手举着号码牌跑一路也是心累，把号码牌塞口袋跑还怎么帅帅的摆 pose。<br>后来发现每个人之前发了五个别针，所以每个人会多一个。就找了还没戴号码牌的人借了 1 个，然后志愿者给了我两个，我最后竟然在地上又捡了一个。。凑了四个戴上号码牌终于可以帅帅地开跑了。</p><p>开跑时间是 7 点半，半马时间是三个小时，十点半结束。平均每 10km 跑 1 个半小时，为了留个缓冲时间，所以大概每 5km 需要在 35 分钟左右完成。</p><p>我的号码牌是 D 开头的，前面有 A、B、C 组是特邀选手和全程马拉松，后面还有 E 组和健康跑，在半马跑道起点的顺序上也是这么排的，全部的总人数大概是 22000 人。7 点半枪响后，人群开始慢慢移动，话说虽然我也没听到枪响。前面的移动实在是慢，大概走了四五分钟后，人群开始疏散，我才开始慢慢跑起来。</p><p>这里要提下一次性雨衣的问题，在起点附近地上到处都是随处可见的黄色一次性雨衣，可能是选手穿上后觉得麻烦又随手扔了，但是对于后面的人来说实在很危险而且不美观，所以还是建议暂时拿到手里，等到人群疏散开后交给志愿者。</p><p>基本开始跑了之后就开始沥沥淅淅的下起了小雨，路两边加油击掌的人满满，可谓热血沸腾。同时我也提醒自己稳住速度，以免太快消耗完体力。</p><p>等到 5 千米时候，雨开始下大，基本到了中雨的程度，我拿出手机看了下时间，大概 8 点 14 分，已经过去了四十四分钟了，可能是在开始的时候走的太慢，浪费了很多时间。这个时候我就开始着急了，喝了一杯水后，开始稍微地提高了下速度，<br>从 5km 开始以后，路上不断的有补给点，每个补给点都必须要喝一杯水，尤其是下雨天，身体对水的需求更大。</p><p>在这里非常感谢汉马的各位志愿者，汉马的补给非常充足，志愿者非常热情，让我这个第一次跑马拉松的人可以完全的只用关注跑步就可以了。</p><p>10km 是在武汉长江大桥上面，平常车水马龙的马路现在只剩了跑步者。但此时的雨已经属于大雨的范围了，上桥的时候鞋子基本是踩在水里的。此时鞋子衣服全部湿透了，耳机也出现了问题，这个时候才明白防水蓝牙耳机的重要性。这个时候大概过去了 1 个小时 15 分钟，时间恰好在我的控制范围内。</p><p>12km 的地方是下桥后的黄鹤楼站，女朋友在那里拿着红牛和巧克力等我。但是人太多了，提前没有联系好，没找到人我就继续跑了。<br>跑到 15km 的时候，早上两片面包的能量基本消耗殆尽了，小腿微微的有抽筋的趋势。肚子基本饿扁了，这个时候就开始走一回，跑一会，路上遇到拉伸点也会跟着大家一起拉伸。</p><p>在剩最后 1km 的时候，时间还有 40 分钟，这个时候基本不用担心时间问题了，脚也非常的沉重，开始完全的走路的方式。</p><p>最后三百米的路段是从楚河汉街到湖北市图书馆，一路上加油的人越来越多，双脚非常沉重的走向终点线，基本跑快一点就有抽筋的趋势，我的首次半程马拉松就在平静、愉悦、疲惫和陌生人的欢呼中完成了。<br><img src="/img/half-mathron/medal.jpg" width="400" height="800px" style="margin-left:auto;margin-right:auto;"></p><h1 id="赛后"><a class="markdownIt-Anchor" href="#赛后"></a> 赛后</h1><p>赛后当然是拿着手机拍拍拍和发朋友圈啊！</p><p>除了晒照还有一件事就是拉伸！尤其对于没有长期训练半马的人来说，拉伸尤为重要。我跑完之后由于没有充分的拉伸和活动，导致目前右脚有轻微的损伤。</p><p>半马一路上看到弱弱的女孩子、五六十岁的大叔大妈都有参与马拉松的，而且很多人的准备和状态都比我要好很多，村上春树也提到他在 38 岁的时候全马成绩大概是 3 小时 40 分钟。所以完成一次全马只是业余跑者的最入门级的水平，一次半马的经历尤为可贵，更可贵的是因为跑步、健身而获得的良好的身体技能和精神状态。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;4 月 9 号，在武汉参加了人生第一次半程马拉松，风里雨里的 21.0975 公里。虽然已时隔一周，但想到那天一路的奔跑、疲惫、欣喜，还是想记记这半马的流水账。&lt;/p&gt;
    
    </summary>
    
      <category term="生活和思考" scheme="http://www.cyhone.com/categories/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E8%80%83/"/>
    
    
  </entry>
  
</feed>
