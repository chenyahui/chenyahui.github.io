<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>编程沉思录</title>
  
  <subtitle>一些思考和总结</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.cyhone.com/"/>
  <updated>2019-12-05T03:22:07.155Z</updated>
  <id>http://www.cyhone.com/</id>
  
  <author>
    <name>cyhone</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>FileBeat-Log相关配置介绍</title>
    <link href="http://www.cyhone.com/articles/usage-of-filebeat-log-config/"/>
    <id>http://www.cyhone.com/articles/usage-of-filebeat-log-config/</id>
    <published>2019-11-26T12:36:54.000Z</published>
    <updated>2019-12-05T03:22:07.155Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍Filebeat 7.5版本中Log相关的各个配置项的含义以及其应用场景。</p><p>一般情况下，我们使用log input的方式如下，只需要指定一系列paths即可。<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/messages</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/*.log</span></span><br></pre></td></tr></table></figure></p><p>但其实除了基本的paths配置外，log input还有大概十几个配置项需要我们关注。</p><p>这些配置项或多或少都会影响到Filebeat的使用方式以及性能。虽然其默认值基本足够日常使用，但是还是需要深刻理解每个配置项背后的含义，这样才能够对其完全把控。</p><p>同时，在filebeat的日常线上运维中，也会涉及到这些配置参数的调节。</p><a id="more"></a><h1 id="log-input配置"><a href="#log-input配置" class="headerlink" title="log input配置"></a>log input配置</h1><h2 id="paths"><a href="#paths" class="headerlink" title="paths"></a>paths</h2><p>我们可以指定一系列的paths作为信息输入源，在指定path的时候，注意以下规则：</p><ol><li>指定的路径必须是文件，不能是目录。</li><li>支持Glob模式。</li><li>默认支持递归路径，如<code>/**/</code>形式，Filebeat将会展开8层嵌套目录。</li></ol><h3 id="Glob模式"><a href="#Glob模式" class="headerlink" title="Glob模式"></a>Glob模式</h3><p>Glob模式支持通配符匹配，目前支持的语法有：</p><table><thead><tr><th>通配符</th><th>解释</th><th>示例</th><th>匹配</th></tr></thead><tbody><tr><td>*</td><td>匹配任意数目的任意字符</td><td><code>La*</code></td><td>Law, Lawyer</td></tr><tr><td>?</td><td>匹配任意的单字符</td><td><code>?at</code></td><td>Cat, cat, Bat or bat</td></tr><tr><td>[abc]</td><td>匹配一个在中括号的字符</td><td><code>[CB]at</code></td><td>Cat or Bat</td></tr><tr><td>[a-z]</td><td>匹配一个指定范围的字符</td><td><code>Letter[0-9]</code></td><td>Letter0, Letter1, Letter2 up to Letter9</td></tr></tbody></table><h3 id="递归的Glob模式"><a href="#递归的Glob模式" class="headerlink" title="递归的Glob模式"></a>递归的Glob模式</h3><p>此外，filebeat对传统的Glob模式进行了扩展，支持用户指定<code>/**/</code>模式的路径，filebeat可以将其展开为8层的Glob路径。</p><p>例如，假如指定了<code>/home/data/**/my*.log</code>, filebeat将会把<code>/**/</code>翻译成8层的子目录，如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/home/data/my*.log</span><br><span class="line">/home/data/*/my*.log</span><br><span class="line">/home/data/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/*/my*.log</span><br><span class="line">/home/data/*/*/*/*/*/*/*/*/my*.log</span><br></pre></td></tr></table></figure></p><p>加上不带子目录的Glob路径，一共会有8条Glob路径。这些路径都会作为input的输入源路径进行搜索。</p><p>但是在使用的时候需要注意：</p><ol><li>filebeat展开为8层子目录的规则，是直接hardcode在代码中的，无法通过配置修改匹配层数</li><li>只支持单纯的<code>/**/</code>模式，对于<code>/data**/</code>模式不支持</li><li>递归模式默认开启，可通过<code>recursive_glob.enabled</code>配置项关闭</li></ol><h2 id="recursive-glob-enabled"><a href="#recursive-glob-enabled" class="headerlink" title="recursive_glob.enabled:"></a>recursive_glob.enabled:</h2><p>是否开启递归的Glob模式，默认为true。</p><h2 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h2><p>指定日志编码，默认是plain。即ASCII模式</p><h2 id="exclude-lines"><a href="#exclude-lines" class="headerlink" title="exclude_lines"></a>exclude_lines</h2><p>可指定多个正则表达式，来去除某些不需要上报的行。例如：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  exclude_lines:</span> <span class="string">['^DBG']</span></span><br></pre></td></tr></table></figure><p>该配置将会去除以<code>DBG</code>开头的行。</p><h2 id="include-lines"><a href="#include-lines" class="headerlink" title="include_lines"></a>include_lines</h2><p>可指定多项正则表达式，来仅上报匹配的行。例如：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  include_lines:</span> <span class="string">['^ERR',</span> <span class="string">'^WARN'</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>该配置将会仅上报以<code>ERR</code>和<code>WARN</code>开头的行。</p><p>问题来了，如果同时指定了exclude_lines和include_lines会怎么处理？</p><p>对于这种情况，Filebeat将会先校验include_lines，再校验exclude_lines，其代码实现如下：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(h *Harvester)</span> <span class="title">shouldExportLine</span><span class="params">(line <span class="keyword">string</span>)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(h.config.IncludeLines) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !harvester.MatchAny(h.config.IncludeLines, line) &#123;</span><br><span class="line"><span class="comment">// drop line</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(h.config.ExcludeLines) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">if</span> harvester.MatchAny(h.config.ExcludeLines, line) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="exclude-files"><a href="#exclude-files" class="headerlink" title="exclude_files"></a>exclude_files</h2><p>可指定多个正则表达式，匹配到的文件名将不会被处理。</p><h2 id="harvester-buffer-size"><a href="#harvester-buffer-size" class="headerlink" title="harvester_buffer_size"></a>harvester_buffer_size</h2><p>读文件时的buffer大小，最终会应用在golang的<code>File.Read</code>函数上面。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *File)</span> <span class="title">Read</span><span class="params">(b []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span></span><br></pre></td></tr></table></figure></p><p>默认是16384。即16k。</p><h2 id="max-bytes"><a href="#max-bytes" class="headerlink" title="max_bytes"></a>max_bytes</h2><p>表示一条log消息的最大bytes数目。超过这个大小，剩余就会被截断。<br>默认值为10485760(即10MB)。</p><h2 id="multiline"><a href="#multiline" class="headerlink" title="multiline"></a>multiline</h2><p>multiline是为了解决需要多行聚合在一起发送的情况，例如Java Stack Traces信息等。<br>虽然filebeat默认不开启multiline，但是官方的配置文件给了一个例子，可以支持Java Stack Traces或者是C语言式的换行连续符<code>\</code>,  可在<a href="https://github.com/elastic/beats/blob/7.5/filebeat/filebeat.reference.yml#L494" target="_blank" rel="noopener">filebeat.reference.yml</a>中查看。</p><p>由于大部分场景不涉及multiline，本文不再进行深入讨论。关于multiline配置的详细资料可查看官方文档：<br><a href="https://www.elastic.co/guide/en/beats/filebeat/7.5/multiline-examples.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/7.5/multiline-examples.html</a></p><h2 id="ignore-older"><a href="#ignore-older" class="headerlink" title="ignore_older"></a>ignore_older</h2><p>ignore_older表示对于最近修改时间距离当前时间已经超过某个时长的文件，就暂时不进行处理。默认值为0，表示禁用该功能。</p><p>注意：ignore_older只是暂时不处理该文件，并不会在Registrar中改变该文件的状态。</p><p>其代码实现如下：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Input)</span> <span class="title">isIgnoreOlder</span><span class="params">(state file.State)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="comment">// ignore_older is disable</span></span><br><span class="line"><span class="keyword">if</span> p.config.IgnoreOlder == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">modTime := state.Fileinfo.ModTime()</span><br><span class="line"><span class="keyword">if</span> time.Since(modTime) &gt; p.config.IgnoreOlder &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="close-系列"><a href="#close-系列" class="headerlink" title="close_* 系列"></a>close_* 系列</h2><p>log input中有一系列以close_开头配置，这些配置决定了Harvester何时结束对文件的读取。</p><ol><li>close_eof<br>如果读取到了EOF(即文件末尾)，是否要结束读取。如果为true，则读取到文件末尾就结束读取，否则Harvester将会继续工作。默认只为false。</li><li>close_inactive<br>如果配置了close_eof为false，则Harvester即使读取到了文件末尾也不会终止。close_inactive决定了最长没有读到新消息的时长，默认为5m(即五分钟)。如果超过了close_inactive规定的时间依然没有新消息，则Harvester退出。</li><li>close_timeout<br>决定了一个Harvester的最长工作时间，如果Harvester工作了一段时间后依然没有停止，则强行停止Harvester。默认为0，表示不强行停止Harvester。</li><li>close_renamed<br>文件更名时是否退出，默认为false。文件更名一般发生在日志轮替的场景下。</li><li>close_removed<br>表示当文件被删除时Harvester是否要继续。默认为true。</li></ol><p>不过即使Harvester关闭了也关系不大。因为根据filebeat会定时扫描文件，如果关闭后又有了新增内容，filebeat依然是可以检查出来的。</p><h2 id="clean-系列"><a href="#clean-系列" class="headerlink" title="clean_* 系列"></a>clean_* 系列</h2><p>clean_开头的一系列配置用来清理Registrar中的文件状态，同时也可以起到减小Registrar文件大小、防止inode复用等作用。</p><ol><li><p>clean_inactive<br>表示一个时间段。用于移除已经一长段时间没有新产生内容的日志文件，默认为0，表示禁用该功能。</p></li><li><p>clean_removed<br>在Registrar中移除那些已经不存在的文件。默认为true。</p></li></ol><h2 id="scan-frequency"><a href="#scan-frequency" class="headerlink" title="scan_frequency"></a>scan_frequency</h2><p>代表input的扫描频率，默认为10s。<br>input会按照此频率，启动定时器定时扫描路径，以发现新文件和文件的改动情况。</p><h2 id="scan-sort和scan-order"><a href="#scan-sort和scan-order" class="headerlink" title="scan.sort和scan.order"></a>scan.sort和scan.order</h2><p>这两个配置项需要放在一起讲。<br><code>scan.sort</code>可取的值为: modtime和filename。默认值为空，不进行排序。<br><code>scan.order</code>可取的值为：asc和desc。默认值为asc。<code>scan.order</code>仅在<code>scan.sort</code>非空时生效。</p><p>需要注意的是：该功能目前为实验功能，可能会在以后版本移除。</p><h2 id="tail-files"><a href="#tail-files" class="headerlink" title="tail_files"></a>tail_files</h2><p>默认情况下，Harvester处理文件时，会文件头开始读取文件。开启此功能后，filebeat将直接会把文件的offset置到末尾，从文件末尾监听消息。默认值是false。</p><p>注意： 开启了tail_files, 则所有文件中的当前内容将不会被上报，只有新产生消息时才会上报。</p><p>在真实的实现中，tail_files被当做<code>ignore_older=1ns</code>处理。因此，在启动的时候，只要是新文件，里面的内容都会被忽略，直接把offset置为文件末尾。</p><p>所以使用该配置项时千万要谨慎！</p><h2 id="harvester-limit"><a href="#harvester-limit" class="headerlink" title="harvester_limit"></a>harvester_limit</h2><p>harvester_limit决定了一个input最多同时有多少个harvester启动。默认为0，代表不对harvester个数进行限制。<br>在使用时要注意两点：</p><ol><li>如果一个文件对应的harvester在本轮扫描时没能启动，那会在下次扫描时，有其他文件的harvester完全退出时，该文件的harvester才能启动。</li><li>harvester_limit仅对针对配置的input进行了限制，多个input之间的harvester_limit互不影响。</li></ol><h2 id="symlinks"><a href="#symlinks" class="headerlink" title="symlinks"></a>symlinks</h2><p>代表是否要对符号链接进行处理，默认值为false，代表不处理。</p><h2 id="backoff相关配置"><a href="#backoff相关配置" class="headerlink" title="backoff相关配置"></a>backoff相关配置</h2><p>我们上文讲到<code>close_eof</code>选项，当读取到eof时，且close_eof为false，则Harvester还会一直尝试读取文件。</p><p>在这种情况下，Harvester继续读取之前，其实filebeat还会等待一段时间。等待的时长就是由<code>backoff</code>、<code>backoff_factor</code>和<code>max_backoff</code>三个配置项共同决定。</p><p>对应的代码实现为：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(f *Log)</span> <span class="title">wait</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// Wait before trying to read file again. File reached EOF.</span></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-f.done:</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(f.backoff):</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Increment backoff up to maxBackoff</span></span><br><span class="line"><span class="keyword">if</span> f.backoff &lt; f.config.MaxBackoff &#123;</span><br><span class="line">f.backoff = f.backoff * time.Duration(f.config.BackoffFactor)</span><br><span class="line"><span class="keyword">if</span> f.backoff &gt; f.config.MaxBackoff &#123;</span><br><span class="line">f.backoff = f.config.MaxBackoff</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中，<code>backoff</code>默认值为1s, <code>backoff_factor</code>默认值为2，<code>max_backoff</code>默认值为10s。</p><p>该配置项意味着，如果读到EOF，则filebeat将会等待一段时间再去读文件。<br>等待时间开始为1s，如果一直是EOF，则会逐渐增大等待时间，每次的等待时间是前一次的两倍，且一次最长等待10s。</p><p>再结合<code>close_inactive</code>选项，如果等待时间超过了默认值5分钟，则Harvester结束。</p><p>此外，如果等待的时候文件又追加了新的数据，则backoff将会重新置为初始值。</p><h1 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h1><p>除了log input相关的属性外，有一些全局属性也需要我们注意。</p><h2 id="queue相关配置"><a href="#queue相关配置" class="headerlink" title="queue相关配置"></a>queue相关配置</h2><p>filebeat会将event暂时存放在queue里面。filebeat的queue目前有mem和spool两种实现，默认是mem。<br>本文只介绍下mem的相关配置项。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">queue:</span></span><br><span class="line"><span class="attr">  mem:</span></span><br><span class="line"><span class="attr">    events:</span> <span class="number">4096</span></span><br><span class="line">    <span class="string">flush.min_events:</span> <span class="number">2048</span></span><br><span class="line">    <span class="string">flush.timeout:</span> <span class="number">1</span><span class="string">s</span></span><br></pre></td></tr></table></figure><p>events代表queue最多能够承载的event的个数。如果个数达到最大值，则input将不能再向queue中插入数据，直至output将数据消费。</p><p><code>flush.min_events</code>代表只有queue里面的数据到达了指定个数，才将数据发送给output。设为0代表直接发送给output，不进行等待。</p><p><code>flush.timeout</code>代表定时刷新event到output中，即使其个数没有达到<code>flush.min_events</code>。该配置项只会在<code>flush.min_events</code>大于0时生效。</p><h2 id="registry相关配置"><a href="#registry相关配置" class="headerlink" title="registry相关配置"></a>registry相关配置</h2><ol><li>filebeat.registry.path<br>定制registry文件的目录，默认值是<code>registry</code>。</li></ol><p>注意，这里指定的只是registry的目录，最终的registry文件的路径会是这样:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$&#123;filebeat.registry.path&#125;/filebeat/data.json</span><br></pre></td></tr></table></figure></p><ol start="2"><li>filebeat.registry.flush<br>将registry文件内容定时刷新到磁盘中。默认为0s，代表每次更新时直接写文件。<br>配置了该选项可以提高些filebeat的性能，避免频繁写磁盘，但是也增加了一定数据丢失的风险。</li></ol><h2 id="日志相关配置"><a href="#日志相关配置" class="headerlink" title="日志相关配置"></a>日志相关配置</h2><p>filebeat可以对输出日志的进行相关配置，filebeat提供了如下日志相关的配置:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">logging.level:</span> <span class="string">info</span> <span class="comment"># 日志输出的最小级别</span></span><br><span class="line"><span class="string">logging.selectors:</span> <span class="string">[]</span> <span class="comment"># 过滤器，用户可在logp.NewLogger时指定</span></span><br><span class="line"><span class="string">logging.to_stderr:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到stderr</span></span><br><span class="line"><span class="string">logging.to_syslog:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到syslog (主要用于unix)</span></span><br><span class="line"><span class="string">logging.to_eventlog:</span> <span class="literal">false</span> <span class="comment"># 将日志输出到windows的event log</span></span><br><span class="line"><span class="string">logging.to_files:</span> <span class="literal">true</span> <span class="comment"># 将日志输出到文件中</span></span><br><span class="line"><span class="string">logging.files:</span></span><br><span class="line"><span class="attr">path:</span> <span class="string">$&#123;filebeat_bin_path&#125;/logs/</span> <span class="comment"># 日志目录</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">filebeat</span>  <span class="comment"># 文件名 filebeat filebeat.1 filebeat.2</span></span><br><span class="line"><span class="attr">rotateonstartup:</span> <span class="literal">true</span> <span class="comment"># 在filebeat启动时进行日志轮替</span></span><br><span class="line"><span class="attr">rotateeverybytes:</span> <span class="number">10485760</span> <span class="comment"># = 10MB 日志轮替的默认值</span></span><br><span class="line"><span class="attr">keepfiles:</span> <span class="number">7</span> <span class="comment"># 日志保留个数</span></span><br><span class="line"><span class="attr">permissions:</span> <span class="number">0600</span> <span class="comment"># 日志权限</span></span><br><span class="line"><span class="attr">interval:</span> <span class="number">0</span> <span class="comment"># 日志轮替</span></span><br><span class="line"><span class="string">logging.metrics.enabled:</span> <span class="literal">true</span> </span><br><span class="line"><span class="string">logging.metrics.period:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="string">logging.json:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure></p><p>filebeat可以选择将日志输出到许多地方，在线上运营时我们常常会将日志输出到文件, 所以接下来讲下文件相关的配置。</p><p>我们可以配置日志文件的所在目录以及文件名，分别对应<code>logging.files.path</code>和<code>logging.files.name</code>。<br>默认情况下，日志的输出目录是在filebeat的bin文件所在目录下的logs文件。</p><p>filebeat会进行日志轮替，一般情况下，常见的日志轮替规则有按大小和按时间，filebeat两种规则均支持。<br>其中:</p><ol><li><code>rotateeverybytes</code>决定了日志文件的最大值，如果日志文件超过了该值，将发生日志轮替，默认值为10MB。</li><li><code>rotateonstartup</code>是说明是否在每次启动时都进行一次日志轮替，这样的话，每次启动的日志都会从一个新文件开始。默认为true</li></ol><p>按文件大小进行轮替后，日志文件名将会变成filebeat、filebeat.1、filebeat.2这种格式，后缀越大文件越旧。</p><p>filebeat也支持按时间进行轮替，可以配置<code>logging.files</code>下的interval属性，支持按照秒、分钟、小时、周、月、年进行轮替，对应值为<code>1s</code>,<code>1m</code>, <code>1h</code>, <code>24h</code>, <code>7*24h</code>, <code>30*24h</code>, 和<code>365*24h</code>。当然，最小值是1s。</p><p>按照时间进行轮替时，时间将会以连字符进行分割, 例如：按照1小时进行轮替的话，文件格式为：<code>filebeat-2019-11-28-15</code>。filebeat目前还不支持日期格式的自定义。</p><p>同时，我们也可以指定日志的保留策略，目前只能通过设置<code>keepfiles</code>来决定保留日志的个数。</p><p>在日志里面还有<code>logging.metrics</code>相关配置，filebeat会定时输出一些当前的运行指标，例如输出下当前ack成功的数目、当前的内存占用情况等：</p><ul><li><code>logging.metrics.enabled</code>决定是否开启指标搜集</li><li><code>logging.metrics.period</code>决定指标输出的间隔</li></ul><h2 id="使用环境变量"><a href="#使用环境变量" class="headerlink" title="使用环境变量"></a>使用环境变量</h2><p>我们可以在使用配置文件中直接使用环境变量，使用方式如下:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">fields:</span></span><br><span class="line"><span class="attr">env:</span> <span class="string">$&#123;ENV_NAME&#125;</span></span><br></pre></td></tr></table></figure></p><p>我们可以直接用<code>${ENV_NAME}</code>来引用系统的环境变量。<br>除了直接引用外，filebeat还提供了两个表达式配合使用:</p><ol><li><code>${VAR:default_value}</code>。如果没有环境变量<code>VAR</code>, 则使用默认值default_value</li><li><code>${VAR:?error_text}</code>。如果没有环境变量<code>VAR</code>，则显示错误提示<code>error_text</code></li></ol><p>filebeat也支持在启动时指定命令行参数来提供环境变量: <code>-E name=${NAME}</code></p><h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><ul><li><a href="https://www.cyhone.com/articles/analysis-of-filebeat/">Elastic-Filebeat实现剖析</a></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-input-log.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/7.5/filebeat-input-log.html</a></li><li><a href="https://github.com/elastic/beats/blob/7.5/filebeat/filebeat.reference.yml" target="_blank" rel="noopener">https://github.com/elastic/beats/blob/7.5/filebeat/filebeat.reference.yml</a></li><li><a href="https://en.wikipedia.org/wiki/Glob_(programming" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Glob_(programming)</a>)</li><li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/using-environ-vars.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/using-environ-vars.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍Filebeat 7.5版本中Log相关的各个配置项的含义以及其应用场景。&lt;/p&gt;
&lt;p&gt;一般情况下，我们使用log input的方式如下，只需要指定一系列paths即可。&lt;br&gt;&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;filebeat.inputs:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;- type:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;log&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;  paths:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;    -&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/var/log/messages&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;bullet&quot;&gt;    -&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/var/log/*.log&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;但其实除了基本的paths配置外，log input还有大概十几个配置项需要我们关注。&lt;/p&gt;
&lt;p&gt;这些配置项或多或少都会影响到Filebeat的使用方式以及性能。虽然其默认值基本足够日常使用，但是还是需要深刻理解每个配置项背后的含义，这样才能够对其完全把控。&lt;/p&gt;
&lt;p&gt;同时，在filebeat的日常线上运维中，也会涉及到这些配置参数的调节。&lt;/p&gt;
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://www.cyhone.com/categories/ElasticSearch/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="Filebeat" scheme="http://www.cyhone.com/tags/Filebeat/"/>
    
      <category term="ElasticSearch" scheme="http://www.cyhone.com/tags/ElasticSearch/"/>
    
      <category term="大数据" scheme="http://www.cyhone.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Redis事件循环器(AE)实现剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-redis-ae/"/>
    <id>http://www.cyhone.com/articles/analysis-of-redis-ae/</id>
    <published>2019-11-20T03:16:54.000Z</published>
    <updated>2019-11-20T03:18:33.103Z</updated>
    
    <content type="html"><![CDATA[<p>Redis作为一个单线程高性能的内存缓存Server而被人熟知。作为一个典型的Reactor式网络应用，Redis能够达到如此高的性能，必然要依靠足够可靠的事件循环库。<br>Redis内置了一个高性能事件循环器，叫做AE。其定义和实现可以在<code>ae*.h/cpp</code>这些文件中找到。</p><p>AE本身就是Redis的一部分，所以整体设计原则就是够用就行。也正因为这个背景，AE的代码才可以简短干净，非常适合阅读和学习。</p><p>本文将基于Redis 5.0.6的源码分析下其事件循环器(AE)的实现原理。</p><p>同时本人也提供了一个<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/redis-5.0" target="_blank" rel="noopener">Redis注释版</a>，用以辅助理解Redis的源码。</p><a id="more"></a><h1 id="eventloop的创建"><a href="#eventloop的创建" class="headerlink" title="eventloop的创建"></a>eventloop的创建</h1><p>Redis通过以下接口进行eventloop的创建和释放。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">aeEventLoop *<span class="title">aeCreateEventLoop</span><span class="params">(<span class="keyword">int</span> setsize)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeDeleteEventLoop</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br></pre></td></tr></table></figure><p>Redis通过将对应事件注册到eventloop中，然后不断循环检测有无事件触发。目前eventloop支持超时事件和网络IO读写事件的注册。</p><p>我们可以通过aeCreateEventLoop来创建一个eventloop。可以看到在创建EventLoop的时候，必须指定一个setsize的参数。</p><p>setsize参数表示了eventloop可以监听的网络事件fd的个数（不包含超时事件），如果当前监听的fd个数超过了setsize，eventloop将不能继续注册。</p><p>我们知道，Linux内核会给每个进程维护一个文件描述符表。而POSIX标准对于文件描述符进行了以下约束：</p><ol><li>fd为0、1、2分别表示标准输入、标准输出和错误输出</li><li>每次新打开的fd，必须使用当前进程中最小可用的文件描述符。</li></ol><p>Redis充分利用了文件描述符的这些特点，来存储每个fd对应的事件。</p><p>在Redis的eventloop中，直接用了一个连续数组来存储事件信息:</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">eventLoop-&gt;events = zmalloc(<span class="keyword">sizeof</span>(aeFileEvent)*setsize);</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; setsize; i++)</span><br><span class="line">    eventLoop-&gt;events[i].mask = AE_NONE;</span><br></pre></td></tr></table></figure><p>可以看到数组长度就是setsize，同时创建之后将每一个event的mask属性置为AE_NONE(即是0)，mask代表该fd注册了哪些事件。</p><p>对于<code>eventLoop-&gt;events</code>数组来说，fd就是这个数组的下标。<br>例如，当程序刚刚启动时候，创建监听套接字，按照标准规定，该fd的值为3。此时就直接在<code>eventLoop-&gt;events</code>下标为3的元素中存放相应event数据。</p><p>不过也基于文件描述符的这些特点，意味着events数组的前三位一定不会有相应的fd赋值。</p><p>那么，Redis是如何指定eventloop的setsize的呢？以下是Redis创建eventloop的相关代码：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">server.el = aeCreateEventLoop(server.maxclients+CONFIG_FDSET_INCR);</span><br></pre></td></tr></table></figure></p><p>其中：</p><ol><li>maxclients代表用户配置的最大连接数，可在启动时由<code>--maxclients</code>指定，默认为10000。</li><li>CONFIG_FDSET_INCR 大小为128。给Redis预留一些安全空间。</li></ol><p>也正是因为Redis利用了fd的这个特点，Redis只能在完全符合POSIX标准的系统中工作。其他的例如Windows系统，生成的fd或者说HANDLE更像是个指针，并不符合POSIX标准。</p><h1 id="网络IO事件"><a href="#网络IO事件" class="headerlink" title="网络IO事件"></a>网络IO事件</h1><p>Redis通过以下接口进行网络IO事件的注册和删除。<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeCreateFileEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeFileProc *proc, <span class="keyword">void</span> *clientData)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeDeleteFileEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask)</span></span>;</span><br></pre></td></tr></table></figure></p><p>aeCreateFileEvent表示将某个fd的某些事件注册到eventloop中。</p><p>目前可注册的事件有三种:</p><ol><li>AE_READABLE  可读事件</li><li>AE_WRITABLE  可写事件</li><li>AE_BARRIER   该事件稍后在”<strong>事件的等待和处理</strong>“一节详细讲到。</li></ol><p>而mask就是这几个事件经过或运算后的掩码。</p><p>aeCreateFileEvent在epoll的实现中调用了epoll_ctl函数。Redis会根据该事件对应之前的mask是否为AE_NONE，来决定使用EPOLL_CTL_ADD还是EPOLL_CTL_MOD。</p><p>同样的，aeDeleteFileEvent也使用了epoll_ctl，Redis判断用户是否是要完全删除该fd上所有事件，来决定使用EPOLL_CTL_DEL还是EPOLL_CTL_MOD。</p><h1 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h1><p>AE中最不值得分析的大概就是定时器了。。因为实现的实在是太简单了，甚至可以说是简陋。</p><p>Redis通过以下两个接口进行定时器的注册和取消。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="keyword">long</span> <span class="title">aeCreateTimeEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">long</span> <span class="keyword">long</span> milliseconds,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeTimeProc *proc, <span class="keyword">void</span> *clientData,</span></span></span><br><span class="line"><span class="function"><span class="params">        aeEventFinalizerProc *finalizerProc)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeDeleteTimeEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">long</span> <span class="keyword">long</span> id)</span></span>;</span><br></pre></td></tr></table></figure></p><p>在调用aeCreateTimeEvent注册超时事件的时候，调用方需要提供两个callback: aeTimeProc和aeEventFinalizerProc。</p><ul><li>aeTimeProc很简单，就是当超时事件触发时调用的callback。有点特殊的是，aeTimeProc需要返回一个int值，代表下次该超时事件触发的时间间隔。如果返回-1，则说明超时时间不需要再触发了，标记为删除即可。</li><li>finalizerProc  当timer被删除的时候，会调用这个callback</li></ul><p>Redis的定时器其实做的非常简陋，只是一个普通的双向链表，链表也并不是有序的。每次最新的超时事件，直接插入链表的最头部。<br>当AE要遍历当前时刻的超时事件时，也是直接暴力的从头到尾遍历链表，看看有没有超时的事件。</p><p>当时我看到这里源码的时候，还是很震惊的。因为一般来说，定时器都会采用最小堆或者时间轮等有序数据结构进行存储，<br>为什么Redis的定时器做的这么简陋？</p><p>《Redis的设计与实现》一书中说，在Redis 3.0版本中，只使用到了serverCon这一个超时事件。<br>所以这种情况下，也无所谓性能了，虽然是个链表，但其实用起来就只有一个元素，相当于当做一个指针在用。</p><p>虽然还不清楚5.0.6版本里面超时事件有没有增多，不过可以肯定的是，目前依然达不到花点时间去优化的程度。<br>Redis在注释里面也说明了这事，并且给出了以后的优化方案：<br>用skiplist代替现有普通链表，查询的时间复杂度将优化为O(1), 插入的时间复杂度将变成O(log(N))</p><h2 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h2><p>虽然定时器做的这么简陋，但是对于一些时间上的异常情况，Redis还是做了下基本的处理。具体可见如下代码：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (now &lt; eventLoop-&gt;lastTime) &#123;</span><br><span class="line">        te = eventLoop-&gt;timeEventHead;</span><br><span class="line">        <span class="keyword">while</span>(te) &#123;</span><br><span class="line">                te-&gt;when_sec = <span class="number">0</span>;</span><br><span class="line">                te = te-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码的意思是，如果当前时刻小于lastTime, 那意味着时间有可能被调整了。</p><p>对于这种情况，Redis是怎么处理的呢：<br>直接把所有的事件的超时时间都置为0, <code>te-&gt;when_sec = 0</code>。这样的话，接下来检查有哪些超时时间到期的时候，所有的超时事件都会被判定为到期。相当于本次遍历把所有超时事件一次性全部激活。</p><p>因为Redis认为，在这种异常情况下，与其冒着超时事件可能永远无法触发的风险，还不如把事情提前做了。</p><p>还是基于Redis够用就行的原则，这个解决方案在Redis中显然是被接受的。</p><p>但是其实还有更好的做法，比如libevent就是通过相对时间的方式进行处理这个问题。为了解决这个几乎不会出现的异常case，libevent也花了大量代码进行处理。</p><h1 id="事件的等待和处理"><a href="#事件的等待和处理" class="headerlink" title="事件的等待和处理"></a>事件的等待和处理</h1><p>Redis中关于处理等待事件的函数有以下两个：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeProcessEvents</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> flags)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeMain</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br></pre></td></tr></table></figure></p><p>aeMain的实现很简单, 就是我们所说的事件循环了，真的就是个循环：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeMain</span><span class="params">(aeEventLoop *eventLoop)</span> </span>&#123;</span><br><span class="line">    eventLoop-&gt;stop = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (!eventLoop-&gt;stop) &#123;</span><br><span class="line">        <span class="keyword">if</span> (eventLoop-&gt;beforesleep != <span class="literal">NULL</span>)</span><br><span class="line">            eventLoop-&gt;beforesleep(eventLoop);</span><br><span class="line">        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>而aeProcessEvents代表处理一次事件循环，那么aeProcessEvents都做了那些事情呢？</p><ol><li>取出最近的一次超时事件。</li><li>计算该超时事件还有多久才可以触发。</li><li>等待网络事件触发或者超时。</li><li>处理触发的各个事件，包括网络事件和超时事件</li></ol><p>为什么要取出最近的一次超时事件？这是因为对于epoll_wait来说，必须要指定一个超时时间。以下是epoll_wait的定义：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, struct epoll_event *events, <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout)</span></span>;</span><br></pre></td></tr></table></figure></p><p>timeout参数单位是毫秒，如果指定了大于0的超时时间，则在这段时间内即使如果没有网络IO事件触发，epoll_wait到了指定时间也会返回。<br>如果超时时间指定为-1，则epoll_wait将会一直阻塞等待，直到网络事件触发。</p><p>epoll_wait的超时时间一定要指定为最近超时事件的时间间隔，这样可以防止万一这段时间没有网络事件触发，超时事件也可以正常的响应。</p><p>同时，eventloop还有两个callback: beforesleep和aftersleep，分别会在epoll_wait之前和之后调用。</p><p>接着，我们看下Redis是怎么处理已触发的网络事件的：<br>一般情况下，Redis会先处理读事件(AE_READABLE)，再处理写事件(AE_WRITABLE)。<br>这个顺序安排其实也算是一点小优化，<strong>先读后写</strong>可以让一个请求的处理和回包都是在同一次循环里面，使得请求可以尽快地回包，</p><p>前面讲到，网络IO事件注册的时候，除了正常的读写事件外，还可以注册一个AE_BARRIER事件，这个事件就是会影响到先读后写的处理顺序。<br>如果某个fd的mask包含了AE_BARRIER，那它的处理顺序会是<strong>先写后读</strong>。</p><p>针对这个场景，redis举的例子是，如果在beforesleep回调中进行了fsync动作，然后需要把结果快速回复给client。这个情况下就需要用到AE_BARRIER事件，用来翻转处理事件顺序了。</p><h1 id="操作系统的适配"><a href="#操作系统的适配" class="headerlink" title="操作系统的适配"></a>操作系统的适配</h1><p>Redis不仅支持Linux下的epoll，还支持其他的IO复用方式，目前支持如下四种：</p><ol><li>epoll：支持Linux系统</li><li>kqueue：支持FreeBSD系统(如macOS)</li><li>select</li><li>evport: 支持Solaris</li></ol><p>几个IO复用方式使用的判断顺序如下:<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EVPORT</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_evport.c"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_EPOLL</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_epoll.c"</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_KQUEUE</span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_kqueue.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ae_select.c"</span></span></span><br><span class="line">        <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>这个顺序其实也代表了四种IO复用方式的性能高低。</p><p>对于每种IO复用方式，只要实现以下8个接口就可以正常对接Redis了：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiCreate</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiDelEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> delmask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiResize</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> setsize)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiFree</span><span class="params">(aeEventLoop *eventLoop)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiAddEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> mask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">aeApiDelEvent</span><span class="params">(aeEventLoop *eventLoop, <span class="keyword">int</span> fd, <span class="keyword">int</span> delmask)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">aeApiPoll</span><span class="params">(aeEventLoop *eventLoop, struct timeval *tvp)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">char</span> *<span class="title">aeApiName</span><span class="params">(<span class="keyword">void</span>)</span></span>;</span><br></pre></td></tr></table></figure></p><p>在这个8个接口下面，其实底层并没有做太多的优化，只是简单的对原有API封装而已。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>与其他通用型的事件循环库(如libevent)不一样的是，Redis的事件循环库不用考虑太多的用户侧因素：</p><ol><li>不用考虑ABI兼容。因为AE本身就和Redis一起编译，所以无需像libevent一样考虑库的升级问题。</li><li>不支持Windows系统，只支持unix like的系统</li><li>指定了监听fd的个数的上限，默认支持10000个客户端连接。</li></ol><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《Redis的设计与实现》</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Redis作为一个单线程高性能的内存缓存Server而被人熟知。作为一个典型的Reactor式网络应用，Redis能够达到如此高的性能，必然要依靠足够可靠的事件循环库。&lt;br&gt;Redis内置了一个高性能事件循环器，叫做AE。其定义和实现可以在&lt;code&gt;ae*.h/cpp&lt;/code&gt;这些文件中找到。&lt;/p&gt;
&lt;p&gt;AE本身就是Redis的一部分，所以整体设计原则就是够用就行。也正因为这个背景，AE的代码才可以简短干净，非常适合阅读和学习。&lt;/p&gt;
&lt;p&gt;本文将基于Redis 5.0.6的源码分析下其事件循环器(AE)的实现原理。&lt;/p&gt;
&lt;p&gt;同时本人也提供了一个&lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/redis-5.0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis注释版&lt;/a&gt;，用以辅助理解Redis的源码。&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.cyhone.com/categories/Redis/"/>
    
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="Redis" scheme="http://www.cyhone.com/tags/Redis/"/>
    
      <category term="网络编程" scheme="http://www.cyhone.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Reactor" scheme="http://www.cyhone.com/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>Elastic-Filebeat实现剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-filebeat/"/>
    <id>http://www.cyhone.com/articles/analysis-of-filebeat/</id>
    <published>2019-11-15T02:55:00.000Z</published>
    <updated>2019-11-26T13:13:38.843Z</updated>
    
    <content type="html"><![CDATA[<p>Filebeat是使用Golang实现的轻量型日志采集器，也是Elasticsearch stack里面的一员。本质上是一个agent，可以安装在各个节点上，根据配置读取对应位置的日志，并上报到相应的地方去。</p><p>Filebeat的可靠性很强，可以保证日志At least once的上报，同时也考虑了日志搜集中的各类问题，例如日志断点续读、文件名更改、日志Truncated等。</p><p>Filebeat并不依赖于ElasticSearch，可以单独存在。我们可以单独使用Filebeat进行日志的上报和搜集。filebeat内置了常用的Output组件, 例如kafka、ElasticSearch、redis等，出于调试考虑，也可以输出到console和file。我们可以利用现有的Output组件，将日志进行上报。</p><p>当然，我们也可以自定义Output组件，让Filebeat将日志转发到我们想要的地方。</p><p>filebeat其实是<a href="https://github.com/elastic/beats" target="_blank" rel="noopener">elastic/beats</a>的一员，除了filebeat外，还有HeartBeat、PacketBeat。这些beat的实现都是基于libbeat框架。</p><a id="more"></a><h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p>下图是Filebeat官方提供的架构图：</p><p><img src="/img/filebeat/filebeat.png" alt="filebeat"></p><p>除了图中提到的各个组件，整个filebeat主要包含以下重要组件：</p><ol><li>Crawler：负责管理和启动各个Input</li><li>Input：负责管理和解析输入源的信息，以及为每个文件启动Harvester。可由配置文件指定输入源信息。</li><li>Harvester: Harvester负责读取一个文件的信息。</li><li>Pipeline: 负责管理缓存、Harvester的信息写入以及Output的消费等，是Filebeat最核心的组件。</li><li>Output: 输出源，可由配置文件指定输出源信息。</li><li>Registrar：管理记录每个文件处理状态，包括偏移量、文件名等信息。当Filebeat启动时，会从Registrar恢复文件处理状态。</li></ol><p>filebeat的整个生命周期，几个组件共同协作，完成了日志从采集到上报的整个过程。</p><h1 id="日志采集流程"><a href="#日志采集流程" class="headerlink" title="日志采集流程"></a>日志采集流程</h1><p>Filebeat不仅支持普通文本日志的作为输入源，还内置支持了redis的慢查询日志、stdin、tcp和udp等作为输入源。</p><p>本文只分析下普通文本日志的处理方式，对于普通文本日志，可以按照以下配置方式，指定log的输入源信息。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">filebeat.inputs:</span></span><br><span class="line"><span class="attr">- type:</span> <span class="string">log</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/var/log/*.log</span></span><br></pre></td></tr></table></figure><p>其中Input也可以指定多个, 每个Input下的Log也可以指定多个。</p><p>filebeat启动时会开启Crawler，对于配置中的每条Input，Crawler都会启动一个Input进行处理，代码如下所示：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Crawler)</span> <span class="title">Start</span><span class="params">(...)</span></span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> _, inputConfig := <span class="keyword">range</span> c.inputConfigs &#123;</span><br><span class="line">        err := c.startInput(pipeline, inputConfig, r.GetStates())</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于指定的paths可以配置多个，而且可以是Glob类型，因此Filebeat将会匹配到多个配置文件。</p><p>Input对于每个匹配到的文件，都会开启一个Harvester进行逐行读取，每个Harvester都工作在自己的的goroutine中。</p><p>Harvester的工作流程非常简单，就是逐行读取文件，并更新该文件暂时在Input中的文件偏移量（注意，并不是Registrar中的偏移量），读取完成则结束流程。</p><p>同时，我们需要考虑到，日志型的数据其实是在不断增长和变化的：</p><ol><li>会有新的日志在不断产生</li><li>可能一个日志文件对应的Harvester退出后，又再次有了内容更新。</li></ol><p>为了解决这两个情况，filebeat采用了Input定时扫描的方式。代码如下，可以看出，Input扫描的频率是由用户指定的<code>scan_frequency</code>配置来决定的( 默认10s扫描一次)。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Runner)</span> <span class="title">Run</span><span class="params">()</span></span> &#123;</span><br><span class="line">p.input.Run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> p.Once &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-p.done:</span><br><span class="line">logp.Info(<span class="string">"input ticker stopped"</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(p.config.ScanFrequency): <span class="comment">// 定时扫描</span></span><br><span class="line">logp.Debug(<span class="string">"input"</span>, <span class="string">"Run input"</span>)</span><br><span class="line">p.input.Run()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>此外，如果用户启动时指定了<code>--once</code>选项，则扫描只会进行一次，就退出了。</p><h1 id="日志定时扫描及异常处理"><a href="#日志定时扫描及异常处理" class="headerlink" title="日志定时扫描及异常处理"></a>日志定时扫描及异常处理</h1><p>我们之前讲到Registrar会记录每个文件的状态，当Filebeat启动时，从Registrar启动时，会从Registrar恢复文件处理状态。</p><p>其实在filebeat运行过程中，Input组件也记录了文件状态。不一样的是，Registrar是持久化存储，而Input中的文件状态仅表示当前文件的读取偏移量，且修改时不会同步到磁盘中。</p><p>每次，Filebeat刚启动时，Input都会载入Registrar中记录的文件状态，作为初始状态。Input中的状态有两个非常重要：</p><ol><li>offset: 代表文件当前读取的offset，从Registrar中初始化。Harvest读取文件后，会同时修改offset。</li><li>finished: 代表该文件对应的Harvester是否已经结束，Harvester开始时置为false，结束时置为False。</li></ol><p>对于每次定时扫描到的文件，概括来说，会有三种大的情况：</p><ol><li>Input找不到该文件状态的记录, 说明是新增文件，则开启一个Harvester，从头开始解析该文件</li><li>如果可以找到文件状态，且finished等于false。这个说明已经有了一个Harvester在处理了，这种情况直接忽略就好了。</li><li>如果可以找到文件状态，且finished等于true。说明之前有Harvester处理过，但已经处理结束了。</li></ol><p>对于这种第三种情况，我们需要考虑到一些异常情况，Filebeat是这么处理的：</p><ol><li>如果offset大于当前文件大小：说明文件被Truncate过，此时按做一个新文件处理，直接从头开始解析该文件</li><li>如果offset小于当前文件大小，说明文件内容有新增，则从上次offset处继续读即可。</li></ol><p>对于第二种情况，Filebeat似乎有一个逻辑上的问题: 如果文件被Truncate过，后来又新增了数据，且文件大小也比之前offset大，那么Filebeat是检查不出来这个问题的。</p><p>除此之外，一个比较有意思的点是，Filebeat甚至可以处理文件名修改的问题。即使一个日志的文件名被修改过，Filebeat重启后，也能找到该文件，从上次读过的地方继续读。</p><p>这是因为Filebeat除了在Registrar存储了文件名，还存储了文件的唯一标识。对于Linux来说，这个文件的唯一标识就是该文件的inode ID + device ID。</p><p>至此，我们可以清楚的知道，Filebeat是如何采集日志文件，同时做到监听日志文件的更新和修改。而日志采集过程，Harvest会将数据写到Pipeline中。我们接下来看下数据是如何写入到Pipeline中的。</p><h1 id="Pipeline的写入"><a href="#Pipeline的写入" class="headerlink" title="Pipeline的写入"></a>Pipeline的写入</h1><p>Haveseter会将数据写入缓存中，而另一方面Output会从缓存将数据读走。整个生产消费的过程都是由Pipeline进行调度的，而整个调度过程也非常复杂。</p><p>此外，Filebeat的缓存目前分为memqueue和spool。memqueue顾名思义就是内存缓存，spool则是将数据缓存到磁盘中。本文将基于memqueue讲解整个调度过程。</p><p>我们首先看下Haveseter是如何将数据写入缓存中的，如下图所示：</p><p><img src="/img/filebeat/produce-to-pipeline.png" alt=""></p><p>Harvester通过pipeline提供的pipelineClient将数据写入到pipeline中，Haveseter会将读到的数据会包装成一个Event结构体，再递交给pipeline。</p><p>在Filebeat的实现中，pipelineClient并不直接操作缓存，而是将event先写入一个events channel中。</p><p>同时，有一个eventloop组件，会监听events channel的事件到来，等event到达时，eventloop会将其放入缓存中。</p><p>当缓存满的时候，eventloop直接移除对该channel的监听。<br>每次event ACK或者取消后，缓存不再满了，则eventloop会重新监听events channel。</p><p>以上是Pipeline的写入过程，此时event已被写入到了缓存中。<br>但是Output是如何从缓存中拿到event数据的？</p><h1 id="Pipeline的消费过程"><a href="#Pipeline的消费过程" class="headerlink" title="Pipeline的消费过程"></a>Pipeline的消费过程</h1><p>整个消费的过程非常复杂，数据会在多个channel之间传递流转，如下图所示：<br><img src="/img/filebeat/consume-from-pipeline.png" alt=""></p><p>首先再介绍两个角色：</p><ol><li>consumer： pipeline在创建的时候，会同时创建一个consumer。consumer负责从缓存中取数据</li><li>client worker：负责接收consumer传来的数据，并调用Output的Publish函数进行上报。</li></ol><p>与producer类似，consumer也不直接操作缓存，而是会向get channel中写入消费请求。<br>consumer本身是个后台loop的过程，这个消费请求会不断进行。</p><p>eventloop监听get channel, 拿到之后会从缓存中取数据。并将数据写入到resp channel中。<br>consumer从resp channel中拿到event数据后，又会将其写入到workQueue。</p><p>workQueue也是个channel。client worker会监听该channel上的数据到来，将数据交给Output client进行Publish上报。</p><p>而且，Output收到的是Batch Events，即会一次收到一批Events。BatchSize由各个Output自行决定。</p><p>至此，消息已经递交给了Output组件。</p><h1 id="Ack机制"><a href="#Ack机制" class="headerlink" title="Ack机制"></a>Ack机制</h1><p>filebeat之所以可以保证日志可以at least once的上报，就是基于其Ack机制。</p><p>简单来说，Ack机制就是，当Output Publish成功之后会调用ACK，最终Registrar会收到ACK，并修改偏移量。</p><p>而且, Registrar只会在Output调用batch的相关信号时，才改变文件偏移量。其中Batch对外提供了这些信号：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Batch <span class="keyword">interface</span> &#123;</span><br><span class="line">Events() []Event</span><br><span class="line"></span><br><span class="line"><span class="comment">// signals</span></span><br><span class="line">ACK()</span><br><span class="line">Drop()</span><br><span class="line">Retry()</span><br><span class="line">RetryEvents(events []Event)</span><br><span class="line">Cancelled()</span><br><span class="line">CancelledEvents(events []Event)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Output在Publish之后，无论失败，必须调用这些函数中的其中一个。</p><p>以下是Output Publish成功后调用Ack的流程：<br><img src="/img/filebeat/ack.png" alt="ack"></p><p>可以看到其中起核心作用的组件是Ackloop。AckLoop中有一个ackChanList，其中每一个ackChan，对应于转发给Output的一个Batch。<br>每次新建一个Batch，同时会建立一个ackChan，该ackChan会被append到ackChanList中。</p><p>而AckLoop每次只监听处于ackChanList最头部的ackChan。</p><p>当Batch被Output调用Ack后，AckLoop会收到对应ackChan上的事件，并将其最终转发给Registrar。同时，ackChanList将会pop头部的ackChan，继续监听接下来的Ack事件。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>了解了Filebeat的实现原理，我们才有会明白Filebeat配置中各个参数对程序的最终影响。同时，由于FileBeat是At least once的上报，但并不保证Exactly once, 因此一条数据可能会被上报多次，所以接收端需要自行进行去重过滤。</p><h1 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h1><ul><li><a href="https://www.cyhone.com/articles/usage-of-filebeat-log-config/">FileBeat-Log相关配置介绍</a></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/how-filebeat-works.html" target="_blank" rel="noopener">How FileBeat Works</a></li><li><a href="https://cloud.tencent.com/developer/article/1367784" target="_blank" rel="noopener">filebeat源码解析</a></li><li><a href="https://niyanchun.com/filebeat-truncate-bug.html" target="_blank" rel="noopener">filebeat数据重复和截断及丢失问题分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/72912085" target="_blank" rel="noopener">容器日志采集利器：filebeat深度剖析与实践</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Filebeat是使用Golang实现的轻量型日志采集器，也是Elasticsearch stack里面的一员。本质上是一个agent，可以安装在各个节点上，根据配置读取对应位置的日志，并上报到相应的地方去。&lt;/p&gt;
&lt;p&gt;Filebeat的可靠性很强，可以保证日志At least once的上报，同时也考虑了日志搜集中的各类问题，例如日志断点续读、文件名更改、日志Truncated等。&lt;/p&gt;
&lt;p&gt;Filebeat并不依赖于ElasticSearch，可以单独存在。我们可以单独使用Filebeat进行日志的上报和搜集。filebeat内置了常用的Output组件, 例如kafka、ElasticSearch、redis等，出于调试考虑，也可以输出到console和file。我们可以利用现有的Output组件，将日志进行上报。&lt;/p&gt;
&lt;p&gt;当然，我们也可以自定义Output组件，让Filebeat将日志转发到我们想要的地方。&lt;/p&gt;
&lt;p&gt;filebeat其实是&lt;a href=&quot;https://github.com/elastic/beats&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;elastic/beats&lt;/a&gt;的一员，除了filebeat外，还有HeartBeat、PacketBeat。这些beat的实现都是基于libbeat框架。&lt;/p&gt;
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://www.cyhone.com/categories/ElasticSearch/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Filebeat" scheme="http://www.cyhone.com/tags/Filebeat/"/>
    
      <category term="ElasticSearch" scheme="http://www.cyhone.com/tags/ElasticSearch/"/>
    
      <category term="大数据" scheme="http://www.cyhone.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>uber-go漏桶限流器使用与原理分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/"/>
    <id>http://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/</id>
    <published>2019-11-10T07:40:19.000Z</published>
    <updated>2019-11-12T09:45:37.478Z</updated>
    
    <content type="html"><![CDATA[<p>uber在Github上开源了一套用于服务限流的go语言库<a href="https://github.com/uber-go/ratelimit/" target="_blank" rel="noopener">ratelimit</a>, 该组件基于Leaky Bucket(漏桶)实现。</p><p>我在之前写过<a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">《Golang限流器time/rate实现剖析》</a>，讲了Golang标准库中提供的基于Token Bucket实现限流组件的<code>time/rate</code>原理，同时也讲了限流的一些背景。</p><p>相比于TokenBucket，只要桶内还有剩余令牌，调用方就可以一直消费。而Leaky Bucket相对来说比较严格，调用方只能严格按照这个间隔顺序进行消费调用。(实际上，uber-go对这个限制也做了一些优化，具体可以看下文详解)</p><p>还是老规矩，在正式讲其实现之前，我们先看下ratelimit的使用方法。<br><a id="more"></a></p><h1 id="ratelimit的使用"><a href="#ratelimit的使用" class="headerlink" title="ratelimit的使用"></a>ratelimit的使用</h1><p>我们直接看下uber-go官方库给的例子：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">rl := ratelimit.New(<span class="number">100</span>) <span class="comment">// per second</span></span><br><span class="line"></span><br><span class="line">prev := time.Now()</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">  now := rl.Take()</span><br><span class="line">  fmt.Println(i, now.Sub(prev))</span><br><span class="line">  prev = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们给定限流器每秒可以通过100个请求，也就是平均每个请求间隔10ms。<br>因此，最终会每10ms打印一行数据。输出结果如下：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Output:</span></span><br><span class="line"><span class="comment">// 0 0</span></span><br><span class="line"><span class="comment">// 1 10ms</span></span><br><span class="line"><span class="comment">// 2 10ms</span></span><br><span class="line"><span class="comment">// 3 10ms</span></span><br><span class="line"><span class="comment">// 4 10ms</span></span><br><span class="line"><span class="comment">// 5 10ms</span></span><br><span class="line"><span class="comment">// 6 10ms</span></span><br><span class="line"><span class="comment">// 7 10ms</span></span><br><span class="line"><span class="comment">// 8 10ms</span></span><br><span class="line"><span class="comment">// 9 10ms</span></span><br></pre></td></tr></table></figure></p><h1 id="基本实现"><a href="#基本实现" class="headerlink" title="基本实现"></a>基本实现</h1><p>要实现以上每秒固定速率的目的，其实还是比较简单的。</p><p>在ratelimit的New函数中，传入的参数是每秒允许请求量(RPS)。<br>我们可以很轻易的换算出每个请求之间的间隔：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">limiter.perRequest = time.Second / time.Duration(rate)</span><br></pre></td></tr></table></figure><p>以上<code>limiter.perRequest</code>指的就是每个请求之间的间隔时间。</p><p>如下图，当请求1处理结束后, 我们记录下请求1的处理完成的时刻, 记为<code>limiter.last</code>。<br>稍后请求2到来, 如果此刻的时间与<code>limiter.last</code>相比并没有达到<code>perRequest</code>的间隔大小，那么sleep一段时间即可。</p><p><img src="/img/token-bucket/wait-interval.png" alt="漏桶示例图"></p><p>对应ratelimit的实现代码如下：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sleepFor = t.perRequest - now.Sub(t.last)</span><br><span class="line"><span class="keyword">if</span> sleepFor &gt; <span class="number">0</span> &#123;</span><br><span class="line">t.clock.Sleep(sleepFor)</span><br><span class="line">t.last = now.Add(sleepFor)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">t.last = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="最大松弛量"><a href="#最大松弛量" class="headerlink" title="最大松弛量"></a>最大松弛量</h1><p>我们讲到，传统的Leaky Bucket，每个请求的间隔是固定的，然而，在实际上的互联网应用中，流量经常是突发性的。对于这种情况，uber-go对Leaky Bucket做了一些改良，引入了最大松弛量(maxSlack)的概念。</p><p>我们先理解下整体背景: 假如我们要求每秒限定100个请求，平均每个请求间隔10ms。但是实际情况下，有些请求间隔比较长，有些请求间隔比较短。如下图所示：</p><p><img src="/img/token-bucket/3-requests.png" alt=""></p><p>请求1完成后，15ms后，请求2才到来，可以对请求2立即处理。请求2完成后，5ms后，请求3到来，这个时候距离上次请求还不足10ms，因此还需要等待5ms。</p><p>但是，对于这种情况，实际上三个请求一共消耗了25ms才完成，并不是预期的20ms。在uber-go实现的ratelimit中，可以把之前间隔比较长的请求的时间，匀给后面的使用，保证每秒请求数(RPS)即可。</p><p>对于以上case，因为请求2相当于多等了5ms，我们可以把这5ms移给请求3使用。加上请求3本身就是5ms之后过来的，一共刚好10ms，所以请求3无需等待，直接可以处理。此时三个请求也恰好一共是20ms。<br>如下图所示：</p><p><img src="/img/token-bucket/maxslack.png" alt=""></p><p>在ratelimit的对应实现中很简单，是把每个请求多余出来的等待时间累加起来，以给后面的抵消使用。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">t.sleepFor += t.perRequest - now.Sub(t.last)</span><br><span class="line"><span class="keyword">if</span> t.sleepFor &gt; <span class="number">0</span> &#123;</span><br><span class="line">  t.clock.Sleep(t.sleepFor)</span><br><span class="line">  t.last = now.Add(t.sleepFor)</span><br><span class="line">  t.sleepFor = <span class="number">0</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  t.last = now</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里跟上述代码不同的是，这里是<code>+=</code>。而同时<code>t.perRequest - now.Sub(t.last)</code>是可能为负值的，负值代表请求间隔时间比预期的长。</p><p>当<code>t.sleepFor &gt; 0</code>，代表此前的请求多余出来的时间，无法完全抵消此次的所需量，因此需要sleep相应时间, 同时将<code>t.sleepFor</code>置为0。</p><p>当<code>t.sleepFor &lt; 0</code>，说明此次请求间隔大于预期间隔，将多出来的时间累加到<code>t.sleepFor</code>即可。</p><p>但是，对于某种情况，请求1完成后，请求2过了很久到达(好几个小时都有可能)，那么此时对于请求2的请求间隔<code>now.Sub(t.last)</code>，会非常大。以至于即使后面大量请求瞬时到达，也无法抵消完这个时间。那这样就失去了限流的意义。</p><p>为了防止这种情况，ratelimit就引入了最大松弛量(maxSlack)的概念, 该值为负值，表示允许抵消的最长时间，防止以上情况的出现。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> t.sleepFor &lt; t.maxSlack &#123;</span><br><span class="line">  t.sleepFor = t.maxSlack</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ratelimit中maxSlack的值为<code>-10 * time.Second / time.Duration(rate)</code>, 是十个请求的间隔大小。我们也可以理解为ratelimit允许的最大瞬时请求为10。</p><h1 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h1><p>ratelimit的New函数，除了可以配置每秒请求数(QPS)， 其实还提供了一套可选配置项Option。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">(rate <span class="keyword">int</span>, opts ...Option)</span> <span class="title">Limiter</span></span></span><br></pre></td></tr></table></figure><p>Option的类型为<code>type Option func(l *limiter)</code>, 也就是说我们可以提供一些这样类型的函数，作为Option，传给ratelimit, 定制相关需求。</p><p>但实际上，自定义Option的用处比较小，因为<code>limiter</code>结构体本身就是个私有类型，我们并不能拿它做任何事情。</p><p>我们只需要了解ratelimit目前提供的两个配置项即可：</p><h2 id="WithoutSlack"><a href="#WithoutSlack" class="headerlink" title="WithoutSlack"></a><code>WithoutSlack</code></h2><p>我们上文讲到ratelimit中引入了最大松弛量的概念，而且默认的最大松弛量为10个请求的间隔时间。</p><p>但是确实会有这样需求场景，需要严格的限制请求的固定间隔。那么我们就可以利用WithoutSlack来取消松弛量的影响。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">limiter := ratelimit.New(<span class="number">100</span>, ratelimit.WithoutSlack)</span><br></pre></td></tr></table></figure><h2 id="WithClock-clock-Clock"><a href="#WithClock-clock-Clock" class="headerlink" title="WithClock(clock Clock)"></a><code>WithClock(clock Clock)</code></h2><p>我们上文讲到，ratelimit的实现时，会计算当前时间与上次请求时间的差值，并sleep相应时间。<br>在ratelimit基于go标准库的time实现时间相关计算。如果有精度更高或者特殊需求的计时场景，可以用WithClock来替换默认时钟。</p><p>通过该方法，只要实现了Clock的interface，就可以自定义时钟了。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Clock <span class="keyword">interface</span> &#123;</span><br><span class="line">Now() time.Time</span><br><span class="line">Sleep(time.Duration)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">clock &amp;= MyClock&#123;&#125;</span><br><span class="line">limiter := ratelimit.New(<span class="number">100</span>, ratelimit.WithClock(clock))</span><br></pre></td></tr></table></figure><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">Golang限流器time/rate实现剖析</a></li><li><a href="https://www.cyhone.com/articles/usage-of-golang-rate/">Golang限流器time/rate使用介绍</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;uber在Github上开源了一套用于服务限流的go语言库&lt;a href=&quot;https://github.com/uber-go/ratelimit/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ratelimit&lt;/a&gt;, 该组件基于Leaky Bucket(漏桶)实现。&lt;/p&gt;
&lt;p&gt;我在之前写过&lt;a href=&quot;https://www.cyhone.com/articles/analisys-of-golang-rate/&quot;&gt;《Golang限流器time/rate实现剖析》&lt;/a&gt;，讲了Golang标准库中提供的基于Token Bucket实现限流组件的&lt;code&gt;time/rate&lt;/code&gt;原理，同时也讲了限流的一些背景。&lt;/p&gt;
&lt;p&gt;相比于TokenBucket，只要桶内还有剩余令牌，调用方就可以一直消费。而Leaky Bucket相对来说比较严格，调用方只能严格按照这个间隔顺序进行消费调用。(实际上，uber-go对这个限制也做了一些优化，具体可以看下文详解)&lt;/p&gt;
&lt;p&gt;还是老规矩，在正式讲其实现之前，我们先看下ratelimit的使用方法。&lt;br&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Golang限流器time/rate实现剖析</title>
    <link href="http://www.cyhone.com/articles/analisys-of-golang-rate/"/>
    <id>http://www.cyhone.com/articles/analisys-of-golang-rate/</id>
    <published>2019-11-05T05:35:19.000Z</published>
    <updated>2019-11-18T03:38:37.679Z</updated>
    
    <content type="html"><![CDATA[<p>限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章<a href="https://www.cyhone.com/articles/usage-of-golang-rate/">《Golang限流器time/rate使用介绍》</a>简单介绍了time/rate的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。</p><p>上一篇文章讲到，time/rate是基于Token Bucket(令牌桶)算法实现的限流。本文将会基于源码，深入剖析下Golang是如何实现Token Bucket的。其代码也非常简洁，去除注释后，也就200行左右的代码量。</p><p>同时，我也提供了<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/go/x/time" target="_blank" rel="noopener">time/rate注释版</a>，辅助大家理解该组件的实现。</p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放Token，桶满则暂时不放。<br>而用户则从桶中取Token，如果有剩余Token就可以一直取。如果没有剩余Token，则需要等到系统中被放置了Token才行。</p><p>一般介绍Token Bucket的时候，都会有一张这样的原理图：<br><img src="/img/token-bucket/token-bucket.jpg" alt="Token Bucket原理图"></p><p>从这个图中看起来，似乎令牌桶实现应该是这样的：</p><blockquote><p>有一个Timer和一个BlockingQueue。Timer固定的往BlockingQueue中放token。用户则从BlockingQueue中取数据。</p></blockquote><p>这固然是Token Bucket的一种实现方式，这么做也非常直观，但是效率太低了：我们需要不仅多维护一个Timer和BlockingQueue，而且还耗费了一些不必要的内存。</p><p>在Golang的<code>timer/rate</code>中的实现, 并没有单独维护一个Timer，而是采用了lazyload的方式，直到每次消费之前才根据时间差更新Token数目，而且也不是用BlockingQueue来存放Token，而是仅仅通过计数的方式。</p><h1 id="Token的生成和消费"><a href="#Token的生成和消费" class="headerlink" title="Token的生成和消费"></a>Token的生成和消费</h1><p>我们在<a href="https://www.cyhone.com/articles/usage-of-golang-rate/">上一篇文章</a>中讲到，Token的消费方式有三种。但其实在内部实现，最终三种消费方式都调用了reserveN函数来生成和消费Token。</p><p>我们看下reserveN函数的具体实现，整个过程非常简单。在正式讲之前，我们先了解一个简单的概念：</p><p>在<code>time/rate</code>中，<code>NewLimiter</code>的第一个参数是速率limit，代表了一秒钟可以产生多少Token。<br>那么简单换算一下，我们就可以知道一个Token的生成间隔是多少。</p><p>有了这个生成间隔，我们就可以轻易地得到两个数据：<br> <strong>1. 生成N个新的Token一共需要多久。</strong><code>time/rate</code>中对应的实现函数为<code>durationFromTokens</code>。<br> <strong>2. 给定一段时长，这段时间一共可以生成多少个Token。</strong><code>time/rate</code>中对应的实现函数为<code>tokensFromDuration</code>。</p><p>那么，有了这些转换函数，整个过程就很清晰了，如下：</p><ol><li><p>计算从上次取Token的时间到当前时刻，期间一共新产生了多少Token：<br>我们只在取Token之前生成新的Token，也就意味着每次取Token的间隔，实际上也是生成Token的间隔。我们可以利用<code>tokensFromDuration</code>, 轻易的算出这段时间一共产生Token的数目。<br>那么，当前Token数目 = 新产生的Token数目 + 之前剩余的Token数目 - 要消费的Token数目。</p></li><li><p>如果消费后剩余Token数目大于零，说明此时Token桶内仍不为空，此时Token充足，无需调用侧等待。<br>如果Token数目小于零，则需等待一段时间。<br>那么这个时候，我们可以利用<code>durationFromTokens</code>将当前负值的Token数转化为需要等待的时间。</p></li><li><p>将需要等待的时间等相关结果返回给调用方。</p></li></ol><p>从上面可以看出，其实整个过程就是利用了<strong>Token数可以和时间相互转化</strong>的原理。而如果Token数为负，则需要等待相应时间即可。</p><p><strong>注意：</strong>如果当消费时，Token桶中的Token数目已经为负值了，依然可以按照上述流程进行消费。随着负值越来越小，等待的时间将会越来越长。<br>从结果来看，这个行为跟用Timer+BlockQueue实现是一样的。</p><p>此外，整个过程为了保证线程安全，更新令牌桶相关数据时都用了mutex加锁。</p><p>我们模拟下请求与Token数变化的关系：</p><ol><li>当某一时间，桶内Token数为3, 此时A线程请求5个Token。那么此时桶内Token不足，因此A线程需要等待2个Token的时间。<br>且此时桶内Token数变为-2。</li><li>同时，B线程请求4个Token，此时桶内Token数为-2，因此B线程需要等待2+4=6个Token的时间，且此时桶内Token数变为-6。</li></ol><p>对于Allow函数实现时，只要判断需要等待的时间是否为0即可，如果大于0说明需要等待，则返回False，反之返回True。</p><p>对于Wait函数，直接<code>t := time.NewTimer(delay)</code>，等待对应的时间即可。</p><h1 id="float精度问题"><a href="#float精度问题" class="headerlink" title="float精度问题"></a>float精度问题</h1><p>从上面原理讲述可以看出，在Token和时间的相互转化函数<code>durationFromTokens</code>和<code>tokensFromDuration</code>中，涉及到float64的乘除运算。<br>一谈到float的乘除，我们就需要小心精度问题了。</p><p>而Golang在这里也踩了坑，以下是<code>tokensFromDuration</code>最初的实现版本</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(limit Limit)</span> <span class="title">tokensFromDuration</span><span class="params">(d time.Duration)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> d.Seconds() * <span class="keyword">float64</span>(limit)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个操作看起来一点问题都没：每秒生成的Token数乘于秒数。<br>然而，这里的问题在于，<code>d.Seconds()</code>已经是小数了。两个小数相乘，会带来精度的损失。</p><p>所以就有了这个issue:<a href="https://github.com/golang/go/issues/34861" target="_blank" rel="noopener">golang.org/issues/34861</a>。</p><p>修改后新的版本如下：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(limit Limit)</span> <span class="title">tokensFromDuration</span><span class="params">(d time.Duration)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line">sec := <span class="keyword">float64</span>(d/time.Second) * <span class="keyword">float64</span>(limit)</span><br><span class="line">nsec := <span class="keyword">float64</span>(d%time.Second) * <span class="keyword">float64</span>(limit)</span><br><span class="line"><span class="keyword">return</span> sec + nsec/<span class="number">1e9</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>time.Duration</code>是<code>int64</code>的别名，代表纳秒。分别求出秒的整数部分和小数部分，进行相乘后再相加，这样可以得到最精确的精度。</p><h1 id="数值溢出问题"><a href="#数值溢出问题" class="headerlink" title="数值溢出问题"></a>数值溢出问题</h1><p>我们讲reserveN函数的具体实现时，第一步就是计算从当前时间到上次取Token的时刻，期间一共新产生了多少Token，同时也可得出当前的Token是多少。</p><p>我最开始的理解是，直接可以这么做：<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// elapsed表示过去的时间差</span></span><br><span class="line">elapsed := now.Sub(lim.last)</span><br><span class="line"><span class="comment">// delta表示这段时间一共新产生了多少Token</span></span><br><span class="line">delta = tokensFromDuration(now.Sub(lim.last))</span><br><span class="line"></span><br><span class="line">tokens := lim.tokens + delta</span><br><span class="line"><span class="keyword">if</span>(token &gt; lim.burst)&#123;</span><br><span class="line">token = lim.burst</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中，<code>lim.tokens</code>是当前剩余的Token，<code>lim.last</code>是上次取token的时刻。<code>lim.burst</code>是Token桶的大小。<br>使用tokensFromDuration计算出新生成了多少Token，累加起来后，不能超过桶的容量即可。</p><p>这么做看起来也没什么问题，然而并不是这样。</p><p>在<code>time/rate</code>里面是这么做的，如下代码所示：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">maxElapsed := lim.limit.durationFromTokens(<span class="keyword">float64</span>(lim.burst) - lim.tokens)</span><br><span class="line">elapsed := now.Sub(last)</span><br><span class="line"><span class="keyword">if</span> elapsed &gt; maxElapsed &#123;</span><br><span class="line">elapsed = maxElapsed</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">delta := lim.limit.tokensFromDuration(elapsed)</span><br><span class="line"></span><br><span class="line">tokens := lim.tokens + delta</span><br><span class="line"><span class="keyword">if</span> burst := <span class="keyword">float64</span>(lim.burst); tokens &gt; burst &#123;</span><br><span class="line">tokens = burst</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>与我们最开始的代码不一样的是，它没有直接用<code>now.Sub(lim.last)</code>来转化为对应的Token数，而是<br>先用<code>lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)</code>，计算把桶填满的时间maxElapsed。<br>取elapsed和maxElapsed的最小值。</p><p>这么做算出的结果肯定是正确的，但是这么做相比于我们的做法，好处在哪里？</p><p>对于我们的代码，当last非常小的时候（或者当其为初始值0的时候），此时<code>now.Sub(lim.last)</code>的值就会非常大，如果<code>lim.limit</code>即每秒生成的Token数目也非常大时，直接将二者进行乘法运算，<strong>结果有可能会溢出。</strong></p><p>因此，<code>time/rate</code>先计算了把桶填满的时间，将其作为时间差值的上限，这样就规避了溢出的问题。</p><h1 id="Token的归还"><a href="#Token的归还" class="headerlink" title="Token的归还"></a>Token的归还</h1><p>而对于Reserve函数，返回的结果中，我们可以通过<code>Reservation.Delay()</code>函数，得到需要等待时间。<br>同时调用方可以根据返回条件和现有情况，可以调用<code>Reservation.Cancel()</code>函数，取消此次消费。<br>当调用<code>Cancel()</code>函数时，消费的Token数将会尽可能归还给Token桶。</p><p>此外，我们在<a href="https://www.cyhone.com/articles/usage-of-golang-rate/">上一篇文章</a>中讲到，Wait函数可以通过Context进行取消或者超时等，<br>当通过Context进行取消或超时时，此时消费的Token数也会归还给Token桶。</p><p>然而，归还Token的时候，并不是简单的将Token数直接累加到现有Token桶的数目上，这里还有一些注意点：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">restoreTokens := <span class="keyword">float64</span>(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct))</span><br><span class="line"><span class="keyword">if</span> restoreTokens &lt;= <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码就是计算需要归还多少的Token。其中：</p><ol><li><code>r.tokens</code>指的是本次消费的Token数</li><li><code>r.timeToAct</code>指的是Token桶可以满足本次消费数目的时刻，也就是消费的时刻+等待的时长。</li><li><code>r.lim.lastEvent</code>指的是最近一次消费的timeToAct值</li></ol><p>其中：<code>r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct))</code> 指的是，从该次消费到当前时间，一共又新消费了多少Token数目。</p><p>根据代码来看，要归还的Token要是该次消费的Token减去新消费的Token。<br>不过这里我还没有想明白，为什么归还的时候，要减去新消费数目。</p><p>按照我的理解，直接归还全部Token数目，这样对于下一次消费是无感知影响的。这块的具体原因还需要进一步探索。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Token Bucket其实非常适合互联网突发式请求的场景，其请求Token时并不是严格的限制为固定的速率，而是中间有一个桶作为缓冲。<br>只要桶中还有Token，请求就还可以一直进行。当突发量激增到一定程度，则才会按照预定速率进行消费。</p><p>此外在维基百科中，也提到了分层Token Bucket(HTB)作为传统Token Bucket的进一步优化，Linux内核中也用它进行流量控制。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">Wiki: Token bucket</a></li></ul><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/usage-of-golang-rate/">Golang限流器time/rate使用介绍</a></li><li><a href="https://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/">uber-go漏桶限流器使用与原理分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章&lt;a href=&quot;https://www.cyhone.com/articles/usage-of-golang-rate/&quot;&gt;《Golang限流器time/rate使用介绍》&lt;/a&gt;简单介绍了time/rate的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。&lt;/p&gt;
&lt;p&gt;上一篇文章讲到，time/rate是基于Token Bucket(令牌桶)算法实现的限流。本文将会基于源码，深入剖析下Golang是如何实现Token Bucket的。其代码也非常简洁，去除注释后，也就200行左右的代码量。&lt;/p&gt;
&lt;p&gt;同时，我也提供了&lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/go/x/time&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;time/rate注释版&lt;/a&gt;，辅助大家理解该组件的实现。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Golang限流器time/rate使用介绍</title>
    <link href="http://www.cyhone.com/articles/usage-of-golang-rate/"/>
    <id>http://www.cyhone.com/articles/usage-of-golang-rate/</id>
    <published>2019-11-02T12:21:54.000Z</published>
    <updated>2019-11-12T09:45:37.478Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本主题为系列文章，分上下两篇。本文主要介绍<code>time/rate</code>的具体使用方法，另外一篇文章<a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">《Golang限流器time/rate实现剖析》</a>则着重介绍其内部实现原理。</p></blockquote><p>限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。<br>限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket等。</p><p>其实golang标准库中就自带了限流算法的实现，即<code>golang.org/x/time/rate</code>。<br>该限流器是基于Token Bucket(令牌桶)实现的。</p><p>简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放Token，桶满则暂时不放。<br>而用户则从桶中取Token，如果有剩余Token就可以一直取。如果没有剩余Token，则需要等到系统中被放置了Token才行。</p><a id="more"></a><p>本文则主要集中介绍下该组件的具体使用方法：</p><h1 id="构造一个限流器"><a href="#构造一个限流器" class="headerlink" title="构造一个限流器"></a>构造一个限流器</h1><p>我们可以使用以下方法构造一个限流器对象：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">limiter := NewLimiter(<span class="number">10</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>这里有两个参数：</p><ol><li>第一个参数是<code>r Limit</code>。代表每秒可以向Token桶中产生多少token。Limit实际上是float64的别名。</li><li>第二个参数是<code>b int</code>。b代表Token桶的容量大小。</li></ol><p>那么，对于以上例子来说，其构造出的限流器含义为，其令牌桶大小为1, 以每秒10个Token的速率向桶中放置Token。</p><p>除了直接指定每秒产生的Token个数外，还可以用Every方法来指定向Token桶中放置Token的间隔，例如：</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">limit := Every(<span class="number">100</span> * time.Millisecond);</span><br><span class="line">limiter := NewLimiter(limit, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>以上就表示每100ms往桶中放一个Token。本质上也就是一秒钟产生10个。</p><p>Limiter提供了三类方法供用户消费Token，用户可以每次消费一个Token，也可以一次性消费多个Token。<br>而每种方法代表了当Token不足时，各自不同的对应手段。</p><h1 id="Wait-WaitN"><a href="#Wait-WaitN" class="headerlink" title="Wait/WaitN"></a>Wait/WaitN</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Wait</span><span class="params">(ctx context.Context)</span> <span class="params">(err error)</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">WaitN</span><span class="params">(ctx context.Context, n <span class="keyword">int</span>)</span> <span class="params">(err error)</span></span></span><br></pre></td></tr></table></figure><p>Wait实际上就是<code>WaitN(ctx,1)</code>。</p><p>当使用Wait方法消费Token时，如果此时桶内Token数组不足(小于N)，那么Wait方法将会阻塞一段时间，直至Token满足条件。如果充足则直接返回。</p><p>这里可以看到，Wait方法有一个context参数。<br>我们可以设置context的Deadline或者Timeout，来决定此次Wait的最长时间。</p><h1 id="Allow-AllowN"><a href="#Allow-AllowN" class="headerlink" title="Allow/AllowN"></a>Allow/AllowN</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Allow</span><span class="params">()</span> <span class="title">bool</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">AllowN</span><span class="params">(now time.Time, n <span class="keyword">int</span>)</span> <span class="title">bool</span></span></span><br></pre></td></tr></table></figure><p>Allow实际上就是<code>AllowN(time.Now(),1)</code>。</p><p>AllowN方法表示，截止到某一时刻，目前桶中数目是否至少为n个，满足则返回true，同时从桶中消费n个token。<br>反之返回不消费Token，false。</p><p>通常对应这样的线上场景，如果请求速率过快，就直接丢到某些请求。</p><h1 id="Reserve-ReserveN"><a href="#Reserve-ReserveN" class="headerlink" title="Reserve/ReserveN"></a>Reserve/ReserveN</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(lim *Limiter)</span> <span class="title">Reserve</span><span class="params">()</span> *<span class="title">Reservation</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="params">(lim *Limiter)</span> <span class="title">ReserveN</span><span class="params">(now time.Time, n <span class="keyword">int</span>)</span> *<span class="title">Reservation</span></span></span><br></pre></td></tr></table></figure><p>Reserve相当于<code>ReserveN(time.Now(), 1)</code>。</p><p>ReserveN的用法就相对来说复杂一些，当调用完成后，无论Token是否充足，都会返回一个Reservation*对象。</p><p>你可以调用该对象的Delay()方法，该方法返回了需要等待的时间。如果等待时间为0，则说明不用等待。<br>必须等到等待时间之后，才能进行接下来的工作。</p><p>或者，如果不想等待，可以调用Cancel()方法，该方法会将Token归还。</p><p>举一个简单的例子，我们可以这么使用Reserve方法。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">r := lim.Reserve()</span><br><span class="line">f !r.OK() &#123;</span><br><span class="line">    <span class="comment">// Not allowed to act! Did you remember to set lim.burst to be &gt; 0 ?</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(r.Delay())</span><br><span class="line">Act() <span class="comment">// 执行相关逻辑</span></span><br></pre></td></tr></table></figure><h1 id="动态调整速率"><a href="#动态调整速率" class="headerlink" title="动态调整速率"></a>动态调整速率</h1><p>Limiter支持可以调整速率和桶大小：</p><ol><li>SetLimit(Limit) 改变放入Token的速率</li><li>SetBurst(int) 改变Token桶大小</li></ol><p>有了这两个方法，可以根据现有环境和条件，根据我们的需求，动态的改变Token桶大小和速率。</p><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ul><li><a href="https://www.cyhone.com/articles/analisys-of-golang-rate/">Golang限流器time/rate实现剖析</a></li><li><a href="https://www.cyhone.com/articles/analysis-of-uber-go-ratelimit/">uber-go漏桶限流器使用与原理分析</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本主题为系列文章，分上下两篇。本文主要介绍&lt;code&gt;time/rate&lt;/code&gt;的具体使用方法，另外一篇文章&lt;a href=&quot;https://www.cyhone.com/articles/analisys-of-golang-rate/&quot;&gt;《Golang限流器time/rate实现剖析》&lt;/a&gt;则着重介绍其内部实现原理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。&lt;br&gt;限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket等。&lt;/p&gt;
&lt;p&gt;其实golang标准库中就自带了限流算法的实现，即&lt;code&gt;golang.org/x/time/rate&lt;/code&gt;。&lt;br&gt;该限流器是基于Token Bucket(令牌桶)实现的。&lt;/p&gt;
&lt;p&gt;简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放Token，桶满则暂时不放。&lt;br&gt;而用户则从桶中取Token，如果有剩余Token就可以一直取。如果没有剩余Token，则需要等到系统中被放置了Token才行。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="http://www.cyhone.com/categories/Golang/"/>
    
    
      <category term="限流" scheme="http://www.cyhone.com/tags/%E9%99%90%E6%B5%81/"/>
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="微服务" scheme="http://www.cyhone.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>微信libco协程库源码分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-libco/"/>
    <id>http://www.cyhone.com/articles/analysis-of-libco/</id>
    <published>2019-10-08T09:58:26.000Z</published>
    <updated>2019-12-05T03:22:07.155Z</updated>
    
    <content type="html"><![CDATA[<p>libco是微信后台开发和使用的协程库，同时应该也是极少数的将C/C++协程直接运用到如此大规模的生成环境中的案例了。</p><p>在<a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">《云风coroutine协程库源码分析》</a>中，介绍了有栈协程的实现原理。相比coroutine，libco在性能上号称可以调度千万级协程。 从使用上来说，不仅提供了一套类pthread的协程通信机制，同时可以零改造地将三方库的阻塞IO调用协程异步化。<br>本文将从源码角度着重分析libco的高效之道。</p><p>在正式阅读本文之前，如果对有栈协程的实现原理不是特别了解，建议提前阅读<a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">《云风coroutine协程库源码分析》</a>。</p><p>同时，我也提供了<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/libco" target="_blank" rel="noopener">libco注释版</a>，用以辅助理解libco的源码<br><a id="more"></a></p><h1 id="libco和coroutine的基本差异"><a href="#libco和coroutine的基本差异" class="headerlink" title="libco和coroutine的基本差异"></a>libco和coroutine的基本差异</h1><p>相比于coroutine协程库, libco整体更成熟，性能更高，使用上也更加方便。主要体现在以下几个方面：</p><ol><li>协程上下文切换性能更好</li><li>协程在IO阻塞时可自动切换，包括gethostname、mysqlclient等。</li><li>协程可以嵌套创建，即一个协程内部可以再创建一个协程。</li><li>提供了超时管理，以及一套类pthread的接口，用于协程间通信。</li></ol><p>关于libco的如何实现有栈协程的切换，co_resume、co_yield是如何实现的。此部分内容已在<a href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/">云风coroutine协程库源码分析</a>中进行了详细的剖析。各个协程库这里的实现大同小异，本文就不再重复讲述此部分内容了。</p><p>不过，libco在协程的栈空间上有不一样的地方：</p><ol><li>共享栈是可选的，如果想要使用共享栈模式，则需要用户自行创建栈空间，在co_create时传递给libco。(参数<code>stCoRoutineAttr_t* attr</code>)</li><li>支持协程使用独立的栈空间，不使用共享栈模式。(默认每个协程有128k的栈空间)</li><li>libco默认是独立的栈空间，不使用共享栈。</li></ol><p>除此之外，出于性能考虑，libco不使用ucontext进行用户态上下文的切换，而是自行写了一套汇编来进行上下文切换。</p><p>另外，libco利用<code>co_create</code>创建的协程, 需要自行调用<code>co_release</code>进行释放。这里和coroutine不太一样。</p><h1 id="协程上下文切换性能更好"><a href="#协程上下文切换性能更好" class="headerlink" title="协程上下文切换性能更好"></a>协程上下文切换性能更好</h1><p>我们之前提到，云风的coroutine库使用ucontext来实现用户态的上下文切换，这也是实现协程的关键。</p><p>而<strong>libco基于性能优化的考虑，没有使用ucontext</strong>，而是自行编写了一套汇编来处理上下文的切换, 具体代码在<a href="https://github.com/Tencent/libco/blob/master/coctx_swap.S" target="_blank" rel="noopener">coctx_swap.S</a>。</p><p>libco的上下文切换大体只保存和交换了两类东西：</p><ol><li>寄存器：函数参数类寄存器、函数返回值、数据存储类寄存器等。</li><li>栈：rsp栈顶指针</li></ol><p>相比于ucontext，缺少了浮点数上下文和sigmask(信号屏蔽掩码)。具体可对比<a href="https://github.com/lattera/glibc/blob/master/sysdeps/unix/sysv/linux/i386/getcontext.S" target="_blank" rel="noopener">glibc的相关源码</a>。</p><ul><li>取消sigmask是因为sigmask会引发一次syscall，在性能上会所损耗。</li><li>取消浮点数上下文，主要是在服务端编程几乎用不到浮点数计算。</li></ul><p>此外，libco的上下文切换只支持x86，不支持其他架构的cpu，这是因为在服务端也几乎都是x86架构的，不用太考虑CPU的通用性。</p><p>据<a href="https://www.zhihu.com/question/52193579/answer/156692295" target="_blank" rel="noopener">知乎网友的实验</a>证明：libco的上下文切换效率大致是ucontext的3.6倍。</p><p>总结来说，libco牺牲了通用性，把运营环境中用不到的寄存器拷贝去掉，对代码进行了极致优化，但是换取到了很高的性能。</p><h1 id="协程在IO阻塞时可自动切换"><a href="#协程在IO阻塞时可自动切换" class="headerlink" title="协程在IO阻塞时可自动切换"></a>协程在IO阻塞时可自动切换</h1><p>我们希望的是，当协程中遇到阻塞IO的调用时，协程可以自行yield出去，等到调用结束，可以再resume回来，这些流程不用用户关心。</p><p><strong>然而难点在于：</strong> 对于自己代码中的阻塞类调用尚且容易改造，可以把它改成非阻塞IO，然后框架内部进行yield和resume。但是大量三方库也存在着阻塞IO调用，如知名的mysqlclient就是阻塞IO，对于此类的IO调用，我们无法直接改造，不便于和我们现有的协程框架进行配合。</p><p>然而，libco的协程不仅可以做到IO阻塞协程的自动切换，甚至包括三方库的阻塞IO调用都可以零改造的自动切换。</p><p>libco巧妙运用了Linux的hook技术，同时配合了epoll事件循环，完美的完成了阻塞IO的协程化改造。</p><p>所谓系统函数hook，简单来说，就是替换原有的系统函数，例如read、write等，替换为自己的逻辑。所有关于hook系统函数的代码都在<code>co_hook_sys_call.cpp</code>中可以看到。</p><p>在分析具体代码之前，有个点需要先注意下：<strong>libco的hook逻辑用于client行为的阻塞类IO调用</strong>。</p><p>client行为指的是，本地主动connect一个远程的服务，使用的时候一般先往socket中write数据，然后再read回包这种形式。</p><h2 id="read函数的hook流程"><a href="#read函数的hook流程" class="headerlink" title="read函数的hook流程"></a>read函数的hook流程</h2><p>我们以read函数为例，看下都做了什么：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> read( <span class="keyword">int</span> fd, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte )</span><br><span class="line">&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span> <span class="title">pf</span> = &#123;</span> <span class="number">0</span> &#125;;</span><br><span class="line">pf.fd = fd;</span><br><span class="line">pf.events = ( POLLIN | POLLERR | POLLHUP );</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> pollret = poll( &amp;pf,<span class="number">1</span>,timeout );</span><br><span class="line"></span><br><span class="line"><span class="keyword">ssize_t</span> readret = g_sys_read_func( fd,(<span class="keyword">char</span>*)buf ,nbyte );</span><br><span class="line"><span class="keyword">return</span> readret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码对原有代码进行了简略，只保留了最核心的hook逻辑。</p><p>注意：这里poll函数实际上也是被hook过的函数，在这个函数中，最终会交由<code>co_poll_inner</code>函数处理。</p><p><code>co_poll_inner</code>函数主要有三个作用：</p><ol><li>将poll的相关事件转换为epoll相关事件，并注册到当前线程的epoll中。</li><li>注册超时事件，到当前的epoll中</li><li>调用co_yield_ct, 让出该协程。</li></ol><p>可以看到，调用poll函数之后，相关事件注册到了EventLoop中后，该协程就yield走了。</p><p>那么，什么时候，协程会再resume回来呢？<br>答案是：<strong>当epoll相关事件触发或者超时触发时</strong>，会再次resume该协程，处理接下来的流程。</p><p>协程resume之后，会接着处理poll之后的逻辑，也就是调用了<code>g_sys_read_func</code>。这个函数就是真实的linux的read函数。</p><p>libco使用dlsym函数获取了系统函数, 如下：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">ssize_t</span> <span class="params">(*<span class="keyword">read_pfn_t</span>)</span><span class="params">(<span class="keyword">int</span> fildes, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte)</span></span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">read_pfn_t</span> g_sys_read_func = (<span class="keyword">read_pfn_t</span>)dlsym(RTLD_NEXT,<span class="string">"read"</span>);</span><br></pre></td></tr></table></figure></p><p>这个逻辑就非常巧妙了：</p><ul><li>从内部来看，本质上是个异步流程，在EventLoop中注册相关事件，当事件触发时就执行接下来的处理函数。</li><li>从外部来看，调用方使用的时候函数行为和普通的阻塞函数基本一样，无需关系底层的注册事件、yield等过程。</li></ul><p>这个就是libco的巧妙之处了，通过hook系统函数的方式，几乎无感知的改造了阻塞IO调用。</p><p>此外，libco也hook了系统的socket函数。在libco实现的socket函数中，会将fd变成非阻塞的(O_NONBLOCK)。</p><p>那么，为什么libco连mysql_client都可以一并协程化改造呢？</p><p>这是因为mysql_client里面的具体网络IO实现，也是用的Linux的那些系统函数connect、read、write这些函数。<br>所以，libco只用hook十几个socket相关的api，就可以将用到的三方库中的IO调用也一起协程化改造了。</p><h2 id="read的超时处理"><a href="#read的超时处理" class="headerlink" title="read的超时处理"></a>read的超时处理</h2><p>libco的read函数和普通的阻塞IO中的read函数，行为上稍微有一点不一样。</p><p>普通的read函数，如果一直没有消息可读，则会一直阻塞。<br>但是libco中的read函数，如果1秒钟之内socket依然不可读，则就认为read失败，返回-1。这也是read中注册超时事件的原因。</p><p>在client侧网络的IO调用里面，一般行为都是，write请求，然后read回包。<br>所以一定是会引入一个超时判断，判断该次调用是否超时。<br>同时，还要保证要保证read的行为和语义，与原有的系统函数保持一致。毕竟hook的目标是mysql_client这种三方库。<br>所以这个超时只能做在read内部，把超时当成一次read失败处理。</p><p>这样即能保证read原有行为，也能保证read不会一直阻塞。</p><p>但这里有个问题：libco把read的超时时间硬编码为1s，那么所有被hook的阻塞IO的read，一旦超过1s，就会被认为失败。<br>但对于某些特殊场景，会存在一些耗时请求，server端的处理时间确实有可能会超过1s。<br>对于这种情况，libco似乎也没有提供一个自定义超时时间的办法。</p><h2 id="stCoEpoll-t结构体分析"><a href="#stCoEpoll-t结构体分析" class="headerlink" title="stCoEpoll_t结构体分析"></a>stCoEpoll_t结构体分析</h2><p>libco的事件循环同时支持epoll和kqueue，libco会在每个线程维护一个<code>stCoEpoll_t</code>对象。<br><code>stCoEpoll_t</code>结构体中维护了事件循环需要的数据。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stCoEpoll_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">int</span> iEpollFd;</span><br><span class="line">co_epoll_res *result; </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeout_t</span> *<span class="title">pTimeout</span>;</span>  </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeoutItemLink_t</span> *<span class="title">pstTimeoutList</span>;</span> </span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stTimeoutItemLink_t</span> *<span class="title">pstActiveList</span>;</span> </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>iEpollFd：epoll或者kqueue的fd</li><li>result: 当前已触发的事件，给epoll或kevent用。如果是epoll的话，则是epoll_wait的已触发事件</li><li>pTimeout：时间轮定时管理器。记录了所有的定时事件</li><li>pstTimeoutList：本轮超时的事件</li><li>pstActiveList: 本轮触发的事件。</li></ol><p>此外，libco使用了时间轮来做超时管理，关于时间轮的原理分析网上比较多，这块也不是libco最核心的东西，就不在本文讨论了。</p><h1 id="协程可以嵌套创建"><a href="#协程可以嵌套创建" class="headerlink" title="协程可以嵌套创建"></a>协程可以嵌套创建</h1><p>libco的协程可以嵌套创建，协程内部可以创建一个新的协程。这里其实没有什么黑科技，只不过云风coroutine中不能实现协程嵌套创建，所以在这里单独讲下。<br>libco使用了一个栈维护协程调用过程。<br>我们模拟下这个调用栈的运行过程, 如下图所示：<br><img src="/img/libco/co_process_stack.png" alt="协程调用栈"></p><p>图中绿色方块代表栈顶，同时也是当前正在运行的协程。</p><ol><li>当在主协程中co_resume到A协程时，当前运行的协程变更为A，同时协程A入栈。</li><li>A协程中co_resume到B协程，当前运行的协程变更为B，同时协程B入栈。</li><li>协程B中调用co_yield_ct。协程B出栈，同时当前协程切换到协程A。</li><li>协程A中调用co_yield_ct。协程B出栈，同时当前协程切换到主协程。</li></ol><p>libco的协程调用栈维护stCoRoutineEnv_t结构体中，如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stCoRoutineEnv_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">stCoRoutine_t *pCallStack[ <span class="number">128</span> ]; </span><br><span class="line"><span class="keyword">int</span> iCallStackSize; </span><br><span class="line">stCoEpoll_t *pEpoll; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>其中pCallStack即是协程的调用栈，从参数可以看出，libco只能支持128层协程的嵌套调用，这个深度已经足够使用了。<br>iCallStackSize代表当前的调用深度。</p><h1 id="libco的运营经验"><a href="#libco的运营经验" class="headerlink" title="libco的运营经验"></a>libco的运营经验</h1><p>libco的负责人leiffyli在purecpp大会上分享了<a href="http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf" target="_blank" rel="noopener">libco的一些运营经验</a>，个人觉得还是非常值得学习的，这里直接引用过来。</p><blockquote><p>协程栈大小有限，接入协程的服务谨慎使用栈空间；</p></blockquote><p>libco中默认每个协程的栈大小是128k，虽然可以自定义每个协程栈的大小，但是其大小依然是有限资源。避免在栈上分配大内存对象(如大数组等)。</p><blockquote><p>池化使用，对系统中资源使用心中有数。随手创建与释放协程不是一个好的方式，有可能系统被过多的协程拖垮；</p></blockquote><p>关于这点，libco的实例<code>example_echosvr.cpp</code>就是一个池化使用的例子。</p><blockquote><p>协程不适合运行cpu密集型任务。对于计算较重的服务，需要分离计算线程与网络线程，避免互相影响；</p></blockquote><p>这是因为计算比较耗时的任务，会严重拖慢EventLoop的运行过程，导致事件响应和协程调度受到了严重影响。</p><blockquote><p>过载保护。对于基于事件循环的协程调度框架，建议监控完成一次事件循环的时间，若此时间过长，会导致其它协程被延迟调度，需要与上层框架配合，减少新任务的调度；</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>libco巧妙的利用了hook技术，将协程的威力发挥的更加彻底，可以改良C++的RPC框架异步化后的回调痛苦。整个库除了基本的协程函数，又加入类pthread的一些辅助功能，让协程的通信更加好用。</p><p>然而遗憾的是，libco在开源方面做得并不是很好，后续bug维护和功能更新都不是很活跃。</p><p>但好消息是，据leiffyli的分享，目前有一些libco有一些实验中的特性，如事件回调、类golang的channel等，目前正在内部使用。相信后期也会同步到开源社区中。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="http://purecpp.org/purecpp/static/64a819e99584452aab70a7f9c307717f.pdf" target="_blank" rel="noopener">leiffyli：Libco分享</a></li><li><a href="https://www.infoq.cn/article/CplusStyleCorourtine-At-Wechat" target="_blank" rel="noopener">C/C++ 协程库 libco：微信怎样漂亮地完成异步化改造</a></li><li><a href="https://www.zhihu.com/question/52193579/answer/156692295" target="_blank" rel="noopener">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么? - 江哈莫夫斯基的回答</a></li><li><a href="https://zhuanlan.zhihu.com/p/27409164" target="_blank" rel="noopener">libco协程库上下文切换原理详解</a></li><li><a href="https://github.com/Tencent/libco/issues/41" target="_blank" rel="noopener">libco Github issue#41</a></li><li><a href="https://linux.die.net/man/3/dlsym" target="_blank" rel="noopener">man: dlsym</a></li><li><a href="http://walkerdu.com/2017/01/09/ucontext-theory/" target="_blank" rel="noopener">协程：posix::ucontext用户级线程实现原理分析</a></li><li><a href="http://man7.org/linux/man-pages/man2/read.2.html" target="_blank" rel="noopener">man: read</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;libco是微信后台开发和使用的协程库，同时应该也是极少数的将C/C++协程直接运用到如此大规模的生成环境中的案例了。&lt;/p&gt;
&lt;p&gt;在&lt;a href=&quot;http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/&quot;&gt;《云风coroutine协程库源码分析》&lt;/a&gt;中，介绍了有栈协程的实现原理。相比coroutine，libco在性能上号称可以调度千万级协程。 从使用上来说，不仅提供了一套类pthread的协程通信机制，同时可以零改造地将三方库的阻塞IO调用协程异步化。&lt;br&gt;本文将从源码角度着重分析libco的高效之道。&lt;/p&gt;
&lt;p&gt;在正式阅读本文之前，如果对有栈协程的实现原理不是特别了解，建议提前阅读&lt;a href=&quot;http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/&quot;&gt;《云风coroutine协程库源码分析》&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;同时，我也提供了&lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/libco&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;libco注释版&lt;/a&gt;，用以辅助理解libco的源码&lt;br&gt;
    
    </summary>
    
      <category term="协程" scheme="http://www.cyhone.com/categories/%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="协程" scheme="http://www.cyhone.com/tags/%E5%8D%8F%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>C++智能指针的正确使用方式</title>
    <link href="http://www.cyhone.com/articles/right-way-to-use-cpp-smart-pointer/"/>
    <id>http://www.cyhone.com/articles/right-way-to-use-cpp-smart-pointer/</id>
    <published>2019-10-05T03:00:54.000Z</published>
    <updated>2019-11-03T09:22:16.606Z</updated>
    
    <content type="html"><![CDATA[<p>C++11中推出了三种智能指针，unique_ptr、shared_ptr和weak_ptr，同时也将auto_ptr置为废弃(deprecated)。</p><p>但是在实际的使用过程中，很多人都会有这样的问题：</p><ol><li>不知道三种智能指针的具体使用场景</li><li>无脑只使用shared_ptr</li><li>认为应该禁用raw pointer(裸指针，即Widget*这种形式)，全部使用智能指针</li></ol><p>本文将从这几方面讲解智能指针：</p><ol><li>智能指针的应用场景分析</li><li>智能指针的性能分析: 为什么shared_ptr性能比unique_ptr差</li><li>指针作为函数参数时应该传，传值、传引用，还是裸指针？</li></ol><a id="more"></a><h1 id="对象所有权"><a href="#对象所有权" class="headerlink" title="对象所有权"></a>对象所有权</h1><p>首先需要理清楚的概念就是对象所有权的概念。所有权在rust语言中非常严格，写rust的时候必须要清楚自己创建的每个对象的所有权。</p><p>但是C++比较自由，似乎我们不需要明白对象的所有权，写的代码也能正常运行。但是明白了对象所有权，我们才可以正确管理好对象生命周期和内存问题。</p><p>C++引入了智能指针，也是为了更好的描述对象所有权，简化内存管理，从而大大减少我们C++内存管理方面的犯错机会。</p><h1 id="unique-ptr：专属所有权"><a href="#unique-ptr：专属所有权" class="headerlink" title="unique_ptr：专属所有权"></a>unique_ptr：专属所有权</h1><p><strong>我们大多数场景下用到的应该都是unique_ptr</strong>。<br>unique_ptr代表的是专属所有权，即由unique_ptr管理的内存，只能被一个对象持有。<br>所以，<strong>unique_ptr不支持复制和赋值</strong>，如下：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_unique&lt;Widget&gt;();</span><br><span class="line"><span class="keyword">auto</span> w2 = w; <span class="comment">// 编译错误</span></span><br></pre></td></tr></table></figure><p>如果想要把w复制给w2, 是不可以的。因为复制从语义上来说，两个对象将共享同一块内存。</p><p>因此，<strong>unique_ptr只支持移动</strong>, 即如下：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_unique&lt;Widget&gt;();</span><br><span class="line"><span class="keyword">auto</span> w2 = <span class="built_in">std</span>::move(w); <span class="comment">// w2获得内存所有权，w此时等于nullptr</span></span><br></pre></td></tr></table></figure></p><p>unique_ptr代表的是专属所有权，如果想要把一个unique_ptr的内存交给另外一个unique_ptr对象管理。<strong>只能使用std::move转移当前对象的所有权</strong>。转移之后，当前对象不再持有此内存，新的对象将获得专属所有权。</p><p>如上代码中，将w对象的所有权转移给w2后，w此时等于nullptr，而w2获得了专属所有权。</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>因为C++的zero cost abstraction的特点，unique_ptr在默认情况下和裸指针的大小是一样的。<br>所以<strong>内存上没有任何的额外消耗，性能是最优的。</strong></p><h2 id="使用场景1：忘记delete"><a href="#使用场景1：忘记delete" class="headerlink" title="使用场景1：忘记delete"></a>使用场景1：忘记delete</h2><p>unique_ptr一个最简单的使用场景是用于类属性。代码如下：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Box</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Box() : w(<span class="keyword">new</span> Widget())</span><br><span class="line">    &#123;&#125;</span><br><span class="line">    ~Box()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 忘记delete w</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Widget* w;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>如果因为一些原因，w必须建立在堆上。如果用裸指针管理w，那么需要在析构函数中<code>delete w</code>;<br>这种写法虽然没什么问题，但是容易漏写delete语句，造成内存泄漏。</p><p>如果按照unique_ptr的写法，不用在析构函数手动delete属性，当对象析构时，属性<code>w</code>将会自动释放内存。</p><h2 id="使用场景2：异常安全"><a href="#使用场景2：异常安全" class="headerlink" title="使用场景2：异常安全"></a>使用场景2：异常安全</h2><p>假如我们在一段代码中，需要创建一个对象，处理一些事情后返回，返回之前将对象销毁，如下所示：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Widget* w = <span class="keyword">new</span> Widget();</span><br><span class="line">    w-&gt;do_something(); <span class="comment">// 可能会发生异常</span></span><br><span class="line">    <span class="keyword">delete</span> w;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在正常流程下，我们会在函数末尾delete创建的对象w，正常调用析构函数，释放内存。</p><p>但是如果w-&gt;do_something()发生了异常，那么<code>delete w</code>将不会被执行。此时就会发生<strong>内存泄漏</strong>。<br>我们当然可以使用try…catch捕捉异常，在catch里面执行delete，但是这样代码上并不美观，也容易漏写。</p><p>如果我们用std::unique_ptr，那么这个问题就迎刃而解了。无论代码怎么抛异常，在unique_ptr离开函数作用域的时候，内存就将会自动释放。</p><h1 id="shared-ptr：共享所有权"><a href="#shared-ptr：共享所有权" class="headerlink" title="shared_ptr：共享所有权"></a>shared_ptr：共享所有权</h1><p>在使用shared_ptr之前应该考虑，是否真的需要使用shared_ptr, 而非unique_ptr。</p><p>shared_ptr代表的是共享所有权，即多个shared_ptr可以共享同一块内存。<br>因此，从语义上来看，<strong>shared_ptr是支持复制的</strong>。如下：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> w = <span class="built_in">std</span>::make_shared&lt;Widget&gt;();</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">auto</span> w2 = w;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; w.use_count() &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 2</span></span><br><span class="line">&#125;  </span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; w.use_count() &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// 1</span></span><br></pre></td></tr></table></figure></p><p>shared_ptr内部是利用引用计数来实现内存的自动管理，每当复制一个shared_ptr，引用计数会+1。当一个shared_ptr离开作用域时，引用计数会-1。当引用计数为0的时候，则delete内存。</p><p>同时，<strong>shared_ptr也支持移动</strong>。从语义上来看，移动指的是所有权的传递。如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto w = std::make_shared&lt;Widget&gt;();</span><br><span class="line">auto w2 = std::move(w); // 此时w等于nullptr，w2.use_count()等于1</span><br></pre></td></tr></table></figure><p>我们将w对象move给w2，意味着w放弃了对内存的所有权和管理，此时w对象等于nullptr。<br>而w2获得了对象所有权，但因为此时w已不再持有对象，因此w2的引用计数为1。</p><h2 id="性能-1"><a href="#性能-1" class="headerlink" title="性能"></a>性能</h2><ol><li><p><strong>内存占用高</strong><br>shared_ptr的内存占用是裸指针的两倍。因为除了要管理一个裸指针外，还要维护一个引用计数。<br>因此相比于unique_ptr, shared_ptr的内存占用更高</p></li><li><p><strong>原子操作性能低</strong><br>考虑到线程安全问题，引用计数的增减必须是原子操作。而原子操作一般情况下都比非原子操作慢。</p></li><li><p><strong>使用移动优化性能</strong><br>shared_ptr在性能上固然是低于unique_ptr。而通常情况，我们也可以尽量避免shared_ptr复制。<br>如果，一个shared_ptr需要将所有权共享给另外一个新的shared_ptr，而我们确定在之后的代码中都不再使用这个shared_ptr，那么这是一个非常鲜明的移动语义。<br>对于此种场景，我们尽量使用std::move，将shared_ptr转移给新的对象。因为移动不用增加引用计数，因此性能比复制更好。</p></li></ol><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ol><li>shared_ptr通常使用在共享权不明的场景。有可能多个对象同时管理同一个内存时。</li><li>对象的延迟销毁。陈硕在《Linux多线程服务器端编程》中提到，当一个对象的析构非常耗时，甚至影响到了关键线程的速度。可以使用<code>BlockingQueue&lt;std::shared_ptr&lt;void&gt;&gt;</code>将对象转移到另外一个线程中释放，从而解放关键线程。</li></ol><h2 id="为什么要用shared-from-this"><a href="#为什么要用shared-from-this" class="headerlink" title="为什么要用shared_from_this?"></a>为什么要用shared_from_this?</h2><p>我们往往会需要在类内部使用自身的shared_ptr，例如：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">do_something</span><span class="params">(A&amp; a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        a.widget = 该对象的<span class="built_in">shared_ptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们需要把当前shared_ptr对象同时交由对象a进行管理。意味着，当前对象的生命周期的结束不能早于对象a。因为对象a在析构之前还是有可能会使用到<code>a.widget</code>。</p><p>如果我们直接<code>a.widget = this;</code>， 那肯定不行， 因为这样并没有增加当前shared_ptr的引用计数。shared_ptr还是有可能早于对象a释放。</p><p>如果我们使用<code>a.widget = std::make_shared&lt;Widget&gt;(this);</code>，肯定也不行，因为这个新创建的shared_ptr，跟当前对象的shared_ptr毫无关系。当前对象的shared_ptr生命周期结束后，依然会释放掉当前内存，那么之后<code>a.widget</code>依然是不合法的。</p><p>对于这种，需要在对象内部获取该对象自身的shared_ptr, 那么该类必须继承<code>std::enable_shared_from_this&lt;T&gt;</code>。代码如下:<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Widget</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;Widget&gt;</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">do_something</span><span class="params">(A&amp; a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        a.widget = shared_from_this();</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这样才是合法的做法。</p><h1 id="weak-ptr"><a href="#weak-ptr" class="headerlink" title="weak_ptr"></a>weak_ptr</h1><p>weak_ptr是为了解决shared_ptr双向引用的问题。即：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;B&gt; b;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;A&gt; a;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">auto</span> pa = make_shared&lt;A&gt;();</span><br><span class="line"><span class="keyword">auto</span> pb = make_shared&lt;B&gt;();</span><br><span class="line">pa-&gt;b = pb;</span><br><span class="line">pb-&gt;a = pa;</span><br></pre></td></tr></table></figure></p><p>pa和pb存在着循环引用，根据shared_ptr引用计数的原理，pa和pb都无法被正常的释放。<br>对于这种情况, 我们可以使用weak_ptr：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">A</span>&#123;</span></span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;B&gt; b;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">B</span>&#123;</span></span><br><span class="line">    weak_ptr&lt;A&gt; a;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">auto</span> pa = make_shared&lt;A&gt;();</span><br><span class="line"><span class="keyword">auto</span> pb = make_shared&lt;B&gt;();</span><br><span class="line">pa-&gt;b = pb;</span><br><span class="line">pb-&gt;a = pa;</span><br></pre></td></tr></table></figure></p><p>weak_ptr不会增加引用计数，因此可以打破shared_ptr的循环引用。<br>通常做法是parent类持有child的shared_ptr, child持有指向parent的weak_ptr。这样也更符合语义。</p><h1 id="如何指针作为函数传参"><a href="#如何指针作为函数传参" class="headerlink" title="如何指针作为函数传参"></a>如何指针作为函数传参</h1><p>很多时候，函数的参数是个指针。这个时候就会面临选择困难症，这个参数应该怎么传，应该是shared_ptr<t>，还是const shared_ptr<t>&amp;，还是直接raw pointer更合适。</t></t></p><p>1. <strong>只在函数使用指针，但并不保存</strong><br>假如我们只需要在函数中，用这个对象处理一些事情，但不打算涉及其生命周期的管理，不打算通过函数传参延长shared_ptr的生命周期。<br>对于这种情况，可以使用raw pointer或者const shared_ptr<t>&amp;。<br>即：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(Widget*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> <span class="built_in">shared_ptr</span>&lt;Widget&gt;&amp;)</span></span></span><br></pre></td></tr></table></figure></t></p><p>实际上第一种裸指针的方式可能更好，从语义上更加清楚，函数也不用关心智能指针的类型。</p><ol start="2"><li><strong>在函数中保存智能指针</strong><br>假如我们需要在函数中把这个智能指针保存起来，这个时候建议直接传值。<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Widget&gt; ptr)</span></span>;</span><br></pre></td></tr></table></figure></li></ol><p>这样的话，外部传过来值的时候，可以选择move或者赋值。函数内部直接把这个对象通过move的方式保存起来。<br>这样性能更好，而且外部调用也有多种选择。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对于智能指针的使用，实际上是对所有权和生命周期的思考，一旦想明白了这两点，那对智能指针的使用也就得心应手了。<br>同时理解了每种智能指针背后的性能消耗、使用场景，那智能指针也不再是黑盒子和洪水猛兽。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《Effective Modern cpp》</li><li>《Linux多线程服务器端编程》</li><li><a href="https://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/" target="_blank" rel="noopener">GotW #91 Solution: Smart Pointer Parameters</a></li><li><a href="https://www.zhihu.com/question/30957800" target="_blank" rel="noopener">std::enable_shared_from_this 有什么意义？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++11中推出了三种智能指针，unique_ptr、shared_ptr和weak_ptr，同时也将auto_ptr置为废弃(deprecated)。&lt;/p&gt;
&lt;p&gt;但是在实际的使用过程中，很多人都会有这样的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不知道三种智能指针的具体使用场景&lt;/li&gt;
&lt;li&gt;无脑只使用shared_ptr&lt;/li&gt;
&lt;li&gt;认为应该禁用raw pointer(裸指针，即Widget*这种形式)，全部使用智能指针&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将从这几方面讲解智能指针：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;智能指针的应用场景分析&lt;/li&gt;
&lt;li&gt;智能指针的性能分析: 为什么shared_ptr性能比unique_ptr差&lt;/li&gt;
&lt;li&gt;指针作为函数参数时应该传，传值、传引用，还是裸指针？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="cpp" scheme="http://www.cyhone.com/categories/cpp/"/>
    
    
      <category term="智能指针" scheme="http://www.cyhone.com/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/"/>
    
      <category term="C++" scheme="http://www.cyhone.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>c++ lambda内std::move失效问题的思考</title>
    <link href="http://www.cyhone.com/articles/why-move-no-work-in-lambda/"/>
    <id>http://www.cyhone.com/articles/why-move-no-work-in-lambda/</id>
    <published>2019-09-29T10:07:00.000Z</published>
    <updated>2019-11-09T13:40:52.594Z</updated>
    
    <content type="html"><![CDATA[<p>最近在写C++时，有这样一个代码需求：在lambda中，将一个捕获参数move给另外一个变量。<br>看似一个很简单常规的操作，然而这个move动作却没有生效。</p><p>具体代码如下：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">auto</span> func = [=]()&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; vec.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; vec2.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码可在<a href="https://wandbox.org/permlink/et6ZTBhwpz5SH6w0" target="_blank" rel="noopener">wandbox</a>运行。</p><p>我们期望的是，将对变量<code>vec</code>调用std::move后，数据将会移动至变量<code>vec2</code>, 此时<code>vec</code>里面应该没有数据了。但是通过打印<code>vec.size()</code>发现vec中的数据并没有按预期移走。</p><p>这也就意味着，构造vec2时并没有按预期调用移动构造函数，而是调用了拷贝构造函数。</p><p>为什么会造成这个问题呢, 我们需要结合<code>std::move</code>和<code>lambda</code>的原理看下。（最终的解决方案可以直接看<a href="#解决方案">这里</a>）</p><a id="more"></a><h1 id="std-move的本质"><a href="#std-move的本质" class="headerlink" title="std::move的本质"></a>std::move的本质</h1><p>对于std::move，有两点需要注意：</p><ol><li>std::move中到底做了什么事情</li><li>std::move是否可以保证数据一定能移动成功</li></ol><p>对于第二点来说，答案显然是不能。这也是本文的问题所在。那么std::move实际上是做了什么事情呢？</p><p>对于std::move，其实现大致如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; </span><br><span class="line"><span class="keyword">decltype</span>(<span class="keyword">auto</span>) move(T&amp;&amp; param)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">using</span> ReturnType = <span class="keyword">remove_reference_t</span>&lt;T&gt;&amp;&amp;;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;ReturnType&gt;(param);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>从代码可以看出，std::move本质上是调用了static_cast做了一层强制转换，强制转换的目标类型是<code>remove_reference_t&lt;T&gt;&amp;&amp;</code>，remove_reference_t是为了去除类型本身的引用，例如左值引用。总结来说，std::move本质上是将对象强制转换为了右值引用。</p><p>那么，为什么我们通常使用std::move实现移动语义，可以将一个对象的数据移给另外一个对象？</p><p>这是因为std::move配合了移动构造函数使用，本质上是移动构造函数起了作用。移动构造函数的一般定义如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class A&#123;</span><br><span class="line">public:</span><br><span class="line">    A(A &amp;&amp;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>可以看到移动构造函数的参数就是个右值引用<code>A&amp;&amp;</code>，因此 <code>A a = std::move(b);</code>, 本质上是先将b强制转化了右值引用<code>A&amp;&amp;</code>,<br>然后触发了移动构造函数，在移动构造函数中，完成了对象b的数据到对象a的移动。</p><p>那么，在哪些情况下，<code>A a = std::move(b);</code>会失效呢？<br>显然是，当std::move强转后的类型不是<code>A&amp;&amp;</code>，这样就不会命中移动构造函数。</p><p>例如：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> str = <span class="string">"123"</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">string</span> str2(<span class="built_in">std</span>::move(str));</span><br></pre></td></tr></table></figure></p><p>这个时候，对str对象调用<code>std::move</code>，强转出来的类型将会是<code>const string&amp;&amp;</code>, 这样移动构造函数就不会起作用了，但是这个类型却可以令复制构造函数生效。</p><p>结合本文最初的问题，在lambda中move没有生效，显然也是std::move强转的类型不是<code>std::vector&lt;int&gt;&amp;&amp;</code>, 才导致了没有move成功。</p><p>那么，为什么会出现这个问题呢，我们需要理解下lambda的工作原理。</p><h1 id="lambda闭包原理"><a href="#lambda闭包原理" class="headerlink" title="lambda闭包原理"></a>lambda闭包原理</h1><p>对于c++的lambda，编译器会将lambda转化为一个独一无二的闭包类。而lambda对象最终会转化成这个闭包类的对象。<br>对于本文最初的这个lambda来说，最终实际上转化成了这么一个类型<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 转换前</span></span><br><span class="line"><span class="keyword">auto</span> func = [=]()&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 转换后</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClosureFunc</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">ClosureFunc func;</span><br></pre></td></tr></table></figure></p><p>这里需要注意, lambda的默认行为是，<strong>生成的闭包类的<code>operator()</code>默认被const修饰</strong>。</p><p>那么这里问题就来了，当调用<code>operator()</code>时, 该闭包类所有的成员变量也是被const修饰的，此时对成员变量调用<code>std::move</code>将会引发上文中提到的，<strong>强转出来的类型将会是<code>const string&amp;&amp;</code>问题</strong>。因此，移动构造函数将不会被匹配到。</p><p>我们最初的问题lambda中std::move失效的问题，也是因为这个原因。这也很符合const函数的语义: const函数是不能修改成员变量的值。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>那么，这个应该怎么解决呢？答案是<code>mutable</code>。即在lambda尾部声明一个mutable，如下：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> func = [=]() <span class="keyword">mutable</span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>这样编译器生成的闭包类的<code>operator()</code>将会不带const了。我们的std::move也可以正常转换，实现移动语义了。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">auto</span> func = [=]() <span class="keyword">mutable</span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> vec2 = <span class="built_in">std</span>::move(vec);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; vec.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：0</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; vec2.size() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; <span class="comment">// 输出：3</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>代码可以在<a href="https://wandbox.org/permlink/ox4SBxNrAi8M8ZLp" target="_blank" rel="noopener">wandbox</a>运行。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://zh.cppreference.com/w/cpp/language/lambda" target="_blank" rel="noopener">Lambda 表达式-cppreference</a></li><li>Effective Modern c++</li><li><a href="https://www.zhihu.com/question/50652989" target="_blank" rel="noopener">关于C++右值及std::move()的疑问？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在写C++时，有这样一个代码需求：在lambda中，将一个捕获参数move给另外一个变量。&lt;br&gt;看似一个很简单常规的操作，然而这个move动作却没有生效。&lt;/p&gt;
&lt;p&gt;具体代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;&amp;gt; vec = &amp;#123;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; func = [=]()&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; vec2 = &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::move(vec);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; vec.size() &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;// 输出：3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; vec2.size() &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;// 输出：3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;代码可在&lt;a href=&quot;https://wandbox.org/permlink/et6ZTBhwpz5SH6w0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;wandbox&lt;/a&gt;运行。&lt;/p&gt;
&lt;p&gt;我们期望的是，将对变量&lt;code&gt;vec&lt;/code&gt;调用std::move后，数据将会移动至变量&lt;code&gt;vec2&lt;/code&gt;, 此时&lt;code&gt;vec&lt;/code&gt;里面应该没有数据了。但是通过打印&lt;code&gt;vec.size()&lt;/code&gt;发现vec中的数据并没有按预期移走。&lt;/p&gt;
&lt;p&gt;这也就意味着，构造vec2时并没有按预期调用移动构造函数，而是调用了拷贝构造函数。&lt;/p&gt;
&lt;p&gt;为什么会造成这个问题呢, 我们需要结合&lt;code&gt;std::move&lt;/code&gt;和&lt;code&gt;lambda&lt;/code&gt;的原理看下。（最终的解决方案可以直接看&lt;a href=&quot;#解决方案&quot;&gt;这里&lt;/a&gt;）&lt;/p&gt;
    
    </summary>
    
      <category term="cpp" scheme="http://www.cyhone.com/categories/cpp/"/>
    
    
      <category term="cpp" scheme="http://www.cyhone.com/tags/cpp/"/>
    
  </entry>
  
  <entry>
    <title>云风coroutine协程库源码分析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/"/>
    <id>http://www.cyhone.com/articles/analysis-of-cloudwu-coroutine/</id>
    <published>2019-09-19T06:26:19.000Z</published>
    <updated>2019-11-03T09:22:16.602Z</updated>
    
    <content type="html"><![CDATA[<p>随着Golang的兴起，协程尤其是有栈协程(stackful coroutine)越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。</p><p>云风实现了一套<a href="https://github.com/cloudwu/coroutine/" target="_blank" rel="noopener">C语言的协程库</a>，整体背景可以参考其<a href="https://blog.codingnow.com/2012/07/c_coroutine.html" target="_blank" rel="noopener">博客</a>。</p><p>这个协程库非常轻量级，一共也才200多行代码，使用上更贴近于lua的写法（众所周知，云风是知名的lua粉)。整体基于ucontext和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。</p><p>同时，我也提供了<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine" target="_blank" rel="noopener">coroutine注释版</a>，辅助大家理解coroutine的代码。</p><a id="more"></a><h1 id="协程的背景"><a href="#协程的背景" class="headerlink" title="协程的背景"></a>协程的背景</h1><p>协程主要有两大优点：</p><ol><li>相比线程更加轻量级<ul><li>线程的创建和调度都是在内核态，而协程是在用户态完成的</li><li>线程的个数往往受限于CPU核数，线程过多，会造成大量的核间切换。而协程无需考虑这些</li></ul></li><li>将异步流程同步化处理：此问题在知乎上有非常多的<a href="https://www.zhihu.com/question/32218874/answer/216801915" target="_blank" rel="noopener">经典回答</a>。尤其在RPC中进行多服务并发协作的时候，相比于回调式的做法，协程的好处更加明显。这个对于后端程序员的意义更大，非常解放生产力。这里就不再赘述了。</li></ol><p>微信基于c++实现的协程库<a href="https://github.com/Tencent/libco/" target="_blank" rel="noopener">libco</a>，hook了网络IO所需要大部分的系统函数，实现了当IO阻塞时协程的自动切换。<br>而Golang做的则更加极致，直接将协程和自动切换的概念集成进了语言。这里不细讲libco和GoRoutine的实现了，有机会会对这些做更详细的剖析。</p><p>协程再细分可以分为有栈协程和无栈协程：我们今天讲的云风的coroutine，包括微信的libco、GoRoutine，都是属于有栈协程。无栈协程包括ES6中的await/async、Python中的协程等。两种协程实现原理有很大的不同，本文主要基于coroutine对有栈协程的原理进行详细的分析。</p><h1 id="有栈协程的原理"><a href="#有栈协程的原理" class="headerlink" title="有栈协程的原理"></a>有栈协程的原理</h1><p>一个程序要真正运行起来，需要两个因素：可执行代码段、数据。体现在CPU中，主要包含以下几个方面：</p><ol><li>EIP寄存器，用来存储CPU要读取指令的地址</li><li>ESP寄存器：指向当前线程栈的栈顶位置</li><li>其他通用寄存器的内容：包括代表函数参数的rdi、rsi等等。</li><li>线程栈中的内存内容。</li></ol><p>这些数据内容，我们一般将其称为”上下文”或者”现场”。</p><p>有栈协程的原理，就是从线程的上下文下手，如果把线程的上下文完全改变。即：改变EIP寄存的内容，指向其他指令地址；改变线程栈的内存内容等等。<br>这样的话，当前线程运行的程序也就完全改变了，是一个全新的程序。</p><p>Linux下提供了一套函数，叫做ucontext簇函数，可以用来获取和设置当前线程的上下文内容。这也是coroutine的核心方法。</p><h1 id="coroutine的使用"><a href="#coroutine的使用" class="headerlink" title="coroutine的使用"></a>coroutine的使用</h1><p>我们首先基于coroutine的例子来讲下coroutine的基本使用，以方便后面原理的讲解</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> &#123;</span></span><br><span class="line"><span class="keyword">int</span> n;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">(struct schedule * S, <span class="keyword">void</span> *ud)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> * <span class="title">arg</span> = <span class="title">ud</span>;</span></span><br><span class="line"><span class="keyword">int</span> start = arg-&gt;n;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"coroutine %d : %d\n"</span>,coroutine_running(S) , start + i);</span><br><span class="line"><span class="comment">// 切出当前协程</span></span><br><span class="line">coroutine_yield(S);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">(struct schedule *S)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> <span class="title">arg1</span> = &#123;</span> <span class="number">0</span> &#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">args</span> <span class="title">arg2</span> = &#123;</span> <span class="number">100</span> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建两个协程</span></span><br><span class="line"><span class="keyword">int</span> co1 = coroutine_new(S, foo, &amp;arg1);</span><br><span class="line"><span class="keyword">int</span> co2 = coroutine_new(S, foo, &amp;arg2);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"main start\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (coroutine_status(S,co1) &amp;&amp; coroutine_status(S,co2)) &#123;</span><br><span class="line"><span class="comment">// 使用协程co1</span></span><br><span class="line">coroutine_resume(S,co1);</span><br><span class="line"><span class="comment">// 使用协程co2</span></span><br><span class="line">coroutine_resume(S,co2);</span><br><span class="line">&#125; </span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"main end\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 创建一个协程调度器</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">schedule</span> * <span class="title">S</span> = <span class="title">coroutine_open</span>();</span></span><br><span class="line"></span><br><span class="line">test(S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭协程调度器</span></span><br><span class="line">coroutine_close(S);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码看来，首先利用<code>coroutine_open</code>创建了协程调度器S，用来统一管理全部的协程。<br>同时在test函数中，创建了两个协程co1和co2，不断的反复yield和resume协程，直至两个协程执行完毕。</p><p>可以看出，最核心的几个对象和函数是:</p><ol><li><code>struct schedule* S</code> 协程调度器</li><li><code>coroutine_resume(S,co1);</code> 切入该协程</li><li><code>coroutine_yield(S);</code> 切出该协程</li></ol><p>接下来，会从这几点出发，分析coroutine的原理。建议大家在阅读下文时，同时对照我做的<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine" target="_blank" rel="noopener">coroutine注释版</a>。</p><h1 id="struct-schedule协程调度器"><a href="#struct-schedule协程调度器" class="headerlink" title="struct schedule协程调度器"></a>struct schedule协程调度器</h1><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">schedule</span> &#123;</span></span><br><span class="line"><span class="keyword">char</span> <span class="built_in">stack</span>[STACK_SIZE];<span class="comment">// 运行时栈，此栈即是共享栈</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ucontext_t</span> main; <span class="comment">// 主协程的上下文</span></span><br><span class="line"><span class="keyword">int</span> nco;        <span class="comment">// 当前存活的协程个数</span></span><br><span class="line"><span class="keyword">int</span> cap;        <span class="comment">// 协程管理器的当前最大容量，即可以同时支持多少个协程。如果不够了，则进行2倍扩容</span></span><br><span class="line"><span class="keyword">int</span> running;    <span class="comment">// 正在运行的协程ID</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">coroutine</span> **<span class="title">co</span>;</span> <span class="comment">// 一个一维数组，用于存放所有协程。其长度等于cap</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>协程调度器schedule负责管理所有协程，有几个属性非常重要：</p><ol><li><code>struct coroutine **co;</code>是一个一维数组，存放了目前所有的协程。</li><li><code>ucontext_t main;</code> 主协程的上下文，方便后面协程执行完后切回到主协程。</li><li><code>char stack[STACK_SIZE];</code> 这个非常重要，是所有协程的运行时栈。具体共享栈的原理会在下文讲到。</li></ol><p>此外，<code>coroutine_open</code>负责创建并初始化一个协程调度器，<code>coroutine_close</code>负责销毁协程调度器以及清理其管理的所有协程。</p><h1 id="协程的创建-coroutine-new"><a href="#协程的创建-coroutine-new" class="headerlink" title="协程的创建: coroutine_new"></a>协程的创建: coroutine_new</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">struct coroutine &#123;</span><br><span class="line">coroutine_func func; <span class="comment">// 协程所用的函数</span></span><br><span class="line"><span class="keyword">void</span> *ud;  <span class="comment">// 协程参数</span></span><br><span class="line">ucontext_t ctx; <span class="comment">// 协程上下文</span></span><br><span class="line">struct schedule * sch; <span class="comment">// 该协程所属的调度器</span></span><br><span class="line">ptrdiff_t cap;  <span class="comment">// 已经分配的内存大小</span></span><br><span class="line">ptrdiff_t size; <span class="comment">// 当前协程运行时栈，保存起来后的大小</span></span><br><span class="line"><span class="keyword">int</span> status;<span class="comment">// 协程当前的状态</span></span><br><span class="line"><span class="keyword">char</span> *stack; <span class="comment">// 当前协程的保存起来的运行时栈</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>coroutine_new</code>负责创建并初始化一个新协程对象，同时将该协程对象放到协程调度器里面。</p><p>这里的实现有两个非常有意思的点：</p><ol><li><strong>扩容</strong>：当目前尚存活的线程个数<code>nco</code>已经等于协程调度器的容量<code>cap</code>了，这个时候需要对协程调度器进行扩容，这里直接就是非常经典简单的2倍扩容。</li><li><strong>如果无需扩容，则需要找到一个空的位置，放置初始化好的协程</strong>。这里一般直接从数组第一位开始找，直到找到空的位置即可。但是云风把这里处理成从第<code>nco</code>位开始寻找（<code>nco</code>代表当前存活的个数。因为一般来说，前面几位最开始都是存活的，从第<code>nco</code>位开始找，效率会更高。</li></ol><p>这样，一个协程对象就被创建好，此时该协程的状态是<code>READY</code>，但尚未正式执行。</p><p><code>coroutine_resume</code>函数会切入到指定协程中执行。当前正在执行的协程的上下文会被保存起来，同时上下文替换成新的协程，该协程的状态将被置为<code>RUNNING</code>。</p><p>进入<code>coroutine_resume</code>函数的前置状态有两个<code>READY</code>和<code>SUSPEND</code>，这两个状态下<code>coroutine_resume</code>的处理方法也是有很大不同。我们先看下协程在READY状态下进行<code>coroutine_resume</code>的流程。</p><h1 id="coroutine-resume-READY-gt-RUNNING）"><a href="#coroutine-resume-READY-gt-RUNNING）" class="headerlink" title="coroutine_resume(READY -&gt; RUNNING）"></a>coroutine_resume(READY -&gt; RUNNING）</h1><p>这块代码比较短，但是非常重要，所以我就直接贴代码了：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//初始化ucontext_t结构体，将当前的上下文放到C-&gt;ctx里面</span></span><br><span class="line">getcontext(&amp;C-&gt;ctx);</span><br><span class="line"><span class="comment">// 将当前协程的运行时栈的栈顶设置为S-&gt;stack，每个协程都这么设置，这就是所谓的共享栈。（注意，这里是栈顶）</span></span><br><span class="line">C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack; </span><br><span class="line">C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;</span><br><span class="line">C-&gt;ctx.uc_link = &amp;S-&gt;main;</span><br><span class="line">S-&gt;running = id;</span><br><span class="line">C-&gt;status = COROUTINE_RUNNING;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置执行C-&gt;ctx函数, 并将S作为参数传进去</span></span><br><span class="line">uintptr_t ptr = (uintptr_t)S;</span><br><span class="line">makecontext(&amp;C-&gt;ctx, (<span class="keyword">void</span> (*)(<span class="keyword">void</span>)) mainfunc, <span class="number">2</span>, (uint32_t)ptr, (uint32_t)(ptr&gt;&gt;<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将当前的上下文放入S-&gt;main中，并将C-&gt;ctx的上下文替换到当前上下文</span></span><br><span class="line">swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx);</span><br></pre></td></tr></table></figure></p><p>这段函数非常的重要，有几个不可忽视的点：</p><ol><li><code>getcontext(&amp;C-&gt;ctx);</code> 初始化ucontext_t结构体，将当前的上下文放到C-&gt;ctx里面</li><li><code>C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;</code> 设置当前协程的运行时栈，也是共享栈。</li><li><code>C-&gt;ctx.uc_link = &amp;S-&gt;main;</code> 如果协程执行完，则切换到<code>S-&gt;main</code>主协程中进行执行。如果不设置, 则默认为NULL，那么协程执行完，整个程序就结束了。</li></ol><p>接下来是makecontext，这个函数用来设置对应ucontext的执行函数。如上，将<code>C-&gt;ctx</code>的执行函数体设置为了mainfunc。</p><p>makecontext后面的两个参数也非常有意思，这个可以看出来是把一个指针掰成了两个int作为参数传给mainfunc了。而在mainfunc的实现可以看出来，又会把这两个int拼成了一个<code>struct schedule*</code>。</p><p>那么，为什么不直接传<code>struct schedule*</code>呢，而要这么做，通过先拆两半，再在函数中拼起来？</p><p>这是因为makecontext的函数指针的参数是<code>uint32_t</code>类型，在64位系统下，一个<code>uint32_t</code>没法承载一个指针, 所以基于兼容性的考虑，才采用了这种做法。</p><p>接下来调用了<code>swapcontext</code>函数，这个函数比较简单，但也非常核心。作用是将当前的上下文内容放入<code>S-&gt;main</code>中，并将<code>C-&gt;ctx</code>的上下文替换到当前上下文。这样的话，将会执行新的上下文对应的程序了。在coroutine中, 也就是开始执行<code>mainfunc</code>这个函数。(<code>mainfunc</code>是对用户提供的协程函数的封装)。</p><h1 id="协程的切出：coroutine-yield"><a href="#协程的切出：coroutine-yield" class="headerlink" title="协程的切出：coroutine_yield"></a>协程的切出：coroutine_yield</h1><p>调用<code>coroutine_yield</code>可以使当前正在运行的协程切换到主协程中运行。此时，该协程会进入<code>SUSPEND</code>状态</p><p><code>coroutine_yield</code>的具体实现依赖于两个行为：</p><ol><li>调用<code>_save_stack</code>将当前协程的栈保存起来。因为coroutine是基于共享栈的，所以协程的栈内容需要单独保存起来。</li><li><code>swapcontext</code> 将当前上下文保存到当前协程的ucontext里面，同时替换当前上下文为主协程的上下文。 这样的话，当前协程会被挂起，主协程会被继续执行。</li></ol><p>这里也有个点极其关键, 就是如何保存当前协程的运行时栈, 也就是如何获取整个栈的内存空间。</p><p>这里我们需要了解下栈内存空间的布局，即栈的生长方向是从高地址往低地址。我们只要找到栈的栈顶和栈底的地址，就可以找到整个栈内存空间了。</p><p>在coroutine中，因为协程的运行时栈的内存空间是自己分配的。在coroutine_resume阶段设置了<code>C-&gt;ctx.uc_stack.ss_sp = S.S-&gt;stack</code>。根据以上理论，栈的生长方向是高地址到低地址，因此栈底的就是内存地址最大的位置，即<code>S-&gt;stack + STACK_SIZE</code>就是栈底位置。</p><p>那么，如何找到栈顶的位置呢？coroutine是基于以下方法做的：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> _save_stack(C,S-&gt;<span class="built_in">stack</span> + STACK_SIZE);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> _save_stack(struct coroutine *C, <span class="keyword">char</span> *top) &#123;</span><br><span class="line"><span class="keyword">char</span> dummy = <span class="number">0</span>;</span><br><span class="line">assert(top - &amp;dummy &lt;= STACK_SIZE);</span><br><span class="line">    <span class="comment">// 如果已分配内存小于当前栈的大小，则释放内存重新分配</span></span><br><span class="line"><span class="keyword">if</span> (C-&gt;cap &lt; top - &amp;dummy) &#123;</span><br><span class="line"><span class="built_in">free</span>(C-&gt;<span class="built_in">stack</span>);</span><br><span class="line">C-&gt;cap = top-&amp;dummy;</span><br><span class="line">C-&gt;<span class="built_in">stack</span> = <span class="built_in">malloc</span>(C-&gt;cap);</span><br><span class="line">&#125;</span><br><span class="line">C-&gt;size = top - &amp;dummy;</span><br><span class="line">    <span class="comment">// 从dummy拷贝size内存到C-&gt;stack</span></span><br><span class="line"><span class="built_in">memcpy</span>(C-&gt;<span class="built_in">stack</span>, &amp;dummy, C-&gt;size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里特意用到了一个dummy变量，这个dummy的作用非常关键也非常巧妙，大家可以细细体会下。因为dummy变量是刚刚分配到栈上的，此时就位于<strong>栈的最顶部位置</strong>。整个内存布局如下图所示：<br><img src="/img/coroutine/coroutine_dummy.png" alt=""></p><p>因此整个栈的大小就是从栈底到栈顶，<code>S-&gt;stack + STACK_SIZE - &amp;dummy</code>。</p><p>最后又调用了memcpy将当前运行时栈的内容，拷贝到了<code>C-&gt;stack</code>中保存了起来。</p><h1 id="coroutine-resume-SUSPEND-gt-RUNNING）"><a href="#coroutine-resume-SUSPEND-gt-RUNNING）" class="headerlink" title="coroutine_resume(SUSPEND -&gt; RUNNING）"></a>coroutine_resume(SUSPEND -&gt; RUNNING）</h1><p>当协程被yield之后会进入<code>SUSPEND</code>阶段，对该协程调用<code>coroutine_resume</code>会再次切入该协程。</p><p>这里的实现有两个重要的点：</p><ol><li><p><code>memcpy(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);</code><br>我们知道，在yield的时候，协程的栈内容保存到了C-&gt;stack数组中。<br>这个时候，就是用memcpy把协程的之前保存的栈内容，重新拷贝到运行时栈里面。这里有个点，拷贝的开始位置，需要简单计算下<br><code>S-&gt;stack + STACK_SIZE - C-&gt;size</code>这个位置就是之前协程的栈顶位置。</p></li><li><p><code>swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx);</code> 交换上下文。这点在上文有具体描述。</p></li></ol><h1 id="状态机转换"><a href="#状态机转换" class="headerlink" title="状态机转换"></a>状态机转换</h1><p>在coroutine中协程定义了四种状态，整个运行期间，也是根据这四种状态进行轮转。</p><p><img src="/img/coroutine/coroutine-state-machine.png" alt=""></p><h1 id="共享栈"><a href="#共享栈" class="headerlink" title="共享栈"></a>共享栈</h1><p>共享栈这个词在libco中提到的多，其实coroutine也是用的共享栈模型。<br>共享栈这个东西说起来很玄乎，实际原理不复杂，本质就是所有的协程在运行的时候都使用同一个栈空间。</p><p>共享栈对标的是非共享栈，也就是每个协程的栈空间都是独立的，固定大小。好处是协程切换的时候，内存不用拷贝来拷贝去。坏处则是<strong>内存空间浪费</strong>.</p><p>因为栈空间在运行时不能随时扩容，为了防止栈内存不够，所以要预先每个协程都要预先开一个足够的栈空间使用。当然很多协程用不了这么大的空间，就必然造成内存的浪费。</p><p>共享栈则是提前开了一个足够大的栈空间(coroutine默认是1M)。所有的栈运行的时候，都使用这个栈空间。<br>conroutine是这么设置每个协程的运行时栈：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">C-&gt;ctx.uc_stack.ss_sp = S-&gt;<span class="built_in">stack</span>; </span><br><span class="line">C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;</span><br></pre></td></tr></table></figure></p><p>对协程调用yield的时候，该协程栈内容暂时保存起来，保存的时候需要用到多少内存就开多少，这样就减少了内存的浪费。(即_save_stack函数的内容)。<br>当resume该协程的时候，协程之前保存的栈内容，会被重新拷贝到运行时栈中。</p><p>这就是所谓的共享栈的原理。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>云风的协程库代码非常简约，可以帮助我们更好的理解协程实现的基本原理。后面有机会也会细讲下微信libco的实现原理，这个更贴近于工业级的使用，用法也非常强大。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://github.com/zfengzhen/Blog/blob/master/article/ucontext%E7%B0%87%E5%87%BD%E6%95%B0%E5%AD%A6%E4%B9%A0.md" target="_blank" rel="noopener">ucontext簇函数学习</a></li><li><a href="https://www.zhihu.com/question/32218874" target="_blank" rel="noopener">为什么觉得协程是趋势?</a></li><li><a href="https://gameinstitute.qq.com/community/detail/107515" target="_blank" rel="noopener">天涯明月刀-无栈协程的应用</a></li><li><a href="https://zhengyinyong.com/ucontext-usage-and-coroutine.html" target="_blank" rel="noopener">ucontext 函数族的使用及协程库的实现</a></li><li><a href="https://langzi989.github.io/tags/ucontext-t/" target="_blank" rel="noopener">C++协程实现及原理</a></li><li><a href="https://www.zhihu.com/question/52193579/answer/129597362" target="_blank" rel="noopener">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么?</a></li><li><a href="https://blog.csdn.net/u011228889/article/details/79759834" target="_blank" rel="noopener">基于云风协程库的协程原理解读</a></li><li><a href="https://zhuanlan.zhihu.com/p/27339191" target="_blank" rel="noopener">x86-64 下函数调用及栈帧原理</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着Golang的兴起，协程尤其是有栈协程(stackful coroutine)越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。&lt;/p&gt;
&lt;p&gt;云风实现了一套&lt;a href=&quot;https://github.com/cloudwu/coroutine/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;C语言的协程库&lt;/a&gt;，整体背景可以参考其&lt;a href=&quot;https://blog.codingnow.com/2012/07/c_coroutine.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;博客&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;这个协程库非常轻量级，一共也才200多行代码，使用上更贴近于lua的写法（众所周知，云风是知名的lua粉)。整体基于ucontext和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。&lt;/p&gt;
&lt;p&gt;同时，我也提供了&lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/coroutine&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;coroutine注释版&lt;/a&gt;，辅助大家理解coroutine的代码。&lt;/p&gt;
    
    </summary>
    
      <category term="协程" scheme="http://www.cyhone.com/categories/%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="协程" scheme="http://www.cyhone.com/tags/%E5%8D%8F%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>WebSocket订单推送稳定性优化方案</title>
    <link href="http://www.cyhone.com/articles/optimization-of-websocket-push-system/"/>
    <id>http://www.cyhone.com/articles/optimization-of-websocket-push-system/</id>
    <published>2019-08-17T06:36:12.000Z</published>
    <updated>2019-11-03T09:22:16.606Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cloud.tencent.com/document/product/569/33102" target="_blank" rel="noopener">微信云支付Android 智能POS</a>使用WebSocket实现了用户订单的实时推送。即，顾客在扫描了门店的付款码，客户端会随即进行语音播报和打印等动作。</p><p>客户端利用WebSocket与后端维持长连接，当后端收到该门店订单时，即将成功态的订单通过对应的连接中。</p><p>然而，商户网络环境的多样性会导致WebSocket链路出现各种异常，从而引发漏单问题。</p><p>我们根据实际的场景，对此订单推送系统在稳定性上进行了大量优化，尽可能地提升了服务的可用性及自我恢复的能力。</p><a id="more"></a><h2 id="客户端的弱网环境"><a href="#客户端的弱网环境" class="headerlink" title="客户端的弱网环境"></a>客户端的弱网环境</h2><p>在网络应用的开发过程中，网络的稳定性始终是不可靠的。这点在网络环境多样的客户侧来说，特点尤为明显。</p><ol><li>客户往往会基于成本考虑，所使用的网络质量不高。如部分用户还会使用2G、3G网络。</li><li>在移动设备中，客户会进行网络切换。例如，从wifi切换到移动数据，或暂时把网络关闭掉。</li><li>后端服务变更或者其他问题可能会引起WebSocket链接暂时不可用。</li></ol><p>对于以上几种场景，都会引起WebSocket连接异常，导致连接关闭，从而会引发漏单现象。</p><p>一旦订单没有得到及时推送，店员虽然可以到交易查询中确认订单状态，但这样的异常行为如果频发，对于客户来说也是很难接受的。</p><p>我们引入了以下多种措施来解决此问题</p><h2 id="一、应用层心跳：尽快发现问题"><a href="#一、应用层心跳：尽快发现问题" class="headerlink" title="一、应用层心跳：尽快发现问题"></a>一、应用层心跳：尽快发现问题</h2><p>在浏览器端WebSocket相关接口非常简单，但缺了一个设置心跳的接口。我们需要设计一个应用层的心跳机制，来保证线路质量。</p><p>在设计应用层心跳时，主要出于以下几个方面：</p><ol><li><strong>nginx的proxy_read_timeout参数</strong>:<br>nginx在反向代理WebSocket请求时，有一个proxy_read_timeout参数。当连接在此超时时间内没有数据传输，则会主动断开，<br>默认行为是60s。因此我们需要一个应用层心跳，在proxy_read_timeout的时间内，发送心跳包，以保证连接不被断开。</li><li><strong>应用层心跳可以帮助我们快速检测和发现链路的健康程度</strong> :<br>为了快速检测到链路的异常问题，我们可以将心跳时间缩短到可接受范围内。</li></ol><p>在最初的版本设计中，我们的应用层心跳只涉及了ping接口。</p><p>即客户端主动发生向server端发生ping，如果发送成功，则说明链路正常，反之意味着链路不正常。</p><p>整个过程中，ping是否成功，都依赖于WebSocket是否触发了onError错误回调。</p><p>但在实际的开发过程中，<strong>我们发现，这样一种特殊场景</strong>：    </p><p>使用手机发热点供收银设备使用网络，在正常使用过程中，如果关闭手机的网络数据连接（wifi或者移动数据），但保持热点的正常开放，那么收银设备将无法快速感知到网络的异常，大概需要3-5分钟才能触发异常回调。</p><p>因此，针对此情况我们对应用层心跳进行了进一步的优化，让server端收到ping之后，回复一个pong包。我们根据ping和pong的时间间隔，来决定当前链路的健康程度。</p><h2 id="二、断线重连：自我恢复"><a href="#二、断线重连：自我恢复" class="headerlink" title="二、断线重连：自我恢复"></a>二、断线重连：自我恢复</h2><p>当WebSocket连接一旦发生了中断，将不会自动的恢复。因此，WebSocket的断线重连机制也是我们首要考虑的一个方面。</p><p>断线重连的实现过程比较简单，即当发生<strong>心跳超时</strong>、<strong>链路错误</strong>或者<strong>链路非正常关闭</strong>等问题时，我们将触发WebSocket的重连机制。</p><p>重连过程也非常简单，即不断重新连接WebSocket、重新鉴权等过程，直至连接成功。</p><p>这里需要注意的一个小小的点就是：在重新连接的时候, WebSocket的各种回调(onmessage、onopen)，都需要重新设置。</p><p>有了断线重连机制，可以实现WebSocket简单的自我恢复功能。</p><h2 id="三、推拉结合：兜底行为"><a href="#三、推拉结合：兜底行为" class="headerlink" title="三、推拉结合：兜底行为"></a>三、推拉结合：兜底行为</h2><p>引入了WebSocket的应用层心跳检测和断线重连，可以快速地帮我们发现链路的异常问题，同时尽快恢复到健康状态。</p><p>但是，当WebSocket服务侧发生了短时异常（如变更等），或者重连时间过长。</p><p>在应用层发现异常到重连成功的这个过程，整个推送服务最长可能有十秒左右的不可用时间，这个时长取决于心跳的间隔时长。且万一重连也不成功，这个不可用时间将会持续增大。</p><p>在设计中，需要考虑到这种异常情况，且在商户网络环境不稳定的情况下，此问题可能会被放大。</p><p>我们引入了主动拉取的方案，在网络异常时，将会切换为主动拉取模式，定时向后端拉取订单。</p><p>这里需要注意的有几点：</p><ol><li>每次主动拉取时，最好拉取时间有重叠。即：本次拉取的开始时间，是上次拉取的结束时间前1秒。<br>这样可以尽量减少因为定时器等环境原因，导致漏单问题</li><li>每次主动拉取后，检测当前WebSocket是否链路健康，如果健康则关闭主动拉取模式。</li></ol><p>因为我们主动拉取的范围重叠性以及主动拉取也可能和推送模式有一段时间的重叠，我们得到的订单可能会重复。</p><p>这里我们需要注意对订单进行一个简单的去重逻辑，即：</p><ol><li>万一订单已存在，就忽略该订单。这个可以用简单的set实现即可</li><li>根据订单范围的时效性，可以定时删除过期的订单号即可。</li></ol><p>引入主动拉取模式，一方面尽可能的减少了漏单可能的发生，另一方面对主动推送来说，也是一个兜底行为。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结来说，我们选择使用了WebSocket长连接的方式，实现了支付订单的实时推送，为了解决推送的不稳定性，我们主要采取了以下几种措施：</p><ul><li>定时发送应用层心跳，来快速地帮我们发现链路的异常问题</li><li>引入了断线重连机制，实现了WebSocket自我恢复</li><li>加入主动拉取模式，尽可能的减少了漏单可能的发生</li></ul><p>我们利用这几点措施，使得整个服务的可用性大大增强。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://nginx.org/en/docs/http/WebSocket.html" target="_blank" rel="noopener">WebSocket proxying</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://cloud.tencent.com/document/product/569/33102&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;微信云支付Android 智能POS&lt;/a&gt;使用WebSocket实现了用户订单的实时推送。即，顾客在扫描了门店的付款码，客户端会随即进行语音播报和打印等动作。&lt;/p&gt;
&lt;p&gt;客户端利用WebSocket与后端维持长连接，当后端收到该门店订单时，即将成功态的订单通过对应的连接中。&lt;/p&gt;
&lt;p&gt;然而，商户网络环境的多样性会导致WebSocket链路出现各种异常，从而引发漏单问题。&lt;/p&gt;
&lt;p&gt;我们根据实际的场景，对此订单推送系统在稳定性上进行了大量优化，尽可能地提升了服务的可用性及自我恢复的能力。&lt;/p&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Websocket" scheme="http://www.cyhone.com/tags/Websocket/"/>
    
  </entry>
  
  <entry>
    <title>重新理解IO模型</title>
    <link href="http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/"/>
    <id>http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/</id>
    <published>2018-11-03T18:50:00.000Z</published>
    <updated>2019-11-03T09:22:16.606Z</updated>
    
    <content type="html"><![CDATA[<p>在进行Linux网络编程开发的时候，免不了会涉及到IO模型的讨论。《Unix网络编程》一书中提到的几种IO模型，我们在开发过程中，讨论最多的应该就是三种： <code>阻塞IO</code>、<code>非阻塞IO</code>以及<code>异步IO</code>。</p><p>本文试图理清楚几种IO模型的根本性区别，同时分析了为什么在Linux网络编程中最好要用非阻塞式IO。<br><a id="more"></a></p><h1 id="网络IO概念准备"><a href="#网络IO概念准备" class="headerlink" title="网络IO概念准备"></a>网络IO概念准备</h1><p>在讨论网络IO之前，一定要有一个概念上的准备前提: <strong>不要用操作磁盘文件的经验去看待网络IO。</strong> 具体的原因我们在下文中会介绍到。</p><p>相比于传统的网络IO来说，一个普通的文件描述符的操作可以分为两部分。以<code>read</code>为例，我们利用read函数从socket中同步阻塞的读取数据，整个流程如下所示：</p><p><img src="/img/noblocking-io/block-read.png" alt="read示意图"></p><ol><li>调用read后，该调用会转入内核调用</li><li>内核会等待该socket的可读事件，直到远程向socket发送了数据。可读事件成立(这里还需要满足TCP的低水位条件，但是不做太详细的讨论)</li><li>数据包到达内核，接着内核将数据拷贝到用户进程中，也就是read函数指定的buffer参数中。至此，read调用结束。</li></ol><p>可以看到除了转入内核调用，与传统的磁盘IO不同的是，网络IO的读写大致可以分为两个阶段：</p><ol><li>等待阶段：等待socket的可读或者可写事件成立</li><li>拷贝数据阶段：将数据从内核拷贝到用户进程，或者从用户进程拷贝到内核中，</li></ol><h1 id="三种IO模型的区别"><a href="#三种IO模型的区别" class="headerlink" title="三种IO模型的区别"></a>三种IO模型的区别</h1><p>我们日常开发遇到最多的三种IO模型分别是：同步阻塞IO、同步非阻塞IO、异步IO。</p><p>这些名词非常容易混淆，为什么一个IO会有两个限定词：同步和阻塞？同步和阻塞分别代表什么意思？<br>简单来说：</p><ol><li>等待<strong>阻塞</strong>: 在socket操作的第一个阶段，也就是用户等待socket可读可写事件成立的这个阶段。如果一直等待下去，直到成立后，才进行下个阶段，则称为阻塞式IO；如果发现socket非可读可写状态，则直接返回，不等待，也不进行下个阶段，则称为非阻塞式IO。</li><li>拷贝<strong>同步</strong>: 从内核拷贝到用户空间的这个阶段，如果直到从开始拷贝直到拷贝结束，read函数才返回，则称为同步IO。如果在调用read的时候就直接返回了，等到数据拷贝结束，才通过某种方式(例如回调)通知到用户，这种被称为异步IO。</li></ol><p>所谓异步，实际上就是非同步非阻塞。</p><h2 id="同步阻塞IO"><a href="#同步阻塞IO" class="headerlink" title="同步阻塞IO"></a>同步阻塞IO</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">read(fd, buffer, count)</span><br></pre></td></tr></table></figure><p>Linux下面如果直接不对fd进行特殊处理，直接调用read，就是同步阻塞IO。同步阻塞IO的两个阶段都需要等待完成后，read才会返回。</p><p><strong>也就是说，如果远程一直没有发送数据，则read一直就不会返回，整个线程就会阻塞到这里了。</strong></p><h1 id="同步非阻塞IO"><a href="#同步非阻塞IO" class="headerlink" title="同步非阻塞IO"></a>同步非阻塞IO</h1><p>对于同步非阻塞IO来说，如果没有可读可写事件，则直接返回；如果有，则进行第二个阶段，复制数据。<br>在linux下面，需要使用fcntl将fd变为非阻塞的。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> flags = fcntl(socket, F_GETFL, <span class="number">0</span>); </span><br><span class="line">fcntl(socket, F_SETFL, flags | O_NONBLOCK);</span><br></pre></td></tr></table></figure></p><p>同时，如果read的时候，fd不可读，则read调用会触发一个EWOULDBLOCK错误(或者EAGAIN，EWOULDBLOCK和EAGAIN是一样的)。用户只要检查下<code>errno == EWOULDBLOCK</code>, 即可判断read是否返回正常。</p><p>基本在Linux下进行网络编程，非阻塞IO都是不二之选。</p><h2 id="异步IO"><a href="#异步IO" class="headerlink" title="异步IO"></a>异步IO</h2><p>Linux开发者应该很少使用纯粹的异步IO。因为目前来说，Linux并没有一个完美的异步IO的解决方案。pthread虽然提供了aio的接口，但是这里不做太具体的讨论了。</p><p>我们平常接触到的异步IO库或者框架都是在代码层面把操作封装成了异步。但是在具体调用read或者write的时候，一般还是用的非阻塞式IO。</p><h1 id="不能用操作磁盘IO的经验看待网络IO"><a href="#不能用操作磁盘IO的经验看待网络IO" class="headerlink" title="不能用操作磁盘IO的经验看待网络IO"></a>不能用操作磁盘IO的经验看待网络IO</h1><p>为什么不能用操作磁盘IO的经验看待网络IO。实际上在磁盘IO中，等待阶段是不存在的，因为磁盘文件并不像网络IO那样，需要等待远程传输数据。 </p><p>所以有的时候，习惯了操作磁盘IO的开发者会无法理解同步阻塞IO的工作过程，无法理解为什么read函数不会返回。</p><p>关于磁盘IO与同步非阻塞的讨论，在知乎上有一篇帖子<a href="https://www.zhihu.com/question/52989189" target="_blank" rel="noopener">为什么书上说同步非阻塞io在对磁盘io上不起作用?</a> 讨论了这个问题。</p><h1 id="为什么在Linux网络编程中最好要用非阻塞式IO？"><a href="#为什么在Linux网络编程中最好要用非阻塞式IO？" class="headerlink" title="为什么在Linux网络编程中最好要用非阻塞式IO？"></a>为什么在Linux网络编程中最好要用非阻塞式IO？</h1><p>上文说到，在linux网络编程中，如果使用阻塞式的IO，假如某个fd长期不可读，那么一个线程相应将会被长期阻塞，那么线程资源就会被白白浪费。</p><p>那么，如果我们用了epoll，还必须要使用非阻塞IO吗？ 因为如果使用epoll监听了fd的可读事件，在epoll_wait之后调用read，此时fd一定是可读的， 那么此时非阻塞IO相比于阻塞IO的优势不就没了吗？</p><p>实际上，并不是这样的。<strong>epoll也必须要搭配非阻塞IO使用。</strong><br>这个帖子<a href="https://www.zhihu.com/question/37271342" target="_blank" rel="noopener">为什么 IO 多路复用要搭配非阻塞 IO?</a> 详细讨论了这个问题？</p><p>总结来说，原因有二：</p><ol><li>fd在read之前有可能会重新进入不可读的状态。要么被其他方式读走了(参考惊群问题), 还有可能被内核抛弃了，总的来说，fd因为在read之前，数据被其他方式读走，fd重新变为不可读。此时，用阻塞式IO的read函数就会阻塞整个线程。</li><li>epoll只是返回了可读事件，但是并没有返回可以读多少数据量。因此，非阻塞IO的做法是读多次，直到不能读。而阻塞io却只能读一次，因为万一一次就读完了缓冲区所有数据，第二次读的时候，read就会又阻塞了。但是对于epoll的ET模式来说，缓冲区的数据只会在改变的通知一次，如果此次没有消费完，在下次数据到来之前，可读事件再也不会通知了。那么对于只能调用一次read的阻塞式IO来说，未读完的数据就有可能永远读不到了。</li></ol><p>因此，在Linux网络编程中最好使用非阻塞式IO。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="http://man7.org/linux/man-pages/man2/read.2.html" target="_blank" rel="noopener">http://man7.org/linux/man-pages/man2/read.2.html</a></li><li><a href="http://matt33.com/2017/08/06/unix-io/" target="_blank" rel="noopener">http://matt33.com/2017/08/06/unix-io/</a></li><li><a href="https://www.zhihu.com/question/52989189" target="_blank" rel="noopener">https://www.zhihu.com/question/52989189</a></li><li><a href="https://www.zhihu.com/question/37271342" target="_blank" rel="noopener">https://www.zhihu.com/question/37271342</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在进行Linux网络编程开发的时候，免不了会涉及到IO模型的讨论。《Unix网络编程》一书中提到的几种IO模型，我们在开发过程中，讨论最多的应该就是三种： &lt;code&gt;阻塞IO&lt;/code&gt;、&lt;code&gt;非阻塞IO&lt;/code&gt;以及&lt;code&gt;异步IO&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;本文试图理清楚几种IO模型的根本性区别，同时分析了为什么在Linux网络编程中最好要用非阻塞式IO。&lt;br&gt;
    
    </summary>
    
      <category term="网络编程" scheme="http://www.cyhone.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.cyhone.com/tags/Linux/"/>
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="epoll" scheme="http://www.cyhone.com/tags/epoll/"/>
    
  </entry>
  
  <entry>
    <title>客户端秒级时间同步方案</title>
    <link href="http://www.cyhone.com/articles/client-time-calibration/"/>
    <id>http://www.cyhone.com/articles/client-time-calibration/</id>
    <published>2018-10-25T12:08:06.000Z</published>
    <updated>2019-10-10T06:02:57.090Z</updated>
    
    <content type="html"><![CDATA[<p>在客户端开发中，往往会有一些功能对时间要求比较严格，客户端需要获取到当前最准确的时间。但由于客户端环境多种多样，我们无法保证直接在客户端设备上获取到的时间是最准确的时间。<br>对于某些问题设备来说，设备时间与比当前实际的时间差了几个小时，甚至几天的情况都存在。倘若某功能依赖于当前时间，而客户端所提供的时间不准，就往往会给客户造成一些困扰。</p><p>那么，客户端如何能够获取到当前最准确的时间呢？<br><a id="more"></a></p><h2 id="从服务器同步时间"><a href="#从服务器同步时间" class="headerlink" title="从服务器同步时间"></a>从服务器同步时间</h2><p>我们首先想到的是，服务器可以提供一个获取当前时间戳的接口。客户端每次获取当前时间时，都直接从服务器拉数据就可以了。</p><p>这个方案简单粗暴，但是问题也可以一眼看出：<br>每次都从服务器拉时间，一方面会对服务器造成一些压力；另一方面网络也存在时延损耗和不稳定的可能，将会减低客户端的体验。</p><h2 id="只拉取一次时间"><a href="#只拉取一次时间" class="headerlink" title="只拉取一次时间"></a>只拉取一次时间</h2><p>那么，能不能只从服务器拉取一次时间，不用每次都访问服务器呢？<br>我们可以在客户端初始化的时候，拉取一次时间接口。<br>记此时的服务器时间为<code>server_init_time</code>，同时获取到当前客户端的时间, 记为<code>local_init_time</code>。</p><p>当客户端需要获取当前的准确时间的时候，首先得到客户端的当前时间 记为local_now_time<br>那么，当前最准确的时间就可以通过一个简单的差值计算得到。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">server_now_time = server_init_time + (local_now_time - local_init_time)</span><br></pre></td></tr></table></figure><p>通过计算两次本地时间的差值，就可以推出当前服务器的时间了。</p><h2 id="网络时延的损耗"><a href="#网络时延的损耗" class="headerlink" title="网络时延的损耗"></a>网络时延的损耗</h2><p>上述方案实际上已经能够准确的获取到当前服务器的时间了。<br>但是仍然有个不严谨的地方：<br>在该方案中，我们假设server_init_time和local_init_time是同一时刻。<br>但实际上并不是这样的。server_init_time只是http请求到达服务器的时间。<br>server_init_time和local_init_time还差一个请求返回时间。</p><p><img src="/img/network.png" alt="网络时延"></p><p>我们都知道网络是不可靠的，严重情况下，一次网络时延可以达到数秒。这对于时间校准的也会造成一些小小的干扰。</p><p>基于这个问题，我们可以假设<code>客户端发出请求到服务器的时间</code> 与 <code>服务器回复请求到客户端的时间</code>基本是一致的。虽然在实际情况下，有可能存在偏差。</p><p>此时<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">server_init_time = server_init_time - delta / <span class="number">2</span>;</span><br></pre></td></tr></table></figure></p><p>其中delta是指一次请求的总时延。</p><h2 id="防止客户端运行期间时间改变"><a href="#防止客户端运行期间时间改变" class="headerlink" title="防止客户端运行期间时间改变"></a>防止客户端运行期间时间改变</h2><p>基于以上考虑，我们的时间校准方案已经基本上可以满足大多数客户端的需求了。</p><p>但是，你永远也不会知道客户端会出现什么情况。<br>假如，在软件运行期间，无论是出于被动还是用户有意主动的修改，客户端的时间发生了变化。那么，以上通过计算两次本地时间差值来获取准确时间的方案将会失效。</p><p>因此，我们需要使用一个不随本地时间变化的维度作为校对的标准。我们首先想到了开机时长，开机时长是指当前时刻距离设备开机时刻的毫秒数，而这个东西是不随设备的时钟变化的。<br>因此我们的公式可以修改为：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_now_time = server_init_time + (local_now_tickcount - local_init_tickout)</span><br></pre></td></tr></table></figure><p>local_now_tickcount和local_init_tickout分别指的是设备当前的开机时长和初始化阶段用户的开机时长。</p><h2 id="时间溢出"><a href="#时间溢出" class="headerlink" title="时间溢出"></a>时间溢出</h2><p>使用开机时长作为校对的标准的方案，看似完美无缺，实际上仍然存在着一些意想不到的问题….</p><p>以Windows为例，C#用来返回开机时长的方法<code>Environment.TickCount</code>是int32类型的，单位为ms。<br>我们可以简单计算下，一天大概有 <code>24 * 60 * 60 * 1000 = 86400000</code> 毫秒，而int32的最大值是<code>2^31 - 1 = 2147483647</code></p><p>这也就意味着，当开机时间超过<code>2147483647 / 86400000 = 24.85</code> 天的时候int32就溢出了。。<br>也就意味着，如果我们的客户端软件运行在一个25天未关机的设备上，那么软件的时间校准将会出现严重的问题。。。</p><p>在真实的情况下，客户端设备25天不关机的情况太常见了。<br>那么，如果解决此问题呢？</p><p>我们发现C#有一个StopWatch函数，常常用来统计函数运行时长。而它的时间表示<code>stopWatch.ElapsedMilliseconds</code>是long型的。同时，StopWatch是基于Timer实现的时间统计，也不与本地时钟相关。</p><p>那么，与利用开机时长的方案类似，我们在软件初始化时，开启一个StopWatch。每次获取准确时间的时候，将stopWatch中记录的当前耗时时间与服务器初始时间相加，即可得到当前的准确时间。</p><p>最终的时间校准方案如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server_init_time = server_init_time - delta / 2;</span><br><span class="line">server_now_time = server_init_time + stopWatch.ElapsedMilliseconds / 1000</span><br></pre></td></tr></table></figure><h2 id="定期校准"><a href="#定期校准" class="headerlink" title="定期校准"></a>定期校准</h2><p>考虑到时间越长，有可能本地时间与服务器时间的偏差逐渐加大。可以采用定时器，定时对本地时间进行重新校准。</p><p>基于以上方案，我们就实现了客户端与后台时间的秒级时间同步方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在客户端开发中，往往会有一些功能对时间要求比较严格，客户端需要获取到当前最准确的时间。但由于客户端环境多种多样，我们无法保证直接在客户端设备上获取到的时间是最准确的时间。&lt;br&gt;对于某些问题设备来说，设备时间与比当前实际的时间差了几个小时，甚至几天的情况都存在。倘若某功能依赖于当前时间，而客户端所提供的时间不准，就往往会给客户造成一些困扰。&lt;/p&gt;
&lt;p&gt;那么，客户端如何能够获取到当前最准确的时间呢？&lt;br&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
  </entry>
  
  <entry>
    <title>muduo源码剖析</title>
    <link href="http://www.cyhone.com/articles/analysis-of-muduo/"/>
    <id>http://www.cyhone.com/articles/analysis-of-muduo/</id>
    <published>2018-06-12T15:51:37.000Z</published>
    <updated>2019-11-20T03:18:33.103Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/chenshuo/muduo" target="_blank" rel="noopener">muduo</a>是<a href="http://chenshuo.com" target="_blank" rel="noopener">陈硕</a>大神个人开发的C++的TCP网络编程库。muduo基于Reactor模式实现。Reactor模式也是目前大多数Linux端高性能网络编程框架和网络应用所选择的主要架构，例如内存数据库Redis和Java的Netty库等。</p><p>陈硕的《Linux多线程服务器端编程》一书对muduo整个架构进行了非常详尽的介绍和分析，可以说是学习muduo源码和设计理念最好的资料了。这本书也非常推荐大家购买阅读，感觉是后台开发的必读书目了。</p><p>而本文则主要是从源码角度辅助理解整个muduo的实现，同时也姑且算是对muduo的一个小小的补充。</p><p>同时我也提供了一个<a href="https://github.com/chenyahui/AnnotatedCode/tree/master/muduo" target="_blank" rel="noopener">muduo注释版</a>，用以辅助理解muduo的源码。<br><a id="more"></a></p><h1 id="muduo的架构和概念"><a href="#muduo的架构和概念" class="headerlink" title="muduo的架构和概念"></a>muduo的架构和概念</h1><p>muduo中类的职责和概念划分的非常清晰，在《Linux多线程服务器端编程》一书的6.3.1章节有详细的介绍。实际上目前很多网络库的接口设计也都受到了muduo的影响，例如360的evpp等。</p><p>而muduo的整体风格受到netty的影响，整个架构依照Reactor模式，基本与如下图所示相符：</p><p><img src="/img/reactor/single_thread_reactor.png" alt="单线程Reactor模式"></p><p>所谓Reactor模式，是有一个循环的过程，监听对应事件是否触发，触发时调用对应的callback进行处理。</p><p>这里的事件在muduo中包括Socket可读写事件、定时器事件。在其他网络库中如libevent也包括了signal、用户自定义事件等。</p><p>负责事件循环的部分在muduo命名为<code>EventLoop</code>，其他库如netty、libevent也都有对应的组件。 </p><p>负责监听事件是否触发的部分，在muduo中叫做<code>Poller</code>。muduo提供了epoll和poll两种来实现，默认是epoll实现。<br>通过环境变量<code>MUDUO_USE_POLL</code>来决定是否使用poll:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Poller* Poller::newDefaultPoller(EventLoop* loop)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 通过此环境变量来决定使用poll还是epoll</span></span><br><span class="line">  <span class="keyword">if</span> (::getenv(<span class="string">"MUDUO_USE_POLL"</span>))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> PollPoller(loop);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> EPollPoller(loop);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>此外，图中的acceptor负责accept新连接，并将新连接分发到subReactor。这个组件在muduo中也叫做<code>Acceptor</code>。<br>关于图中的其他部分，会在<a href="#muduo的线程模型">muduo的线程模型</a>一节有详细介绍。</p><h1 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h1><p>本文首先从最简单的echo server入手，来介绍muduo的基本使用，同时也方便后面概念的理解。<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">onMessage</span><span class="params">(<span class="keyword">const</span> muduo::net::TcpConnectionPtr&amp; conn,</span></span></span><br><span class="line"><span class="function"><span class="params">                           muduo::net::Buffer* buf,</span></span></span><br><span class="line"><span class="function"><span class="params">                           muduo::Timestamp time)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  conn-&gt;send(buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    muduo::net::EventLoop loop;</span><br><span class="line">    muduo::net::<span class="function">InetAddress <span class="title">listenAddr</span><span class="params">(<span class="number">2007</span>)</span></span>;</span><br><span class="line">    <span class="function">TcpServer <span class="title">server</span><span class="params">(&amp;loop, listenAddr)</span></span>;</span><br><span class="line">    server.setMessageCallback(onMessage);</span><br><span class="line">    server.start();</span><br><span class="line">    loop.loop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>echo-server的代码量非常简洁。一个典型的muduo的TcpServer工作流程如下：</p><ol><li>建立一个事件循环器EventLoop</li><li>建立对应的业务服务器TcpServer</li><li>设置TcpServer的Callback</li><li>启动server</li><li>开启事件循环</li></ol><p>陈硕认为，TCP网络编程的本质是处理三个半事件，即：</p><ol><li>连接的建立</li><li>连接的断开：包括主动断开和被动断开</li><li>消息到达，文件描述符可读。</li><li>消息发送完毕。这个算半个事件。</li></ol><p>我们接下来分析下muduo是怎么处理和实现这三个半事件的</p><h1 id="连接的建立"><a href="#连接的建立" class="headerlink" title="连接的建立"></a>连接的建立</h1><p>在我们单纯使用linux的API，编写一个简单的Tcp服务器时，建立一个新的连接通常需要四步：</p><blockquote><p>步骤1. socket() // 调用socket函数建立监听socket<br>步骤2. bind()   // 绑定地址和端口<br>步骤3. listen() // 开始监听端口<br>步骤4. accept() // 返回新建立连接的fd</p></blockquote><p>我们接下来分析下，这四个步骤在muduo中都是何时进行的：</p><p>首先在TcpServer对象构建时，TcpServer的属性acceptor同时也被建立。<br>在Acceptor的构造函数中分别调用了socket函数和bind函数完成了<strong>步骤1</strong>和<strong>步骤2</strong>。<br>即，当<code>TcpServer server(&amp;loop, listenAddr);</code>执行结束时，监听socket已经建立好，并已绑定到对应地址和端口了。</p><p>而当执行<code>server.start()</code>时，主要做了两个工作：</p><ol><li>在监听socket上启动listen函数，也就是<strong>步骤3</strong>；</li><li>将监听socket的可读事件注册到EventLoop中。</li></ol><p>此时，程序已完成对地址的监听，但还不够，因为此时程序的主角<code>EventLoop</code>尚未启动。<br>当调用<code>loop.loop()</code>时，程序开始监听该socket的可读事件。</p><p>当新连接请求建立时，可读事件触发，此时该事件对应的callback在EventLoop::loop()中被调用。<br>该事件的callback实际上就是Acceptor::handleRead()方法。</p><p>在Acceptor::handleRead()方法中，做了三件事：</p><ol><li>调用了accept函数，完成了<strong>步骤4</strong>，实现了连接的建立。得到一个已连接socket的fd</li><li>创建TcpConnection对象</li><li>将已连接socket的可读事件注册到EventLoop中。</li></ol><p>这里还有一个需要注意的点，创建的TcpConnnection对象是个shared_ptr，该对象会被保存在TcpServer的connections中。这样才能保证引用计数大于0，对象不被释放。</p><p>至此，一个新的连接已完全建立好，其可读事件也已注册到EventLoop中了。</p><h1 id="消息的读取"><a href="#消息的读取" class="headerlink" title="消息的读取"></a>消息的读取</h1><p>上节讲到，在新连接建立的时候，会将新连接的socket的可读事件注册到EventLoop中。<br>假如客户端发送消息，导致已连接socket的可读事件触发，该事件对应的callback同样也会在EventLoop::loop()中被调用。</p><p>该事件的callback实际上就是TcpConnection::handleRead方法。<br>在TcpConnection::handleRead方法中，主要做了两件事：</p><ol><li>从socket中读取数据，并将其放入inputbuffer中</li><li>调用messageCallback，执行业务逻辑。</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ssize_t</span> n = inputBuffer_.readFd(channel_-&gt;fd(), &amp;savedErrno);</span><br><span class="line"><span class="keyword">if</span> (n &gt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">    messageCallback_(shared_from_this(), &amp;inputBuffer_, receiveTime);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>messageCallback是在建立新连接时，将<code>TcpServer::messageCallback</code>方法bind到了<code>TcpConnection::messageCallback</code>的方法。</p><p>TcpServer::messageCallback就是业务逻辑的主要实现函数。通常情况下，我们可以在里面实现消息的编解码、消息的分发等工作，这里就不再深入探讨了。</p><p>在我们上面给出的示例代码中，echo-server的messageCallback非常简单，就是直接将得到的数据，重新send回去。在实际的业务处理中，一般都会调用TcpConnection::send()方法，给客户端回复消息。</p><p>这里需要注意的是，在messageCallback中，用户会有可能会把任务抛给自定义的Worker线程池处理。<br>但是这个在Worker线程池中任务，切忌直接对Buffer的操作。因为Buffer并不是线程安全的。</p><p>我们需要记住一个准则:</p><blockquote><p>所有对IO和buffer的读写，都应该在IO线程中完成。</p></blockquote><p>一般情况下，先在交给Worker线程池之前，应该现在IO线程中把Buffer进行切分解包等动作。将解包后的消息交由线程池处理，避免多个线程操作同一个资源。</p><h1 id="消息的发送"><a href="#消息的发送" class="headerlink" title="消息的发送"></a>消息的发送</h1><p>用户通过调用TcpConnection::send()向客户端回复消息。由于muduo中使用了OutputBuffer，因此消息的发送过程比较复杂。</p><p>首先需要注意的是线程安全问题, 对于消息的读写必须都在EventLoop的同一个线程(通常称为IO线程)中进行：<br>因此，TcpConnection::send保证了线程安全性，它是这么做的：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> TcpConnection::send(<span class="keyword">const</span> StringPiece&amp; message)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (state_ == kConnected)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (loop_-&gt;isInLoopThread())</span><br><span class="line">    &#123;</span><br><span class="line">      sendInLoop(message);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      loop_-&gt;runInLoop(</span><br><span class="line">          boost::bind(&amp;TcpConnection::sendInLoop,</span><br><span class="line">                      <span class="keyword">this</span>,     <span class="comment">// FIXME</span></span><br><span class="line">                      message.as_string()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>检测send的时候，是否在当前IO线程，如果是的话，直接进行写相关操作<code>sendInLoop</code>。<br>如果不在一个线程的话，需要将该任务抛给IO线程执行<code>runInloop</code>, 以保证write动作是在IO线程中执行的。我们后面会讲解<code>runInloop</code>的具体实现。</p><p>在sendInloop中，做了下面几件事：</p><ol><li>假如OutputBuffer为空，则直接向socket写数据</li><li>如果向socket写数据没有写完，则统计剩余的字节个数，并进行下一步。没有写完可能是因为此时socket的TCP缓冲区已满了。</li><li>如果此时OutputBuffer中的旧数据的个数和未写完字节个数之和大于highWaterMark，则将highWaterMarkCallback放入待执行队列中</li><li><strong>将对应socket的可写事件注册到EventLoop中</strong></li></ol><p>注意，直到发送的时候，才把socket的可写事件注册到了EventLoop中。之前只注册了可读事件。</p><p>连接socket的可写事件对应的callback是TcpConnection::handleWrite()<br>当某个socket的可写事件触发时，TcpConnection::handleWrite会做两个工作：</p><ol><li>尽可能将数据从OutputBuffer中向socket中write数据</li><li>如果OutputBuffer没有剩余的，则<strong>将该socket的可写事件移除</strong>，并调用writeCompleteCallback</li></ol><h2 id="为什么要移除可写事件"><a href="#为什么要移除可写事件" class="headerlink" title="为什么要移除可写事件"></a>为什么要移除可写事件</h2><p>因为当OutputBuffer中没数据时，我们不需要向socket中写入数据。但是此时socket一直是处于可写状态的， 这将会导致TcpConnection::handleWrite()一直被触发。然而这个触发毫无意义，因为并没有什么可以写的。</p><p>所以muduo的处理方式是，当OutputBuffer还有数据时，socket可写事件是注册状态。当OutputBuffer为空时，则将socket的可写事件移除。</p><p>此外，highWaterMarkCallback和writeCompleteCallback一般配合使用，起到限流的作用。在《linux多线程服务器端编程》一书的8.9.3一节中有详细讲解。这里就不再赘述了</p><h1 id="连接的断开"><a href="#连接的断开" class="headerlink" title="连接的断开"></a>连接的断开</h1><p>我们看下muduo对于连接的断开是怎么处理的。<br>连接的断开分为被动断开和主动断开。主动断开和被动断开的处理方式基本一致，因此本文只讲下被动断开的部分。</p><p>被动断开即远程端断开了连接，server端需要感知到这个断开的过程，然后进行的相关的处理。</p><p>其中感知远程断开这一步是在Tcp连接的可读事件处理函数<code>handleRead</code>中进行的：当对socket进行read操作时，返回值为0，则说明此时连接已断开。</p><p>接下来会做四件事情：</p><ol><li>将该TCP连接对应的事件从EventLoop移除</li><li>调用用户的ConnectionCallback</li><li>将对应的TcpConnection对象从Server移除。</li><li>close对应的fd。此步骤是在析构函数中被动触发的，当TcpConnection对象被移除后，引用计数为0，对象析构时会调用close。</li></ol><h1 id="runInLoop的实现"><a href="#runInLoop的实现" class="headerlink" title="runInLoop的实现"></a>runInLoop的实现</h1><p>在讲解消息的发送过程时候，我们讲到为了保证对buffer和socket的写动作是在io线程中进行，使用了一个<code>runInLoop</code>函数，将该写任务抛给了io线程处理。</p><p>我们接下来看下<code>runInLoop</code>的实现：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::runInLoop(<span class="keyword">const</span> Functor&amp; cb)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (isInLoopThread())</span><br><span class="line">  &#123;</span><br><span class="line">    cb();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    queueInLoop(cb);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里可以看到，做了一层判断。如果调用时是此EventLoop的运行线程，则直接执行此函数。<br>否则调用<code>queueInLoop</code>函数。我们看下<code>queueInLoop</code>的实现。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::queueInLoop(<span class="keyword">const</span> Functor&amp; cb)</span><br><span class="line">&#123;</span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  pendingFunctors_.push_back(cb);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!isInLoopThread() || callingPendingFunctors_)</span><br><span class="line">  &#123;</span><br><span class="line">    wakeup();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有两个动作：</p><ol><li>加锁，然后将该函数放到该EventLoop的pendingFunctors_队列中。</li><li>判断是否要唤醒EventLoop，如果是则调用wakeup()唤醒该EventLoop。</li></ol><p>这里有几个问题：</p><ul><li>为什么要唤醒EventLoop？</li><li>wakeup是怎么实现的?</li><li>pendingFunctors_是如何被消费的?</li></ul><h2 id="为什么要唤醒EventLoop"><a href="#为什么要唤醒EventLoop" class="headerlink" title="为什么要唤醒EventLoop"></a>为什么要唤醒EventLoop</h2><p>我们首先调用了<code>pendingFunctors_.push_back(cb);</code>, 将该函数放在pendingFunctors_中。EventLoop的每一轮循环最后会调用doPendingFunctors依次执行这些函数。</p><p>而EventLoop的唤醒是通过epoll_wait实现的，如果此时该EventLoop中迟迟没有事件触发，那么epoll_wait一直就会阻塞。<br>这样会导致，pendingFunctors_迟迟不能被执行了。</p><p>所以对EventLoop的唤醒是必要的。</p><h2 id="wakeup是怎么实现的"><a href="#wakeup是怎么实现的" class="headerlink" title="wakeup是怎么实现的"></a>wakeup是怎么实现的</h2><p>muduo这里采用了对eventfd的读写来实现对EventLoop的唤醒。</p><p>在EventLoop建立之后，就创建一个eventfd，并将其可读事件注册到EventLoop中。</p><p><code>wakeup()</code>的过程本质上是对这个eventfd进行写操作，以触发该eventfd的可读事件。这样就起到了唤醒EventLoop的作用。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::wakeup()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">uint64_t</span> one = <span class="number">1</span>;</span><br><span class="line">  sockets::write(wakeupFd_, &amp;one, <span class="keyword">sizeof</span> one);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很多库为了兼容macos，往往使用pipe来实现这个功能。muduo采用了eventfd，性能更好些，但代价是不能支持macos了。不过muduo似乎从一开始的定位就不打算支持？</p><h2 id="doPendingFunctors的实现"><a href="#doPendingFunctors的实现" class="headerlink" title="doPendingFunctors的实现"></a>doPendingFunctors的实现</h2><p>本部分讲下<code>doPendingFunctors</code>的实现，muduo是如何处理这些待处理的函数的，以及中间用了哪些优化操作。<br>代码如下所示：<br><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> EventLoop::doPendingFunctors()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Functor&gt; functors;</span><br><span class="line"> </span><br><span class="line">  callingPendingFunctors_ = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  functors.swap(pendingFunctors_);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; functors.size(); ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    functors[i]();</span><br><span class="line">  &#125;</span><br><span class="line">  callingPendingFunctors_ = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>从代码可以看到，函数非常简单。大概只有十行代码，但是这十行却有两个非常巧妙的措施。</p><p><strong>callingPendingFunctors_的作用</strong></p><p>从代码可以看出，如果callingPendingFunctors_为false，则说明此时尚未开始执行doPendingFunctors函数。<br>这个有什么作用呢，我们需要结合下queueInLoop中，对是否执行wakeup()的判断</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (!isInLoopThread() || callingPendingFunctors_)</span><br><span class="line">&#123;</span><br><span class="line">  wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里还需要结合下EventLoop循环的实现，其中<code>doPendingFunctors()</code>是<strong>每轮循环的最后一步处理</strong>。<br>如果调用queueInLoop和EventLoop在同一个线程，且callingPendingFunctors_为false时，则说明：<strong>此时尚未执行到doPendingFunctors()。</strong><br>那么此时即使不用wakeup，也可以在之后照旧执行doPendingFunctors()了。</p><p>这么做的好处非常明显，可以减少对eventfd的io读写。</p><p><strong>锁范围的减少</strong><br>在此函数中，有一段特别的代码：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Functor&gt; functors;</span><br><span class="line">&#123;</span><br><span class="line">  <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">  functors.swap(pendingFunctors_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个作用是pendingFunctors_和functors的内容进行交换，实际上就是此时functors持有了pendingFunctors_的内容，而pendingFunctors_被清空了。</p><p>这个好处是什么呢？<br>如果不这么做，直接遍历pendingFunctors_,然后处理对应的函数。这样的话，锁会一直等到所有函数处理完才会被释放。在此期间，queueInLoop将不可用。</p><p>而以上的写法，可以极大减小锁范围，整个锁的持有时间就是swap那一下的时间。待处理函数执行的时候，其他线程还是可以继续调用queueInLoop。</p><h1 id="muduo的线程模型"><a href="#muduo的线程模型" class="headerlink" title="muduo的线程模型"></a>muduo的线程模型</h1><p>muduo默认是单线程模型的，即只有一个线程，里面对应一个EventLoop。这样整体对于线程安全的考虑可能就比较简单了，<br>但是muduo也可以支持以下几种线程模型：</p><h2 id="主从reactor模式"><a href="#主从reactor模式" class="headerlink" title="主从reactor模式"></a>主从reactor模式</h2><p>主从reactor是netty的默认模型，一个reactor对应一个EventLoop。主Reactor只有一个，只负责监听新的连接，accept后将这个连接分配到子Reactor上。子Reactor可以有多个。这样可以分摊一个Eventloop的压力，性能方面可能会更好。如下图所示：</p><p><img src="/img/reactor/main_sub_reactor.jpg" alt="主从Reactor模式"></p><p>在muduo中也可以支持主从Reactor，其中主Reactor的EventLoop就是TcpServer的构造函数中的<code>EventLoop*</code>参数。Acceptor会在此EventLoop中运行。</p><p>而子Reactor可以通过<code>TcpServer::setThreadNum(int)</code>来设置其个数。因为一个Eventloop只能在一个线程中运行，所以线程的个数就是子Reactor的个数。</p><p>如果设置了子Reactor，新的连接会通过Round Robin的方式分配给其中一个EventLoop来管理。如果没有设置子Reactor，则是默认的单线程模型，新的连接会再由主Reactor进行管理。</p><p>但其实这里似乎有些不合适的地方：多个TcpServer之间可以共享同一个主EventLoop，但是子Eventloop线程池却不能共享，这个是每个TcpServer独有的。<br>这里不太清楚是muduo的设计问题，还是作者有意为之。不过netty的主EventLoop和子Eventloop池都是可以共享的。</p><h2 id="业务线程池"><a href="#业务线程池" class="headerlink" title="业务线程池"></a>业务线程池</h2><p>对于一些阻塞型或者耗时型的任务，例如MySQL操作等。这些显然是不能放在IO线程（即EventLoop所在的线程）中运行的，因为会严重影响EventLoop的正常运行。具体原理可以查看<a href="http://www.cyhone.com/articles/reunderstanding-of-non-blocking-io/">另外一篇博客</a>。</p><p>对于这类耗时型的任务，一般做法是可以放在另外单独线程池中运行，这样就不会阻塞IO线程的运行了。我们一般把这种处理耗时任务的线程叫做Worker线程。</p><p>muduo本身没有提供一套直接使用Worker线程池的方式，但是muduo本身提供了线程池的相关类<code>ThreadPool</code>。muduo官方的推荐做法是，在OnMessage中，自行进行包的切分，然后将数据和对应的处理函数打包成Task的方式提交给线程池。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>个人认为，muduo源码对于学习网络编程和项目设计非常有帮助, 里面几乎包含了大部分网络编程和框架设计的最佳实践，配合《Linux多线程服务器端编程》一书，可以学到很多东西。<br>基于这几个方面来说，muduo绝对是一个值得一探究竟的优质源码。<br>此外，不但是网络编程方面，如何将复杂的底层细节封装好，暴露出友好的通用业务层接口，如何设计类的职责，对象的生命周期管理等方面，muduo都给了我们一个很好的示范。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《Linux多线程服务器端编程》</li><li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf" target="_blank" rel="noopener">Scalable IO in Java</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/chenshuo/muduo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;muduo&lt;/a&gt;是&lt;a href=&quot;http://chenshuo.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;陈硕&lt;/a&gt;大神个人开发的C++的TCP网络编程库。muduo基于Reactor模式实现。Reactor模式也是目前大多数Linux端高性能网络编程框架和网络应用所选择的主要架构，例如内存数据库Redis和Java的Netty库等。&lt;/p&gt;
&lt;p&gt;陈硕的《Linux多线程服务器端编程》一书对muduo整个架构进行了非常详尽的介绍和分析，可以说是学习muduo源码和设计理念最好的资料了。这本书也非常推荐大家购买阅读，感觉是后台开发的必读书目了。&lt;/p&gt;
&lt;p&gt;而本文则主要是从源码角度辅助理解整个muduo的实现，同时也姑且算是对muduo的一个小小的补充。&lt;/p&gt;
&lt;p&gt;同时我也提供了一个&lt;a href=&quot;https://github.com/chenyahui/AnnotatedCode/tree/master/muduo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;muduo注释版&lt;/a&gt;，用以辅助理解muduo的源码。&lt;br&gt;
    
    </summary>
    
      <category term="网络编程" scheme="http://www.cyhone.com/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="源码" scheme="http://www.cyhone.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="TCP" scheme="http://www.cyhone.com/tags/TCP/"/>
    
      <category term="网络编程" scheme="http://www.cyhone.com/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Reactor" scheme="http://www.cyhone.com/tags/Reactor/"/>
    
  </entry>
  
  <entry>
    <title>自动生成数据库文档小工具的诞生</title>
    <link href="http://www.cyhone.com/articles/db-doc-generator/"/>
    <id>http://www.cyhone.com/articles/db-doc-generator/</id>
    <published>2018-01-30T11:00:54.000Z</published>
    <updated>2019-11-03T09:22:16.606Z</updated>
    
    <content type="html"><![CDATA[<p>最近我用Golang开发了一个可以将数据库每张表的各个列信息转化成文档的小工具。开发的缘由是因为写后端时，经常需要为数据库写说明文档，对于稍微有些规模的项目来说，就动辄几十张上百张数据表，开发人员在文档中不断的写各个列的列名、类型、描述实在是无聊、枯燥和苦不堪言。所以就有了这个小工具的诞生。</p><p>项目地址在<a href="https://github.com/chenyahui/db_doc_generator" target="_blank" rel="noopener">这里</a><br><a id="more"></a></p><h1 id="工具使用介绍"><a href="#工具使用介绍" class="headerlink" title="工具使用介绍"></a>工具使用介绍</h1><p>工具用golang开发的，所以直接使用release的可执行文件就可以, 无需复杂任何编译安装。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dbdoc -c config.json</span><br></pre></td></tr></table></figure></p><p>在config.json文件中，按照格式配置好数据库信息，具体的配置方法如下:<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"db_info"</span>: &#123;</span><br><span class="line">    "db_type": "mysql",  // required</span><br><span class="line">    "ip_port": "127.0.0.1:3306", // required</span><br><span class="line">    "username": "root", // required</span><br><span class="line">    "password": "", // required</span><br><span class="line">    "schema": "cms" // required</span><br><span class="line">  &#125;,</span><br><span class="line">  "includes": [  // optional</span><br><span class="line">  ],</span><br><span class="line">  "excludes": [  // optional</span><br><span class="line">  ],</span><br><span class="line">  "template_path": "", // optional</span><br><span class="line">  "out_path": ""  // optional</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>简单两步，就可以自动生成数据库的说明文档了。如下图<br><img src="/img/db_doc/markdown_preview.png" alt="展示图"></p><p>展示图中的文档模板是使用工具内置的markdown模板</p><h1 id="开发过程"><a href="#开发过程" class="headerlink" title="开发过程"></a>开发过程</h1><p>整个项目的思路其实非常简单，说起来其实就三步</p><ol><li>读取数据库的各个表</li><li>依次读取每个表的列信息</li><li>将列信息转化成markdown</li></ol><p>虽然步骤简单，但是还是有些值得谈的东西。</p><h2 id="数据库适配"><a href="#数据库适配" class="headerlink" title="数据库适配"></a>数据库适配</h2><p>目前这个小工具支持MySQL和SQL Server, 这俩数据库在SQL语句上有着很大的区别。比如<br>MySQL的读取当前数据库下的所有表名的语句是<code>show tables</code>，而SQL Server的是<code>SELECT Distinct TABLE_NAME FROM information_schema.TABLES</code>。除此之外，两个数据库的连接语句，查询列信息的语句，都有很大区别。<br>所以适配各个数据库，让这个工具支持多个数据库，是件非常复杂的事情。</p><p>我目前的做法给每个用到的SQL语句做一个工厂方法，给定一个数据库的类型，返回对应的sql语句。这种方法虽然复杂繁琐，但是有效。好在我们用到的SQL语句也不多，所以效率上也算还好。</p><p>目前还在调研各大ORM库是怎么实现的这个功能。这个也是以后着重要做的功能。</p><h2 id="文档模板"><a href="#文档模板" class="headerlink" title="文档模板"></a>文档模板</h2><p>我最初的本意是直接将信息转化成固定的markdown格式就可以了，想想既然都提取了表信息为何不做些更自由的做法——用户可以自己定义文档的格式。<br>比如，这个工具默认生成的格式是这样的:<br><img src="/img/db_doc/markdown_preview.png" alt="markdown_preview"></p><p>但是万一用户不想用这个格式，想给每个表格的标题加个编号，或者给每一列加个编号啥的。那这个工具生成的结果就完全没法用了。<br>不能将我的喜好强加给用户，那么，可以给用户提供足够自由的接口。</p><p>所以我提供了一个扩展的做法, 用户可以在配置文件的<code>template_path</code>项，配置一个自己定义的文档模板给工具。如果不提供的话，可以使用默认的模板，如下:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;- .schema&#125;&#125; Document</span><br><span class="line">&#123;&#123;range .tables -&#125;&#125;</span><br><span class="line"># &#123;&#123;.TableName&#125;&#125;</span><br><span class="line">|column|type|description|</span><br><span class="line">| ------| ------ | ------ |</span><br><span class="line">&#123;&#123;- range .Columns&#125;&#125;</span><br><span class="line">|&#123;&#123;.ColumnName&#125;&#125;|&#123;&#123;.ColumnType&#125;&#125;|&#123;&#123;.Description -&#125;&#125;|</span><br><span class="line">&#123;&#123;- end&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>这个模板的语法直接用的是golang标准库的<code>text/template</code>, 文档在<a href="https://golang.org/pkg/text/template/" target="_blank" rel="noopener">这里</a>。开始我本来想着随便搜个模板引擎用下，没想到golang直接在标准库里自带了。再次感叹下golang真是为工业化而生。</p><p>有了这个文档模板的功能，这个工具的想象空间变得很大。文档的格式不再局限于markdown了，用户可以随便定义文档的格式, html、json都行。当然word的doc格式就是另外一个次元的事情了，我也在考虑是否以后加入进去。</p><h2 id="以后要加的功能"><a href="#以后要加的功能" class="headerlink" title="以后要加的功能"></a>以后要加的功能</h2><ul><li>支持更多的数据库.</li><li>支持导出格式为Word、Excel.</li><li>更人性化的命令行接口。目前我为了图省事，就直接传了个-c。后期打算做成MySQL那样直观的接口</li></ul><h1 id="谈谈Golang"><a href="#谈谈Golang" class="headerlink" title="谈谈Golang"></a>谈谈Golang</h1><p>这个项目是我用Golang做的第一个项目，Golang在这种跨平台小工具，且完全无需考虑安装依赖的情况下是最好的选择了。Golang的熟悉之后用起来几乎和Python一样快速。我在<code>文档模板</code>一节感叹，Golang真是为工业化而生，把很多在其他语言里是三方库的东西直接做到了标准库。但是另一方面，由于Golang中模板和泛型的缺失，有些东西本该内置的又没有了。比如判断一个元素是否在数组中的方法InArray,String的IsBlank方法，都需要用户在项目中再单独写一遍。实在是无法理解</p><p>总而言之，如果以后有类似的小工具的需求，我依然会选择Golang或者Python作为首选的开发语言。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近我用Golang开发了一个可以将数据库每张表的各个列信息转化成文档的小工具。开发的缘由是因为写后端时，经常需要为数据库写说明文档，对于稍微有些规模的项目来说，就动辄几十张上百张数据表，开发人员在文档中不断的写各个列的列名、类型、描述实在是无聊、枯燥和苦不堪言。所以就有了这个小工具的诞生。&lt;/p&gt;
&lt;p&gt;项目地址在&lt;a href=&quot;https://github.com/chenyahui/db_doc_generator&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="Golang" scheme="http://www.cyhone.com/tags/Golang/"/>
    
      <category term="数据库" scheme="http://www.cyhone.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>2017年读了哪些书？</title>
    <link href="http://www.cyhone.com/articles/2017-reading-records/"/>
    <id>http://www.cyhone.com/articles/2017-reading-records/</id>
    <published>2018-01-03T06:00:54.000Z</published>
    <updated>2019-11-03T09:22:16.602Z</updated>
    
    <content type="html"><![CDATA[<p>2017年总共阅读了21本书，相比于2016年减少了4本。<br>今年读的这些书相对于去年来说种类比较全而且质量比较高, 但是有一个非常大的缺点就是没有留下可用的笔记，尤其是像《北宋名家词选讲》这种书，没有好的笔记留下，书里的精髓就会流失很多。<br>希望2018年的阅读能够做到以下几点:</p><ol><li>读的每本非小说类书，都要认真的做笔记或者思维图</li><li>2018年可以阅读30本书以上</li><li>多把空闲时间放在用kindle读书上</li></ol><a id="more"></a><h2 id="计算机-1本"><a href="#计算机-1本" class="headerlink" title="计算机 (1本)"></a>计算机 (1本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/25723064/" target="_blank" rel="noopener">大型网站技术架构</a></td><td>四星</td><td>2017-01-07</td><td>这本书是一本很好的网站架构科普读物。虽然薄薄的一本书，但是方方面面也都涉及。在一致性Hash、分布式Session方面都讲的蛮清楚</td></tr></tbody></table><h2 id="思想-3本"><a href="#思想-3本" class="headerlink" title="思想 (3本)"></a>思想 (3本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/26895993/" target="_blank" rel="noopener">刻意练习</a></td><td>五星</td><td>2017-01-17</td><td>对我而言这本书的意义有三点：1. 打破“天才论” 2. 辩证看待“一万小时专家理论” 3.用于教育界或者自教育</td></tr><tr><td><a href="https://book.douban.com/subject/25985021/" target="_blank" rel="noopener">人类简史</a></td><td>五星</td><td>2017-02-15</td><td>19分的好书。9分给原著，10分给翻译。完全感觉不到这是本经过翻译的书！一本开了卫星视角的书，看完后刷新了世界观。</td></tr><tr><td><a href="https://book.douban.com/subject/25928708/" target="_blank" rel="noopener">佛祖都说了些什么</a></td><td>五星</td><td>2017-03-19</td><td>语言非常的轻松诙谐。对于了解佛教的历史、宗派、思想非常有益。很明显地可以看出来作者是个唯物主义者，这使得这本书在整体气质上与佛教徒所写的书有本质的区别。</td></tr></tbody></table><h2 id="历史-传记-6本"><a href="#历史-传记-6本" class="headerlink" title="历史/传记 (6本)"></a>历史/传记 (6本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/3239549/" target="_blank" rel="noopener">夹边沟记事</a></td><td>五星</td><td>2017-01-26</td><td>荒唐时代的牺牲品。一段不应该被忘记的历史</td></tr><tr><td><a href="https://book.douban.com/subject/26819435/" target="_blank" rel="noopener">胡适四十自述</a></td><td>五星</td><td>2017-01-05</td><td>大师的自传满满的真情实感。在传记中，经常能够代入式的感受到同样的迷茫与坚持</td></tr><tr><td><a href="https://book.douban.com/subject/6538430/" target="_blank" rel="noopener">人类群星闪耀时</a></td><td>五星</td><td>2017-02-13</td><td>不同于一般的传记，茨威格列举的十四位人类群星，在勇敢、努力这些词之前更强调命运和上帝。此外语句翻译的也非常有力</td></tr><tr><td><a href="https://book.douban.com/subject/26291984/" target="_blank" rel="noopener">最后的耍猴人</a></td><td>四星</td><td>2017-03-20</td><td>“和你们这些少爷不同,我们光是活着就已经拼尽全力了”</td></tr><tr><td><a href="https://book.douban.com/subject/26872888/" target="_blank" rel="noopener">人类砍头小史</a></td><td>四星</td><td>2017-09-03</td><td>非常冷静地、近距离地打量头颅，不背过身正视它。砍头史是人类的文明史</td></tr><tr><td><a href="https://book.douban.com/subject/26698660/" target="_blank" rel="noopener">巨人的陨落</a></td><td>五星</td><td>2017-12-03</td></tr></tbody></table><h2 id="随笔-2本"><a href="#随笔-2本" class="headerlink" title="随笔 (2本)"></a>随笔 (2本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/6126821/" target="_blank" rel="noopener">远方的鼓声</a></td><td>四星</td><td>2017-04-24</td><td>以人为主的游记书，很好。一个旅行者最渴望的大概也是可以在旅行的地方长住一个月到一年，而非走马观花式的旅游</td></tr><tr><td><a href="https://book.douban.com/subject/10826904/" target="_blank" rel="noopener">蒙田随笔集</a></td><td>五星</td><td>2017-06-10</td><td>很明显蒙田是一个喜欢和自己对话的人，看这本书的时候几乎可以看到他思考的轨迹。有种和良师益友交谈的感觉</td></tr></tbody></table><h2 id="小说-8本"><a href="#小说-8本" class="headerlink" title="小说 (8本)"></a>小说 (8本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/26892084/" target="_blank" rel="noopener">降临(特德.姜小说集)</a></td><td>五星</td><td>2017-02-24</td><td>特德·姜的八篇小说，每一篇的立意毫无重复，每一篇都是精琢的艺术品。用科幻来定义他的小说实在是太狭隘了</td></tr><tr><td><a href="https://book.douban.com/subject/26839300/" target="_blank" rel="noopener">局外人</a></td><td>五星</td><td>2017-04-25</td><td>一直想读加缪的书，这是第一本。在我看来，主人公默尔索是一个坦诚的、拒绝伪饰感情的真实的人。“人生在世，永远也不该演戏作假”</td></tr><tr><td><a href="https://book.douban.com/subject/26416777/" target="_blank" rel="noopener">罗生门</a></td><td>五星</td><td>2017-04-27</td><td>看完这本书永远的记住了芥川龙之介这个绕口的名字。非常喜欢《竹林中》一篇，短短的故事可以把人性描述得淋漓尽致。有机会要找来黑泽明的《罗生门》片子看看。</td></tr><tr><td><a href="https://book.douban.com/subject/6518605/" target="_blank" rel="noopener">三体</a></td><td>五星</td><td>2017-07-12</td><td>高三毕业后用小屏功能机看完了前两部，以为最后罗辑用黑暗森林法则要挟三体人而地球获救是最终结局。最后重看时发现了第三部死神永生。如果说前两部中人类总是化险为夷，第三部中大刘直接毁了整个宇宙。印象最深的是一幕智子用滴血的武士刀指着人类，“人类自由堕落的时代结束了，要想活下去，必须重新拾起人的尊严”。我想这应该也是大刘的想法</td></tr><tr><td><a href="https://book.douban.com/subject/3266609/" target="_blank" rel="noopener">流浪地球</a></td><td>四星</td><td>2017-08-04</td><td>据说要拍成电影了，有些期待。整部书的水平当然不如三体，但是还是可以看的</td></tr><tr><td><a href="https://book.douban.com/subject/3266609/" target="_blank" rel="noopener">十日谈</a></td><td>三星</td><td>2017-09-24</td><td></td></tr><tr><td><a href="https://book.douban.com/subject/20473505/" target="_blank" rel="noopener">山月记</a></td><td>四星</td><td></td><td></td></tr><tr><td><a href="https://book.douban.com/subject/4105446/" target="_blank" rel="noopener">十一种孤独</a></td><td>四星</td><td>2017-10-25</td><td>每个人有每个人的孤独</td></tr></tbody></table><h2 id="诗词-1本"><a href="#诗词-1本" class="headerlink" title="诗词 (1本)"></a>诗词 (1本)</h2><table><thead><tr><th>书名</th><th>推荐程度</th><th>合卷日期</th><th>评价</th></tr></thead><tbody><tr><td><a href="https://book.douban.com/subject/2005704/" target="_blank" rel="noopener">北宋名家词选讲</a></td><td>五星</td><td>2017-06-26</td><td>想要把它推荐给所有爱词的人。我认为它的定位是诗词启蒙、美感启蒙与中国古典文化的启蒙。非常赞同叶嘉莹先生两点。1. 宋词的美感绝不仅在于意向，而在于音律。2. 要读懂一首词的前提是需要了解作词人的生平</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2017年总共阅读了21本书，相比于2016年减少了4本。&lt;br&gt;今年读的这些书相对于去年来说种类比较全而且质量比较高, 但是有一个非常大的缺点就是没有留下可用的笔记，尤其是像《北宋名家词选讲》这种书，没有好的笔记留下，书里的精髓就会流失很多。&lt;br&gt;希望2018年的阅读能够做到以下几点:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;读的每本非小说类书，都要认真的做笔记或者思维图&lt;/li&gt;
&lt;li&gt;2018年可以阅读30本书以上&lt;/li&gt;
&lt;li&gt;多把空闲时间放在用kindle读书上&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="生活和思考" scheme="http://www.cyhone.com/categories/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E8%80%83/"/>
    
    
      <category term="读书" scheme="http://www.cyhone.com/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>ClassViewer的介绍及实现</title>
    <link href="http://www.cyhone.com/articles/classviewer/"/>
    <id>http://www.cyhone.com/articles/classviewer/</id>
    <published>2018-01-01T03:45:00.000Z</published>
    <updated>2019-11-03T09:22:16.602Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://chenyahui.github.io/ClassViewer" target="_blank" rel="noopener">ClassViewer</a>是我最近开发的一个用于展示jvm class字节码的小工具。它是一个单纯的静态网页，完全使用浏览器端的Javascript开发。之所以开发这款工具，是因为我在开发<a href="https://github.com/chenyahui/ToyJVM" target="_blank" rel="noopener">ToyJVM</a>的时候，需要常常校验class文件某一部分的字节码, 所以如果一款工具能够很方便的显示class文件各个部分的信息和字节码，对于ToyJVM的开发将会是一个非常大的帮助。</p><p>在开始写代码之前调研了一些类似的产品，主要有jdk自带的javap、国外的Java-Class-Viewer以及国人开发的classpy，它们都是非常不错的class文件分析工具，但是也存在着一些算不上缺陷的小问题。所以最终还是决定自己写一个适合自己小工具，同时也加深下class结构的理解。</p><p>在调研了目前的产品后，我也更加清晰了自己的目标。首先它的受众应该是有兴趣研究jvm的程序员，而它应该有这些特性:</p><ul><li>不依赖于特定操作系统平台<br>它应该具备基本的跨平台的能力，因为程序员的Mac和Linux使用率很高。</li><li>无需复杂的安装和编译，无需用户有特定的知识背景<br>我不太希望用户拿到我的代码后，还需要安装相应的环境、了解一堆无关知识。</li></ul><p>最终实现出来的工具是这样的:<br><a id="more"></a><br><img src="/img/classviewer/welcome.png" alt="welcome"><br><img src="/img/classviewer/show.png" alt="show"></p><h2 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h2><p>基于浏览器来实现这个工具是非常符合我的需求的。首先网页跨平台能力是毋庸置疑的，只要有浏览器的电脑就可以运行这个工具。<br>其次，它不需要任何的编译和安装，也不需要用户有任何的背景知识才能使用。只要在Github下载好源码，在浏览器中打开index.html就可以运行使用。或者，直接访问<a href="https://chenyahui.github.io/ClassViewer" target="_blank" rel="noopener">Github Page</a>。所以我在开发这个工具的时候完全没有使用后台，也避免使用了各种前端工具链，尽可能的降低使用的复杂度。<br>我在开发中大量使用了ES6的特性，比如let、模板字符串、类等和ES7中的async。这是因为我实在是对ES5及其之前的js语法提不起太多兴趣，用起来实在是不爽。好在ES6提供了许多语法糖，解决了很多问题，用起来也算顺手。<br>也正因为我使用了一些ES6的特性，导致这个工具在低版本的浏览器上无法work。这个问题后期也没打算解决，因为我认为程序员的浏览器应该都会支持这些特性。</p><p>使用JavaScript开发还有个问题就是，js里面没有int、short和无符号类型，所有数字都是统一使用Number类型表示了。而对jvm的分析需要严格地按读取每个字节来说，是个非常头疼的问题。<br>好在ES6提供了ArrayBuffer和DataView，可以方便的实现这些功能。</p><h2 id="Class文件的解析"><a href="#Class文件的解析" class="headerlink" title="Class文件的解析"></a>Class文件的解析</h2><p>在官方的<a href="https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf" target="_blank" rel="noopener">JVM S8标准</a>的第四章中，给出了Class文件的格式结构。我们可以根据jvm标准来严格读取字节。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClassFile &#123;</span><br><span class="line">    u4 magic;</span><br><span class="line">    u2 minor_version;</span><br><span class="line">    u2 major_version;</span><br><span class="line">    u2 constant_pool_count;</span><br><span class="line">    cp_info constant_pool[constant_pool_count-<span class="number">1</span>];</span><br><span class="line">    u2 access_flags;</span><br><span class="line">    u2 this_class;</span><br><span class="line">    u2 super_class;</span><br><span class="line">    u2 interfaces_count;</span><br><span class="line">    u2 interfaces[interfaces_count];</span><br><span class="line">    u2 fields_count;</span><br><span class="line">    field_info fields[fields_count];</span><br><span class="line">    u2 methods_count;</span><br><span class="line">    method_info methods[methods_count];</span><br><span class="line">    u2 attributes_count;</span><br><span class="line">    attribute_info attributes[attributes_count];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码定义了从上到下依次每部分的字节大小。<br>如果仔细看下这个结构定义，发现大部分数据都以u2、u4定义。其中u4、u2分别代表该部分占据4个字节和2个字节。比如class文件的前4字节，代表了magic这部分。接下来的2个字节代表了minor_version。对于这种类型的数据，我们只要简单读取对应数目的字节就可以了。<br>但是还有两部分特殊的定义: <code>cp_info</code>和<code>attribute_info</code>。它们都属于复合结构，可以理解为<code>struct</code>。<br>其中<code>cp_info constant_pool[constant_pool_count-1]</code>代表常量池，共有<code>constant_pool_count-1</code>项，每一项都是一个cp_info结构的数据。cp_info的结构定义如下</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">cp_info&#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    data..</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>cp_info</code>包含多种类型的数据，比如<code>CONSTANT_Class_info</code>、<code>CONSTANT_String_Info</code>等，在jvms8中定义了14种cp_info。每个cp_info的第一个字节都以1个字节的tag开头，代表了这个cp_info的类型。接下来每种cp_info各自的数据都不一样，比如<code>CONSTANT_Class_info</code>和<code>CONSTANT_Integer_info</code>的定义如下:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CONSTANT_Class_info &#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    u2 name_index;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CONSTANT_Integer_info &#123;</span><br><span class="line">    u1 tag;</span><br><span class="line">    u4 bytes;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>CONSTANT_Class_info代表在tag后，有2个字节的name_index，就读取结束了。而CONSTANT_Integer_info在tag后有4个字节才能读取结束。<br>对于这种常量池的解析来说，一种最直观的方法是可以这么做:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; constant_pool_count; i++)&#123;</span><br><span class="line">   u1 tag = read <span class="number">1</span> <span class="keyword">byte</span></span><br><span class="line">   <span class="keyword">switch</span>(tag)&#123;</span><br><span class="line">       <span class="keyword">case</span> CONSTANT_Class_info:</span><br><span class="line">        read <span class="number">2</span> <span class="keyword">byte</span></span><br><span class="line">       <span class="keyword">case</span> CONSTANT_Integer_info:</span><br><span class="line">        read <span class="number">4</span> <span class="keyword">byte</span></span><br><span class="line">       ...</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>由于我们后期要用到cp_info的每个字段，所以需要把每个<code>cp_info</code>的定义表示为一个类。使用工厂方法来根据tag生成相应的对象，将读取的部分包含在各自类的read方法中。代码如下:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">cp_info <span class="title">cpInfoFactory</span><span class="params">(u1 tag)</span></span>&#123;</span><br><span class="line">    <span class="keyword">switch</span>(tag)&#123;</span><br><span class="line">         <span class="keyword">case</span> CONSTANT_Class_info:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ConstClassInfo();</span><br><span class="line">         <span class="keyword">case</span> CONSTANT_Integer_info:</span><br><span class="line">             <span class="keyword">return</span> <span class="keyword">new</span> ConstClassInfo();</span><br><span class="line">         ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cp_info info = cpInfoFactory(tag)</span><br><span class="line">info.read()</span><br></pre></td></tr></table></figure></p><p>目前这样看起来似乎我们只需要为cp_info定义14种不同的类，然后在类中为每个不同的cp_info定义不同的读取方法即可。<br>我目前在ToyJVM中是这么做的，但是这么做有个问题就是太繁琐了。我们需要为每个类定义不同的属性，然后在read方法中为这些属性读取不同的字节，极易出现编写错误。一旦一个字节读取错误，就会导致后面的字节全部错误。<br>由于ClassViewer采用了js实现，可以使用eval动态定义变量。我采用了这么一种做法，来简化constant_pool的读取:<br><figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    read(reader)&#123;</span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.properties.length; i += <span class="number">2</span>) &#123;</span><br><span class="line">               <span class="keyword">let</span> len = <span class="keyword">this</span>.properties[i]</span><br><span class="line">               <span class="keyword">let</span> property = <span class="keyword">this</span>.properties[i + <span class="number">1</span>]</span><br><span class="line">               <span class="built_in">eval</span>(<span class="string">`this.<span class="subst">$&#123;property&#125;</span> = reader.read(<span class="subst">$&#123;len&#125;</span>)`</span>)</span><br><span class="line">         &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstClassInfo</span> <span class="keyword">extends</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.properties = [</span><br><span class="line">            <span class="number">2</span>, <span class="string">'name_index'</span>,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstFieldRefInfo</span> <span class="keyword">extends</span> <span class="title">BaseCpInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">constructor</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>.properties = [</span><br><span class="line">            <span class="number">2</span>, <span class="string">"class_index"</span>,</span><br><span class="line">            <span class="number">2</span>, <span class="string">"name_and_type_index"</span>,</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>首先在这里我定义了一个BaseCpInfo,作为所有cp_info的类。在子类中，只需要在this.properties定义相关字段的名称和字节长度就可以。在read的时候，使用父类公共的read方法，使用eval为每个子类读取字段内容。<br>这里需要注意的是，this.properties我使用了数组来实现，而非字典。是因为这些属性是必须严格有序的，不可以颠倒顺序。而字典常常使用Hash来实现，并不保证顺序。</p><p>使用这种方法子类可以不用写read方法，减少了出错的可能。对于constant_pool来说，大概可以少写14个read方法。后面attributes也采用了同样的策略，也可以少写十几个方法。这对于开发效率的提升程度还是非常客观的。</p><p>这种写法代码写起来很爽，只是有个缺点就是eval的速度实在太慢，会极大降低运行效率。但是因为写起来实在是太爽了，只要从jvm标准中把每个类型的字节信息抄过来，定义一个公共的read方法就可以了。所以在后面我也没打算把它改写成非eval方式的读写，或许有可能写一个codegen脚本，但是都是后话了。</p><h2 id="字节显示区域"><a href="#字节显示区域" class="headerlink" title="字节显示区域"></a>字节显示区域</h2><p>在预览图中可以看到，中间有一块区域用于显示Hex字节码信息，这是一块超大的排列整齐的方格区域，用普通的div+css显然没法很好的实现。在我的实现中，使用了canvas绘制了字节码区域。具体代码可以参考<a href="https://github.com/chenyahui/ClassViewer/blob/master/js/ui/byte_painter.js" target="_blank" rel="noopener">byte_painter.js</a><br>除了正常的绘制之外，还实现了部分区域高亮以及滚动到指定区域的功能。</p><h2 id="左侧栏"><a href="#左侧栏" class="headerlink" title="左侧栏"></a>左侧栏</h2><p>左侧栏实际上就是直接调用了<a href="http://www.treejs.cn/v3/main.php#_zTreeInfo" target="_blank" rel="noopener">ztree</a>。在<a href="https://github.com/chenyahui/ClassViewer/blob/master/js/ui/class_to_ztree.js" target="_blank" rel="noopener">class_to_ztree.js</a>中，将读取到的class文件转换成了ztree的node节点。</p><p>为什么要特意提下左侧栏。哈哈，因为我是jetbtrains粉，特意从jetbrians官网上找了IDE中的<a href="https://www.jetbrains.com/help/idea/symbols.html" target="_blank" rel="noopener">符号图标</a>，替换了ztree的默认样式，算是对jetbrains的一个小小的致敬吧！</p><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>目前ClassViewer的初版已经发布，可以直接<a href="https://chenyahui.github.io/ClassViewer/" target="_blank" rel="noopener">通过Github Page查看页面</a>或者直接<a href="https://github.com/chenyahui/ClassViewer" target="_blank" rel="noopener">在Github上查看源码</a>。接下来我会继续把开发重心放在ToyJVM上，但同时也会抽时间继续优化ClassViewer的使用体验。</p><p>接下的开发方向主要会集中在以下几点:</p><ul><li>Method的字节码信息展示<br>当用户点击了method的时候，直接在中间区域显示对应的jvm命令。这部分需要对jvm的命令进行解析，相应的功能我在ToyJVM中做过一遍，所以这个会是首选的实现功能。</li><li>Index之间跳转<br>jvm中很多部分都是直接给了一个index。比如this_class，就是给了一个2个字节的index，这个index表示<code>constant_pool</code>某一项的索引，这一项必须是<code>CONSTANT_Class_info</code>类型的。诸如此类，所以打算做一个可以根据index跳转对应真实数据的功能。</li><li>支持jar包的解析<br>故名思意，可以直接解析jar包。jar包可以理解成一个zip压缩包，里面是一堆的class文件。所以这里我可能要借助第三方的js的zip解析包来实现。</li><li>jvm s9的支持<br>目前的ClassViewer是根据jvms8来实现的，接下来会跟进jvm s9的标准。</li><li>Java modified UTF8的解析<br>JVM对标准UTF8进行了一些轻微的修改，称为M-UTF8。我目前的实现都是直接使用标准的UTF8来解析的，这么做可以适合大部分的场景，对于一些特定字符会有问题，接下来会对这部分进行处理。</li></ul><p>有感兴趣的可以和我一起跟进这个项目。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>开发这个工具的最大目的还是自用，实现一个适合自己和大部分人的Class字节码工具，除此之外也是对JVM class的进一步的研究。这个项目如果继续深入下去，甚至可以使用js来实现一个玩具版的虚拟机。但是对我来说没必要了，我会把对JVM的实现都放在<a href="https://github.com/chenyahui/ToyJVM" target="_blank" rel="noopener">ToyJVM</a>中。</p><p>我在开发过程中最初打算尽可能地不依赖任何三方库，以便界面和功能上更贴近自己的体验。但是个人的能力始终有限，把时间花在工具的核心内容之外，实在有些得不偿失。所以还是用了一些开源项目，比如使用ztree实现了左侧信息栏，iziModal实现了遮罩层，也用了fontawesome的一些图标来美化界面。最后也非常感谢这些项目对ClassViewer的帮助。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://chenyahui.github.io/ClassViewer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ClassViewer&lt;/a&gt;是我最近开发的一个用于展示jvm class字节码的小工具。它是一个单纯的静态网页，完全使用浏览器端的Javascript开发。之所以开发这款工具，是因为我在开发&lt;a href=&quot;https://github.com/chenyahui/ToyJVM&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ToyJVM&lt;/a&gt;的时候，需要常常校验class文件某一部分的字节码, 所以如果一款工具能够很方便的显示class文件各个部分的信息和字节码，对于ToyJVM的开发将会是一个非常大的帮助。&lt;/p&gt;
&lt;p&gt;在开始写代码之前调研了一些类似的产品，主要有jdk自带的javap、国外的Java-Class-Viewer以及国人开发的classpy，它们都是非常不错的class文件分析工具，但是也存在着一些算不上缺陷的小问题。所以最终还是决定自己写一个适合自己小工具，同时也加深下class结构的理解。&lt;/p&gt;
&lt;p&gt;在调研了目前的产品后，我也更加清晰了自己的目标。首先它的受众应该是有兴趣研究jvm的程序员，而它应该有这些特性:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不依赖于特定操作系统平台&lt;br&gt;它应该具备基本的跨平台的能力，因为程序员的Mac和Linux使用率很高。&lt;/li&gt;
&lt;li&gt;无需复杂的安装和编译，无需用户有特定的知识背景&lt;br&gt;我不太希望用户拿到我的代码后，还需要安装相应的环境、了解一堆无关知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终实现出来的工具是这样的:&lt;br&gt;
    
    </summary>
    
      <category term="开发经验" scheme="http://www.cyhone.com/categories/%E5%BC%80%E5%8F%91%E7%BB%8F%E9%AA%8C/"/>
    
    
      <category term="JVM" scheme="http://www.cyhone.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>首次半马记</title>
    <link href="http://www.cyhone.com/articles/my-first-half-marathon/"/>
    <id>http://www.cyhone.com/articles/my-first-half-marathon/</id>
    <published>2017-04-17T14:20:47.000Z</published>
    <updated>2019-10-10T06:02:57.090Z</updated>
    
    <content type="html"><![CDATA[<p>4月9号，在武汉参加了人生第一次半程马拉松，风里雨里的21.0975公里。虽然已时隔一周，但想到那天一路的奔跑、疲惫、欣喜，还是想记记这半马的流水账。<br><a id="more"></a> </p><h1 id="赛前训练"><a href="#赛前训练" class="headerlink" title="赛前训练"></a>赛前训练</h1><p>关于赛前训练这一块，我自己真的是非常的汗颜，被自己的记性给坑了一把。本来4月9号的马拉松，硬是记成了5月9号。所以本来安排的提前1个月训练半马，也恰好完美地错过。汉马马拉松官网提前10天发送了备赛的消息，我还在想提前40天就发消息会不会太早，直到赛前一周的时候去东湖玩看到了路上马拉松赛道的标牌，才知道记错了时间。。</p><p>但是由于我这几年一直有跑步的习惯，基本不下雨的晚上都会去跑个5km(虽然武汉下雨的天气居多…)，之前也有跑过10km，1个小时左右的水平，所以对于三个小时完赛21km还是比较有信心的。<br>在野心勃勃地列了赛前一周训练计划后，伴随着武汉连绵一周的阴雨，基本我的赛前训练计划就这么泡汤了。</p><p><img src="/img/emoji/emoji2.jpg" width="200" height="200px" style="margin-left:auto;margin-right:auto;"></p><p>比赛时间是周日，虽然天公不作美，还是在周三晚上停雨的间歇跑个了5km，周五晚上跑了3km热了身，就这么草率地开始我的半马历程。</p><p>言归正传，对于普通的业余跑者如我来说，至少要留足一个月的时间去准备马拉松，训练多次10km，至少一次半程马拉松的模拟，学习充足热身、恢复知识，才具备跑半马的资格。<br>要不然都像我今天这样右脚贴着膏药坐电脑打字总归是不好的。</p><h1 id="比赛前夕的准备"><a href="#比赛前夕的准备" class="headerlink" title="比赛前夕的准备"></a>比赛前夕的准备</h1><h2 id="饮食"><a href="#饮食" class="headerlink" title="饮食"></a>饮食</h2><p>虽然咱练得不行，但起码得吃好。。</p><p>赛前饮食还是需要十分注意的，少油腻、多能量的摄入,不至于赛前精神的萎靡。在赛前三天每天也都要多喝水，每天保证2L的水，让身体充满水。</p><h2 id="住宿与交通"><a href="#住宿与交通" class="headerlink" title="住宿与交通"></a>住宿与交通</h2><p>关于住宿这一块，如果想要住到赛点周围，要至少提前一周甚至更早预定，要不然只剩下比平常贵几倍或者是比较远的酒店了。</p><p>同时，武汉当天的公交、地铁也都会提前开放，这是武汉马拉松官网赛前给我发的短信。</p><blockquote><p>【武汉马拉松】温馨提示：4月9日比赛日当天，参赛选手可凭号码布，免费乘公交、地铁和轮渡。建议乘坐地铁2号线和6号线抵达起点附近江汉路站，全程和半程选手从地铁C口出，13公里跑选手从地铁B口出。其中2、6号线运营始发时间调整为5:30，提前一小时，祝您顺利参赛，取得好成绩。</p></blockquote><p>虽然我就在武汉住，但是想到第二天要五点爬起来吃饭赶地铁，头一天在宿舍还有睡不好的可能，还是在赛点2公里远的地方订了宾馆。</p><h2 id="装备"><a href="#装备" class="headerlink" title="装备"></a>装备</h2><p>我在周六下午去了马拉松指定的地方领取了武汉马拉松组织发的装备，主要有号码牌、短袖、存衣袋、能量胶和能量棒，天气预报说周日可能中雨，所以主办单位也准备了一次性的雨衣，这点还是很贴心的。</p><p>关于号码牌要多说一句，此次半马采用的计时芯片直接和号码牌固定到一起、一次性使用，并不是和常见的绑到鞋带上的计时芯片。我觉得一次性芯片在使用上非常方便，而且减少了芯片的发放、回收的时间，个人在跑的时候也完全不用注意芯片的事情。</p><p>此外，特步赞助的短袖穿起来非常的舒服，所以如果不是专业的跑步者，有自己的固定装备，我觉得使用赠送的统一的小黄衫就足够了。</p><p>关于鞋子，要求不漏水，平常跑起来舒服的就可以，在跑前一定要试跑下鞋子，确定鞋子的舒适度才可在半马上正式使用。</p><p>裤子方面我本来打算简单穿下之前本科发的校服配套的运动裤，周六晚上在江汉路逛的时候，被女朋友怂恿去买了一条跑步专用的运动裤，不得不说，专业的穿起来要舒服很多，我半马一路跑下来它功不可没。</p><p>赛前在京东买了一个腰袋，用来放手机，买了之后周五跑步的时候就试了下，一直后悔没有提前买，实在是太好用了除了影响颜值。</p><h2 id="线路和补给点"><a href="#线路和补给点" class="headerlink" title="线路和补给点"></a>线路和补给点</h2><p>在武汉马拉松官网上会给出线路和补给点的情况，在<a href="http://www.wuhanmarathon.org/html/saishixinxi_Event/bisaixianlu/" target="_blank" rel="noopener">这里</a>可以看到,对于首次跑马拉松的人来说，这个还是要提前记清楚，以调整自己的状态。</p><h1 id="万人雨中马拉松"><a href="#万人雨中马拉松" class="headerlink" title="万人雨中马拉松"></a>万人雨中马拉松</h1><p>头天晚上收拾好东西，记了下半马的路线图，大概9点半就入睡了，保证了7个半个小时睡眠时间，这点也是在宾馆住的优点。<br>早上五点半起床，吃了两片面包一瓶牛奶就吃不下去了，进场地前又啃了半个巧克力和一瓶红牛。关于早餐这块，我在半马后半段的时候后悔莫及。。</p><p>进入赛场后我志气满满地开始戴号码牌，咦，别针呢！我看着漏了的号码牌袋欲哭无泪，估计是来的路上把别针全丢光了。想着可能要手举着号码牌跑一路也是心累，把号码牌塞口袋跑还怎么帅帅的摆pose。<br>后来发现每个人之前发了五个别针，所以每个人会多一个。就找了还没戴号码牌的人借了1个，然后志愿者给了我两个，我最后竟然在地上又捡了一个。。凑了四个戴上号码牌终于可以帅帅地开跑了。</p><p>开跑时间是7点半，半马时间是三个小时，十点半结束。平均每10km跑1个半小时，为了留个缓冲时间，所以大概每5km需要在35分钟左右完成。</p><p>我的号码牌是D开头的，前面有A、B、C组是特邀选手和全程马拉松，后面还有E组和健康跑，在半马跑道起点的顺序上也是这么排的，全部的总人数大概是22000人。7点半枪响后，人群开始慢慢移动，话说虽然我也没听到枪响。前面的移动实在是慢，大概走了四五分钟后，人群开始疏散，我才开始慢慢跑起来。</p><p>这里要提下一次性雨衣的问题，在起点附近地上到处都是随处可见的黄色一次性雨衣，可能是选手穿上后觉得麻烦又随手扔了，但是对于后面的人来说实在很危险而且不美观，所以还是建议暂时拿到手里，等到人群疏散开后交给志愿者。</p><p>基本开始跑了之后就开始沥沥淅淅的下起了小雨，路两边加油击掌的人满满，可谓热血沸腾。同时我也提醒自己稳住速度，以免太快消耗完体力。</p><p>等到5千米时候，雨开始下大，基本到了中雨的程度，我拿出手机看了下时间，大概8点14分，已经过去了四十四分钟了，可能是在开始的时候走的太慢，浪费了很多时间。这个时候我就开始着急了，喝了一杯水后，开始稍微地提高了下速度，<br>从5km开始以后，路上不断的有补给点，每个补给点都必须要喝一杯水，尤其是下雨天，身体对水的需求更大。</p><p>在这里非常感谢汉马的各位志愿者，汉马的补给非常充足，志愿者非常热情，让我这个第一次跑马拉松的人可以完全的只用关注跑步就可以了。</p><p>10km是在武汉长江大桥上面，平常车水马龙的马路现在只剩了跑步者。但此时的雨已经属于大雨的范围了，上桥的时候鞋子基本是踩在水里的。此时鞋子衣服全部湿透了，耳机也出现了问题，这个时候才明白防水蓝牙耳机的重要性。这个时候大概过去了1个小时15分钟，时间恰好在我的控制范围内。</p><p>12km的地方是下桥后的黄鹤楼站，女朋友在那里拿着红牛和巧克力等我。但是人太多了，提前没有联系好，没找到人我就继续跑了。<br>跑到15km的时候，早上两片面包的能量基本消耗殆尽了，小腿微微的有抽筋的趋势。肚子基本饿扁了，这个时候就开始走一回，跑一会，路上遇到拉伸点也会跟着大家一起拉伸。</p><p>在剩最后1km的时候，时间还有40分钟，这个时候基本不用担心时间问题了，脚也非常的沉重，开始完全的走路的方式。</p><p>最后三百米的路段是从楚河汉街到湖北市图书馆，一路上加油的人越来越多，双脚非常沉重的走向终点线，基本跑快一点就有抽筋的趋势，我的首次半程马拉松就在平静、愉悦、疲惫和陌生人的欢呼中完成了。<br><img src="/img/half-mathron/medal.jpg" width="400" height="800px" style="margin-left:auto;margin-right:auto;"></p><h1 id="赛后"><a href="#赛后" class="headerlink" title="赛后"></a>赛后</h1><p>赛后当然是拿着手机拍拍拍和发朋友圈啊！</p><p>除了晒照还有一件事就是拉伸！尤其对于没有长期训练半马的人来说，拉伸尤为重要。我跑完之后由于没有充分的拉伸和活动，导致目前右脚有轻微的损伤。</p><p>半马一路上看到弱弱的女孩子、五六十岁的大叔大妈都有参与马拉松的，而且很多人的准备和状态都比我要好很多，村上春树也提到他在38岁的时候全马成绩大概是3小时40分钟。所以完成一次全马只是业余跑者的最入门级的水平，一次半马的经历尤为可贵，更可贵的是因为跑步、健身而获得的良好的身体技能和精神状态。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;4月9号，在武汉参加了人生第一次半程马拉松，风里雨里的21.0975公里。虽然已时隔一周，但想到那天一路的奔跑、疲惫、欣喜，还是想记记这半马的流水账。&lt;br&gt;
    
    </summary>
    
      <category term="生活和思考" scheme="http://www.cyhone.com/categories/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E8%80%83/"/>
    
    
  </entry>
  
  <entry>
    <title>结合Guava源码解读布隆过滤器</title>
    <link href="http://www.cyhone.com/articles/introduction-of-bloomfilter/"/>
    <id>http://www.cyhone.com/articles/introduction-of-bloomfilter/</id>
    <published>2017-02-07T08:51:51.000Z</published>
    <updated>2019-11-03T09:22:16.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><blockquote><p>BloomFilter（布隆过滤器）是一种可以高效地判断元素是否在某个集合中的算法。</p></blockquote><p>在很多日常场景中，都大量存在着布隆过滤器的应用。例如：检查单词是否拼写正确、网络爬虫的URL去重、黑名单检验，微博中昵称不能重复的检测等。</p><p>在工业界中，Google著名的分布式数据库BigTable也用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数；Google Chrome浏览器使用BloomFilter来判断一个网站是否为恶意网站。   </p><p>对于以上场景，可能很多人会说，用HashSet甚至简单的链表、数组做存储，然后判断是否存在不就可以了吗？</p><p>当然，对于少量数据来说，HashSet是很好的选择。但是对于海量数据来说，BloomFilter相比于其他数据结构在空间效率和时间效率方面都有着明显的优势。   </p><p>但是，布隆过滤器具有一定的误判率，有可能会将本不存在的元素判定为存在。因此，对于那些需要“零错误”的应用场景，布隆过滤器将不太适用。具体的原因将会在第二部分中介绍。<br><a id="more"></a><br>同时其他章节的安排如下：</p><ul><li>在本文的第二部分，本文将会介绍BloomFilter的基本算法思想；</li><li>第三部分将会基于Google开源库Guava来讲解BloomFilter的具体实现；</li><li>在第四部分中，将会介绍一些开源的BloomFilter的扩展，以解决目前BloomFilter的不足。</li></ul><h1 id="算法讲述"><a href="#算法讲述" class="headerlink" title="算法讲述"></a>算法讲述</h1><p>布隆过滤器是基于Hash来实现的，在学习BloomFilter之前，也需要对Hash的原理有基本的了解。个人认为，BloomFilter的总体思想实际上和bitmap很像，但是比bitmap更节省空间，误判率也更低。</p><p>BloomFilter的整体思想并不复杂，主要是使用k个Hash函数将元素映射到位向量的k个位置上面，并将这k个位置全部置为1。当查找某元素是否存在时，查找该元素所对应的k位是否全部为1即可说明该元素是否存在。</p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>BloomFilter的整体算法流程可总结为如下步骤：</p><ol><li>BloomFilter初始化为m位长度的位向量，每一位均初始化为0<br><img src="/img/bloomfilter/bf1.jpg" alt="step-1"></li><li>使用k个相互独立的Hash函数，每个Hash函数将元素映射到{1..m}的范围内，并将对应的位置为1。<br><img src="/img/bloomfilter/bf2.jpg" alt="step-2"><br>如上图所示，元素x分别被三个Hash函数映射到了三个位置8、1、14，并将这三个位置从0变为1。</li><li>若检查一个元素y是否存在，首先第一步使用k个Hash函数将元素y映射到k位。分别检测每一位是否为0。若某一位为0，则元素y一定不存在，若全部为1，则有可能存在。</li></ol><p><strong>空间复杂度</strong><br>BloomFilter 使用位向量来表示元素，而不存储本身，这样极大压缩了元素的存储空间。其空间复杂度为O(m)，m是位向量的长度。而m与插入总数量n的关系如公式$\eqref{eq:mn}$所示<br>\begin{equation}<br>  m=-{\frac {n\ln p}{(\ln 2)^{2}}} \label{eq:mn}<br>\end{equation}</p><p>我们可以利用这个公式来算一下需要抓取100万个URL时BloomFilter所占据的空间。</p><p>假设要求误判率为1%，因此该公式可转化为$m=9.6 * n$。故此时BloomFilter位向量的大小为$100w*9.6 = 960w bit$，约1.1M内存空间。<br>只需要1.1M的内存空间，就可满足100万个url的去重需求，这个空间复杂度之低不可谓不惊人。<br>实际上，哪怕是1亿个URL，也仅需100M左右的内存空间即可满足BloomFilter的空间需求，这对于绝大部分爬虫的体量来说，是完全可行的。</p><p><strong>时间复杂度</strong><br>时间复杂度方面 BloomFilter的时间复杂度仅与Hash函数的个数k有关，即O(k)</p><h2 id="误判率"><a href="#误判率" class="headerlink" title="误判率"></a>误判率</h2><p>为什么说，在查找元素时，即使某个元素所映射的k位全部位1，依然无法确定它一定存在？</p><p>这是因为当插入的元素很多的情况下，某个元素即使之前不存在，但是它所映射的k位已经被之前其他的元素置为1了，这样就会出现误判，BloomFilter会认为它已经存在了。</p><p>但是这个概率是非常小的。根据维基百科的推导公式来说，误判率的大小p满足以下公式$\eqref{eq:p}$<br>\begin{equation}<br>  \ln p = -{\frac {m}{n}}\left(\ln 2\right)^{2} \label{eq:p}<br>\end{equation}<br>其中m为位向量的长度，n为要插入元素的总数。当误判率为1%时,$\frac mn=9.6$即每个元素仅需要9.6个字节存储即可</p><p>Hash函数的个数k，与误判率大小p的关系为公式$\eqref{eq:k1}$ 所示<br>\begin{equation}<br>  k = {-{\ln p} \over {\ln 2}} \label{eq:k1}<br>\end{equation}<br>当误判率大小为0.1时，k为3。当误判率大小为0.01时，k为7</p><p>而，k与位向量的长度m和插入元素的总数n的关系为公式$\eqref{eq:k2}$ 所示<br>\begin{equation}<br>  k = {\frac {m}{n}}\ln 2 \label{eq:k2}<br>\end{equation}</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><p>BloomFilter 由于并不存储元素，而是用位的01来表示元素是否存在，并且很有可能一个位时被多个元素同时使用。所以无法通过将某元素对应的位置为0来删除元素。</p><p>幸运的是，目前学术界和工业界都有很多方法扩展已解决以上问题。具体可以参考本文第三部分 <strong><a href="#BloomFilter的优化和扩展">BloomFilter的优化和扩展</a></strong></p><h1 id="Guava’s-BloomFilter源码剖析"><a href="#Guava’s-BloomFilter源码剖析" class="headerlink" title="Guava’s BloomFilter源码剖析"></a>Guava’s BloomFilter源码剖析</h1><p><a href="https://github.com/google/guava" target="_blank" rel="noopener">Guava</a>是Google主导开发的基于Java 6开发的一个开源工具包, 其中便包含了<a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/hash/BloomFilter.java" target="_blank" rel="noopener">一个BloomFilter的实现</a>。Guava’s BloomFilter也是一个完全可工程化的BloomFilter的最佳实现范本，本文基于Guava 19.0的源码进行解读。</p><h2 id="使用介绍"><a href="#使用介绍" class="headerlink" title="使用介绍"></a>使用介绍</h2><p>在讲解Guava BloomFilter的源码之前，还是要用一个简单的例子来说明下Guava中BloomFilter的使用，以便更好地理解Guava。具体代码在<a href="https://github.com/chenyahui/practice/blob/master/bloomfilter/BloomFilterSample.java" target="_blank" rel="noopener">这里</a></p><p>在这个例子中，我们定义了一个Person类,来表示一个人的姓名信息。代码如下<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String firstName;</span><br><span class="line">  <span class="keyword">private</span> String lastName;</span><br><span class="line">  <span class="comment">//getter.. </span></span><br><span class="line">  <span class="comment">//setter..</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，我们会将Person对象传递给BloomFilter，当该对象的firstName+lastName在BloomFilter中存在时，会提示已存在，不将其加入BloomFilter中。</p><p>但是对于BloomFilter来说，它无法主动地知道如何把一个自定义类的对象转化为hash值，也许有人会说，重写类的hashcode方法不就行了吗？</p><p>事实上还真不行，因为这和BloomFilter的概念冲突了，BloomFilter简单来说是通过计算出k个不同的hash值来定位元素，重写了hashcode那么这个计算k个hash的过程将毫无意义。</p><p>Guava通过将自定义对象分解为普通类型，对普通类型进行Hash值的计算，来将对象存入BloomFilter中。</p><p>这里Guava引入了一个叫做<code>Funnel</code>的类，Funnel类定义了如何把一个具体的对象类型分解为原生字段值，从而将值分解为Byte以供后面BloomFilter进行hash运算。通过使用这个类，我们可以自己定义一个属于自己类的Funnel。如下代码<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> PersonFunnel implements Funnel&lt;Person&gt; &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">funnel</span><span class="params">(Person person, PrimitiveSink into)</span> </span>&#123;</span><br><span class="line">        into.putString(person.getFirstName(), Charset.defaultCharset())</span><br><span class="line">                .putString(person.getLastName(), Charset.defaultCharset());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>此外，Guava预定义了一些原生类型的Funnel，如String、Long、Integer。具体代码可以在<a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/hash/Funnels.java" target="_blank" rel="noopener">这里看到</a>。当我们的BloomFilter存储的是这些原生类型时，不用再额外自行写Funnel，直接使用Guava预定义的这些即可。</p><p>以下是整个代码调用的流程<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BloomFilterSample</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建一个BloomFilter，其预计插入的个数为10，误判率大约为0.01</span></span><br><span class="line">        BloomFilter&lt;Person&gt; bloomFilter = BloomFilter.create(PersonFunnel.INSTANCE, <span class="number">10</span>, <span class="number">0.01</span>);</span><br><span class="line">        <span class="comment">// 查询new Person("chen", "yahui")是否存在</span></span><br><span class="line">        System.out.println(bloomFilter.mightContain(<span class="keyword">new</span> Person(<span class="string">"chen"</span>, <span class="string">"yahui"</span>))); <span class="comment">//false</span></span><br><span class="line">        <span class="comment">// 将new Person("chen", "yahui")对象放入BloomFilter中</span></span><br><span class="line">        bloomFilter.put(<span class="keyword">new</span> Person(<span class="string">"chen"</span>,<span class="string">"yahui"</span>));</span><br><span class="line">        <span class="comment">// 再次查询new Person("chen", "yahui")是否存在</span></span><br><span class="line">        System.out.println(bloomFilter.mightContain(<span class="keyword">new</span> Person(<span class="string">"chen"</span>, <span class="string">"yahui"</span>))); <span class="comment">//true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h2><h3 id="初始化BloomFilter"><a href="#初始化BloomFilter" class="headerlink" title="初始化BloomFilter"></a>初始化BloomFilter</h3><p>在例子中，我们通过调用<code>BloomFilter.create</code>工厂方法来生成一个BloomFilter<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;T&gt; <span class="function">BloomFilter&lt;T&gt; <span class="title">create</span><span class="params">(Funnel&lt;? <span class="keyword">super</span> T&gt; funnel, </span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">long</span> expectedInsertions,  //预期会插入多少元素</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">double</span> fpp, //自定义误判率</span></span></span><br><span class="line"><span class="function"><span class="params">                          Strategy strategy //Hash策略 </span></span></span><br><span class="line"><span class="function"><span class="params">                          )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (expectedInsertions == <span class="number">0</span>) &#123;</span><br><span class="line">      expectedInsertions = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">//根据插入的数量和误判率来得出位向量应有的长度,这里使用的算法就是公式 2</span></span><br><span class="line">    <span class="keyword">long</span> numBits = optimalNumOfBits(expectedInsertions, fpp);</span><br><span class="line">    <span class="comment">//根据插入的数量和位向量的长度来得出应该用多少个Hash函数，这里使用的算法是公式 4</span></span><br><span class="line">    <span class="keyword">int</span> numHashFunctions = optimalNumOfHashFunctions(expectedInsertions, numBits);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> BloomFilter&lt;T&gt;(<span class="keyword">new</span> BitArray(numBits), numHashFunctions, funnel, strategy);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>整个创建流程非常清晰，如果看懂了本文的算法描述部分，应该不难理解该段代码。整个初始化流程的目的主要有两个：根据参数计算出位向量的长度以及Hash函数的个数</p><ol><li><p>根据预期插入的数量expectedInsertions和自定义的误判率fpp来得到位向量的长度numBits，其中optimalNumOfBits的实现如下</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据插入的数量和误判率来得出位向量应有的长度</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">long</span> <span class="title">optimalNumOfBits</span><span class="params">(<span class="keyword">long</span> n, <span class="keyword">double</span> p)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="number">0</span>) &#123;</span><br><span class="line">      p = Double.MIN_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">long</span>) (-n * Math.log(p) / (Math.log(<span class="number">2</span>) * Math.log(<span class="number">2</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以很明显看出，optimalNumOfBits的源码，其实就是对公式$\eqref{eq:mn}$的实现</p></li><li><p>根据插入的数量expectedInsertions和位向量的长度numBits来得出应该用多少个Hash函数，其中optimalNumOfHashFunctions的实现如下</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">optimalNumOfHashFunctions</span><span class="params">(<span class="keyword">long</span> n, <span class="keyword">long</span> m)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// (m / n) * log(2), but avoid truncation due to division!</span></span><br><span class="line">    <span class="keyword">return</span> Math.max(<span class="number">1</span>, (<span class="keyword">int</span>) Math.round((<span class="keyword">double</span>) m / n * Math.log(<span class="number">2</span>)));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>同样，optimalNumOfHashFunctions也对应了我们算法中公式$\eqref{eq:k2}$</p></li><li>根据numBits生成BitArray。<br>BitArray是Guava中位向量的表示，具体的实现细节，将会在下一节中讲述。</li></ol><h3 id="位向量的表示"><a href="#位向量的表示" class="headerlink" title="位向量的表示"></a>位向量的表示</h3><p>本节主要讲述了Guava中位向量的表示，此部分对于BloomFilter的整体算法流程的理解关联性并不是特别强。读者如对此部分不感兴趣，可直接跳过此节。</p><p>位向量是BloomFilter的存储表示，所有的数据都在BloomFilter中存储。如何更高效地表示位向量也是一个优质的BloomFilter代码重要考量标准。<br>在Guava中，自定义了BitArray类,代码如下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BitArray</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span>[] data;</span><br><span class="line">    <span class="keyword">long</span> bitCount;</span><br><span class="line"></span><br><span class="line">    BitArray(<span class="keyword">long</span> bits) &#123;</span><br><span class="line">      <span class="comment">//对于长度为m的位向量来说，对应的long数组的长度应为m/64向上取整。</span></span><br><span class="line">      <span class="keyword">this</span>(<span class="keyword">new</span> <span class="keyword">long</span>[Ints.checkedCast(LongMath.divide(bits, <span class="number">64</span>, RoundingMode.CEILING))]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">set</span><span class="params">(<span class="keyword">long</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!get(index)) &#123;</span><br><span class="line">          data[(<span class="keyword">int</span>) (index &gt;&gt;&gt; <span class="number">6</span>)] |= (<span class="number">1L</span> &lt;&lt; index);</span><br><span class="line">          bitCount++;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">get</span><span class="params">(<span class="keyword">long</span> index)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> (data[(<span class="keyword">int</span>) (index &gt;&gt;&gt; <span class="number">6</span>)] &amp; (<span class="number">1L</span> &lt;&lt; index)) != <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p>在BitArray中，使用long数组来表示位向量，一个数组元素对应位向量的64位，所以对于长度为m的位向量来说，对应的long数组的长度应为m/64向上取整。<br>即<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="keyword">long</span>[Ints.checkedCast(LongMath.divide(bits, <span class="number">64</span>, RoundingMode.CEILING))]</span><br></pre></td></tr></table></figure></p><p>在BloomFilter算法讲解部分，我们可以看到，对于位向量的常用操作主要有两个，将位向量某一位置为1以及查看位向量某一位是否为1。分别对应源码中的set操作和get操作。<br>本文只讲下get方法的源码部分，set方法与get方法类似，不再累述。</p><p>get方法大致可以分为两部分</p><ol><li>data[(int) (index &gt;&gt;&gt; 6)] 定位到元素<br>上面讲到long数组的每一个元素都包含位向量其中的64位，如果想要找出某个位的bit，那么首先第一步就是定位到该bit所在的元素编号。我们一般的做法是<code>index/64</code>。<br>而源码中使用了<code>index &gt;&gt;&gt; 6</code>,逻辑右移6位，$2^6=64$,其效果与除以64相同。采用位运算的速度比普通的除法要快很多。</li><li>…  &amp; (1L &lt;&lt; index) 获取位的状态<br>源码中直接将要查看的bit以及同一数组元素块的64位bits一起取出，将1L左移index位后求且运算，最终即可得出该位的值。</li></ol><h2 id="k个hash函数的选取"><a href="#k个hash函数的选取" class="headerlink" title="k个hash函数的选取"></a>k个hash函数的选取</h2><p>在Hash函数的选取方面，一个很重要的问题就是如何选取多个Hash函数？</p><p>我们在对元素进行映射的时候，Hash函数的个数k的选取，最少也得为3个，最多可能多达十几个甚至更多，而目前世界上可商用的高质量的开源的Hash方法，远远达不到BloomFilter的需求。<br>在论文<a href="http://www.ccs.neu.edu/home/pete/pub/bloom-filters-verification.pdf" target="_blank" rel="noopener">《Bloom Filters in Probabilistic Verification》</a>中提出了一种算法，把原本需要几十个hash函数的bloom filter转化成了两个hash值的运算，完美地解决了这个问题。<br>\begin{equation}<br>g_i(x)=h_1(x)+ih_2(x)+i^2 mod m \label{eq:gxhash}<br>\end{equation}</p><p>上述公式中$g_i(x)$为第i个hash函数。其中<code>0 &lt; i &lt; k</code>。也就是说使用hash1()和hash2()对一次输入求出两个不同的hash值，然后将这两个hash值代入公式，求出k个hash值。<br>整体的计算流程如下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//准备阶段 </span></span><br><span class="line">h1 = hash1(input), h2 = hash2(input)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 求出k个hash值</span></span><br><span class="line">g0(x) = h1                    第<span class="number">0</span>个hash函数求出的hash值</span><br><span class="line">g1(x) = h1+h2+<span class="number">1</span>               第<span class="number">1</span>个hash函数求出的hash值</span><br><span class="line">g2(x) = h1+<span class="number">2</span>*h2+<span class="number">4</span>             第<span class="number">2</span>个hash函数求出的hash值</span><br><span class="line">...</span><br><span class="line">gk-<span class="number">1</span>(x) = h1+(k-<span class="number">1</span>)*h2+(k-<span class="number">1</span>)^<span class="number">2</span> 第k-<span class="number">1</span>个hash函数求出的hash值</span><br></pre></td></tr></table></figure></p><p>在哈佛大学2006年的一篇论文《Less hashing, same performance: building a better bloom filter》中，对此方法的有效性进行了验证，证明了此种方法不会对BloomFilter的效率有所恶化。</p><p>Guava实现了两种策略MURMUR128_MITZ_32和MURMUR128_MITZ_64，其所有的实现类为<a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/hash/BloomFilterStrategies.java" target="_blank" rel="noopener">BloomFilterStrategies</a>。<br>本文针对Guava的BloomFilter所采用的MURMUR128_MITZ_32策略进行讲解，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">public</span> &lt;T&gt; <span class="function"><span class="keyword">boolean</span> <span class="title">put</span><span class="params">(T object, </span></span></span><br><span class="line"><span class="function"><span class="params">                        Funnel&lt;? <span class="keyword">super</span> T&gt; funnel, </span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">int</span> numHashFunctions, </span></span></span><br><span class="line"><span class="function"><span class="params">                        BitArray bits)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">long</span> bitSize = bits.bitSize();</span><br><span class="line">      <span class="keyword">long</span> hash64 = Hashing.murmur3_128().hashObject(object, funnel).asLong();</span><br><span class="line">      <span class="keyword">int</span> hash1 = (<span class="keyword">int</span>) hash64;</span><br><span class="line">      <span class="keyword">int</span> hash2 = (<span class="keyword">int</span>) (hash64 &gt;&gt;&gt; <span class="number">32</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">boolean</span> bitsChanged = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= numHashFunctions; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> combinedHash = hash1 + (i * hash2);</span><br><span class="line">        <span class="comment">// Flip all the bits if it's negative (guaranteed positive number)</span></span><br><span class="line">        <span class="keyword">if</span> (combinedHash &lt; <span class="number">0</span>) &#123;</span><br><span class="line">          combinedHash = ~combinedHash;</span><br><span class="line">        &#125;</span><br><span class="line">        bitsChanged |= bits.set(combinedHash % bitSize);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> bitsChanged;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MURMUR128_MITZ_32是对公式$\eqref{eq:gxhash}$的一个实现的体现。首先根据MurMurHash计算出某个对象的64位hash值，将其分为两段，后32位为hash1，前32位为hash2。<br>将hash1看成公式$\eqref{eq:gxhash}$中的h1(x)计算后的结果，hash2看做是h2(x)计算后的结果，同时省去公式中的$i^2$，将hash1和hash2代入公式计算。</p><p>在Hash函数选取方面，Guava采用了MurmurHash3算法。MurmurHash算法是2008年提出的一种Hash算法，运算简单高效，而且随机性强。目前最新的版本为MurmurHash3。</p><p>MurmurHash3能够产生出32-bit或128-bit两种哈希值。在MURMUR128_MITZ_32和MURMUR128_MITZ_64都选择使用了128-bit的结果。二者不同的是，MURMUR128_MITZ_32仅使用128-bit的前64位。而MURMUR128_MITZ_64完全使用了128位的结果。</p><h1 id="BloomFilter的优化和扩展"><a href="#BloomFilter的优化和扩展" class="headerlink" title="BloomFilter的优化和扩展"></a>BloomFilter的优化和扩展</h1><h2 id="Counting-BloomFilter"><a href="#Counting-BloomFilter" class="headerlink" title="Counting BloomFilter"></a>Counting BloomFilter</h2><p>上文提到布隆过滤器无法支持元素的删除操作,Counting BloomFilter通过存储位元素每一位的置为1的数量，使得布隆过滤器可以支持删除操作。<br>但是这样会数倍地增加布隆过滤器的存储空间。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://en.wikipedia.org/wiki/Bloom_filter" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Bloom_filter</a></li><li><a href="https://www.cs.dal.ca/research/techreports/cs-2002-10" target="_blank" rel="noopener">https://www.cs.dal.ca/research/techreports/cs-2002-10</a></li><li><a href="https://llimllib.github.io/bloomfilter-tutorial/" target="_blank" rel="noopener">https://llimllib.github.io/bloomfilter-tutorial/</a></li><li><a href="https://github.com/cpselvis/zhihu-crawler/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0" target="_blank" rel="noopener">https://github.com/cpselvis/zhihu-crawler/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0</a></li><li><a href="http://stackoverflow.com/questions/4282375/what-is-the-advantage-to-using-bloom-filters" target="_blank" rel="noopener">http://stackoverflow.com/questions/4282375/what-is-the-advantage-to-using-bloom-filters</a></li><li><a href="http://blog.csdn.net/v_july_v/article/details/6685894" target="_blank" rel="noopener">http://blog.csdn.net/v_july_v/article/details/6685894</a></li><li><a href="http://leadtoit.iteye.com/blog/1961751" target="_blank" rel="noopener">http://leadtoit.iteye.com/blog/1961751</a></li><li><a href="http://ifeve.com/google-guava-hashing/" target="_blank" rel="noopener">http://ifeve.com/google-guava-hashing/</a></li><li><a href="http://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf" target="_blank" rel="noopener">http://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf</a></li><li><a href="http://blog.csdn.net/jiaomeng/article/details/1498283" target="_blank" rel="noopener">http://blog.csdn.net/jiaomeng/article/details/1498283</a></li><li><a href="http://www.jianshu.com/p/8193d7dc8348" target="_blank" rel="noopener">http://www.jianshu.com/p/8193d7dc8348</a></li><li><a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/MurmurHash</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;BloomFilter（布隆过滤器）是一种可以高效地判断元素是否在某个集合中的算法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在很多日常场景中，都大量存在着布隆过滤器的应用。例如：检查单词是否拼写正确、网络爬虫的URL去重、黑名单检验，微博中昵称不能重复的检测等。&lt;/p&gt;
&lt;p&gt;在工业界中，Google著名的分布式数据库BigTable也用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数；Google Chrome浏览器使用BloomFilter来判断一个网站是否为恶意网站。   &lt;/p&gt;
&lt;p&gt;对于以上场景，可能很多人会说，用HashSet甚至简单的链表、数组做存储，然后判断是否存在不就可以了吗？&lt;/p&gt;
&lt;p&gt;当然，对于少量数据来说，HashSet是很好的选择。但是对于海量数据来说，BloomFilter相比于其他数据结构在空间效率和时间效率方面都有着明显的优势。   &lt;/p&gt;
&lt;p&gt;但是，布隆过滤器具有一定的误判率，有可能会将本不存在的元素判定为存在。因此，对于那些需要“零错误”的应用场景，布隆过滤器将不太适用。具体的原因将会在第二部分中介绍。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="http://www.cyhone.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="BloomFilter" scheme="http://www.cyhone.com/tags/BloomFilter/"/>
    
      <category term="算法" scheme="http://www.cyhone.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>2016年度总结</title>
    <link href="http://www.cyhone.com/articles/2016-summary/"/>
    <id>http://www.cyhone.com/articles/2016-summary/</id>
    <published>2017-01-01T05:00:54.000Z</published>
    <updated>2019-11-03T09:22:16.602Z</updated>
    
    <content type="html"><![CDATA[<p>2016年过去了。真的是转瞬即逝，一眨眼的功夫，365个日夜。总结2016年，平平凡凡但踏踏实实。</p><a id="more"></a><h2 id="学习"><a href="#学习" class="headerlink" title="学习"></a>学习</h2><p>在学习方面今年有最大的两个变化。第一个是本科毕业，研究生入学。第二个是决定成为Javaer。</p><p>研究生生活的学习生活没有什么值得说的。最大的体会就是没有在研究生的任何课上学到有价值的东西。。<br>中间穿插了几个横向的项目，蛮忙的。研究生期间学会了合理地规划自己的时间，也更懂得了不断学习的重要性。<br>虽然留给自己的时间不多，但还是自学了很多东西。</p><p>开始全心做Java开发的原因有很多，一方面因为实验室的项目大多以Java为主，对于常用的语言熟悉掌握才可以有更高的开发效率。<br>另外一个原因是Java在学习曲线上并不陡峭，而且开源库十分丰富。</p><p>我在大二下学期开始学习PHP，使用PHP可以很简单的打造出一个网站后台。但是个人觉得PHP始终不是一个适合<br>研究学习的语言。在C++语言的学习方面，虽然看了一些C++的相关书，《C++ primer》、<br>《STL源码剖析》、《Effective C++》等，但始终进步不大，最终还是选择了暂时放弃。</p><p>在Java的学习过程中，看了《Thinking in Java》、《Effective Java》、《Java并发编程实践》、《Java并发编程实战》，对于<br>整个语言有了清晰的脉络，虽然还远远的称不上熟知Java语言，但是它确实已经成为我的主开发语言了。</p><p>当然今年除了Java也大量地使用了Python、GO语言。对不同语言的使用，体会了不同语言的魅力，也更容易看清楚<br>一个语言的优点在哪，缺点又是什么。</p><h2 id="项目"><a href="#项目" class="headerlink" title="项目"></a>项目</h2><p>2016年进行的项目和作品有：</p><ul><li>毕业设计-同类网站推荐系统的设计和研究</li><li>基于SpringMVC的轻量级CMS （已完成，未开源）</li><li>爬虫系统新内核的编写 （进行中）</li><li><a href="http://ecic.org.cn" target="_blank" rel="noopener">ecic.org.cn</a>官网 (已上线)</li><li><a href="http://ecra.com.cn/" target="_blank" rel="noopener">ecra.com.cn</a>官网 (已上线)</li><li>MIT 6.824 Lab (完成lab1)</li></ul><p>看了<a href="https://www.zhihu.com/question/26983024/answer/85772802" target="_blank" rel="noopener">如何成为 @RednaxelaFX 一样的大牛? - 知乎</a><br>RednaxelaFX大的回答后，觉得R大的状态是一个技术人最好的状态了。愿意花时间和精力去穷尽这行业的每一点知识。</p><h2 id="读书"><a href="#读书" class="headerlink" title="读书"></a>读书</h2><p>今年共读了25本书。大部分为kindle和微信读书的电子书。具体关于读书的总结在<a href="http://www.cyhone.com/2017/01/01/2016-summary/">另外一篇博客</a>中。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p>我在2015年的三月份左右也就是旧历年，给自己定了两个目标：编程能力提高以及减肥。</p><p>编程能力方面，在上一部分已经总结过。虽然总体并没有大的提高，但是自己确实能实实在在地感受到进步。</p><p>之所以下定决心减肥是因为过年的时候一度胖到心里压抑。<br>从2016年的四月份到2016年7月份，三个月的时间减了大概24斤左右。达到了一个小小的目标，<br>虽然现在依然蛮胖。。但是身心得到了很大的调节。</p><p>健身这件事情是要坚持一辈子的事情。我从11月中旬开始除了下月每天都跑步5公里以上，<br>在精神和专注力上明显的充沛了很多。</p><p>自己从本科就一直想学一门乐器，今年生日女朋友送了一把尤克里里。非常惭愧半年过去了依然是<br>小星星水平。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>今年最惭愧的就是除了一个总结外一篇博客都没产出。很大程度上也是因为目前学习的内容实在没有拿的出手总结的东西。<br>在接下来的一年内，已经有了一些想要分享的内容，希望自己可以好好总结发表。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>2016年就这么过去了。并不曲折，并不离奇，在个人的时间线也几乎没有大事发生。<br>新的一年，还可以再努力一点~</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2016年过去了。真的是转瞬即逝，一眨眼的功夫，365个日夜。总结2016年，平平凡凡但踏踏实实。&lt;/p&gt;
    
    </summary>
    
      <category term="生活和思考" scheme="http://www.cyhone.com/categories/%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E8%80%83/"/>
    
    
      <category term="总结" scheme="http://www.cyhone.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
</feed>
